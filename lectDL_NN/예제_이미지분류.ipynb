{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 환경설치"
      ],
      "metadata": {
        "id": "bch3hYc_la0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOKD_DvClPW0",
        "outputId": "36f46e70-52bf-42bd-dc83-237fa069e5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            " 모든 라이브러리가 성공적으로 로드되었습니다!\n",
            "PyTorch 버전: 2.6.0+cu124\n",
            "CUDA 사용 가능: True\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치 (코랩에서 실행)\n",
        "!pip install torch torchvision matplotlib seaborn pandas numpy Pillow scikit-learn\n",
        "\n",
        "# 기본 라이브러리 import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import io\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "import os\n",
        "\n",
        "# 시드 설정 (재현 가능한 결과를 위해)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\" 모든 라이브러리가 성공적으로 로드되었습니다!\")\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bdc4727",
        "outputId": "3dbe2492-3734-4eb2-bef6-94e5ca35235f"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "\n",
        "class FakeImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Creates a fake dataset of images and labels for demonstration purposes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples=1000, image_size=(3, 224, 224), num_classes=10, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_samples (int): Number of samples in the dataset.\n",
        "            image_size (tuple): Size of the images (C, H, W).\n",
        "            num_classes (int): Number of classes.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.num_samples = num_samples\n",
        "        self.image_size = image_size\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transform\n",
        "        self.data = torch.randn(num_samples, *image_size) # Generate random image data\n",
        "        self.labels = torch.randint(0, num_classes, (num_samples,)) # Generate random labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            # Convert tensor to PIL Image to apply torchvision transforms\n",
        "            # Note: This is a simplified approach. For real image data,\n",
        "            # you would load images from files.\n",
        "            image_np = image.mul(255).clamp(0, 255).byte().permute(1, 2, 0).numpy()\n",
        "            image_pil = Image.fromarray(image_np, 'RGB')\n",
        "            image = self.transform(image_pil)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "print(\" FakeImageDataset 클래스가 정의되었습니다.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FakeImageDataset 클래스가 정의되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CompletePipeline:\n",
        "    \"\"\"데이터 파이프라인 예제\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"  파이프라인 초기화 (Device: {self.device})\")\n",
        "\n",
        "    def create_transforms(self):\n",
        "        \"\"\"Transform 생성\"\"\"\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=10),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        val_transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        return train_transform, val_transform\n",
        "\n",
        "    def create_datasets(self, num_train=1000, num_val=200):\n",
        "        \"\"\"데이터셋 생성\"\"\"\n",
        "        train_transform, val_transform = self.create_transforms()\n",
        "\n",
        "        # 훈련 및 검증 데이터셋 생성\n",
        "        train_dataset = FakeImageDataset(\n",
        "            num_samples=num_train,\n",
        "            image_size=(3, 224, 224),\n",
        "            num_classes=10,\n",
        "            transform=train_transform\n",
        "        )\n",
        "\n",
        "        val_dataset = FakeImageDataset(\n",
        "            num_samples=num_val,\n",
        "            image_size=(3, 224, 224),\n",
        "            num_classes=10,\n",
        "            transform=val_transform\n",
        "        )\n",
        "\n",
        "        return train_dataset, val_dataset\n",
        "\n",
        "    def create_dataloaders(self, train_dataset, val_dataset, batch_size=32):\n",
        "        \"\"\"DataLoader 생성\"\"\"\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2,\n",
        "            pin_memory=torch.cuda.is_available()\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=torch.cuda.is_available()\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "    def analyze_data(self, train_loader, val_loader):\n",
        "        \"\"\"데이터 분석\"\"\"\n",
        "        print(f\"\\n 데이터 분석:\")\n",
        "\n",
        "        # 훈련 데이터 분석\n",
        "        train_batch = next(iter(train_loader))\n",
        "        train_images, train_labels = train_batch\n",
        "\n",
        "        print(f\"   훈련 데이터:\")\n",
        "        print(f\"     - 배치 크기: {train_images.size(0)}\")\n",
        "        print(f\"     - 이미지 shape: {train_images.shape}\")\n",
        "        print(f\"     - 값 범위: [{train_images.min():.3f}, {train_images.max():.3f}]\")\n",
        "        print(f\"     - 라벨 분포: {torch.bincount(train_labels, minlength=10)}\")\n",
        "\n",
        "        # 검증 데이터 분석\n",
        "        val_batch = next(iter(val_loader))\n",
        "        val_images, val_labels = val_batch\n",
        "\n",
        "        print(f\"   검증 데이터:\")\n",
        "        print(f\"     - 배치 크기: {val_images.size(0)}\")\n",
        "        print(f\"     - 이미지 shape: {val_images.shape}\")\n",
        "        print(f\"     - 값 범위: [{val_images.min():.3f}, {val_images.max():.3f}]\")\n",
        "        print(f\"     - 라벨 분포: {torch.bincount(val_labels, minlength=10)}\")\n",
        "\n",
        "        return train_batch, val_batch\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"전체 파이프라인 실행\"\"\"\n",
        "        print(\"  데이터 파이프라인 실행\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # 1. 데이터셋 생성\n",
        "        print(\"\\n1 데이터셋 생성...\")\n",
        "        train_dataset, val_dataset = self.create_datasets()\n",
        "\n",
        "        # 2. DataLoader 생성\n",
        "        print(\"\\n2 DataLoader 생성...\")\n",
        "        train_loader, val_loader = self.create_dataloaders(train_dataset, val_dataset)\n",
        "\n",
        "        # 3. 데이터 분석\n",
        "        print(\"\\n3 데이터 분석...\")\n",
        "        train_batch, val_batch = self.analyze_data(train_loader, val_loader)\n",
        "\n",
        "        # 4. 성능 측정\n",
        "        print(\"\\n4 성능 측정...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        batch_count = 0\n",
        "        for batch_images, batch_labels in train_loader:\n",
        "            # GPU로 이동 (사용 가능한 경우)\n",
        "            batch_images = batch_images.to(self.device)\n",
        "            batch_labels = batch_labels.to(self.device)\n",
        "\n",
        "            # 간단한 연산 (실제로는 모델 훈련)\n",
        "            _ = batch_images.mean()\n",
        "\n",
        "            batch_count += 1\n",
        "            if batch_count >= 10:\n",
        "                break\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        throughput = (batch_count * train_loader.batch_size) / elapsed_time\n",
        "\n",
        "        print(f\"     - 처리 시간: {elapsed_time:.3f}초\")\n",
        "        print(f\"     - 처리량: {throughput:.1f} 샘플/초\")\n",
        "\n",
        "        print(\"\\n 파이프라인 실행 완료!\")\n",
        "\n",
        "        return {\n",
        "            'train_loader': train_loader,\n",
        "            'val_loader': val_loader,\n",
        "            'performance': {\n",
        "                'time': elapsed_time,\n",
        "                'throughput': throughput\n",
        "            }\n",
        "        }\n",
        "\n",
        "# 완전한 파이프라인 실행\n",
        "pipeline = CompletePipeline()\n",
        "results = pipeline.run_complete_pipeline()\n",
        "\n",
        "# 결과 요약\n",
        "print(f\"\\n 최종 결과 요약:\")\n",
        "print(f\"   - 훈련 배치 수: {len(results['train_loader'])}\")\n",
        "print(f\"   - 검증 배치 수: {len(results['val_loader'])}\")\n",
        "print(f\"   - 처리 성능: {results['performance']['throughput']:.1f} 샘플/초\")\n",
        "print(f\"   - Device: {pipeline.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeqraOWWlgrA",
        "outputId": "db410c97-19c4-46cd-a32e-58bbbee0da00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  파이프라인 초기화 (Device: cuda)\n",
            "  데이터 파이프라인 실행\n",
            "============================================================\n",
            "\n",
            "1 데이터셋 생성...\n",
            "\n",
            "2 DataLoader 생성...\n",
            "\n",
            "3 데이터 분석...\n",
            "\n",
            " 데이터 분석:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-1972242258.py:36: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image_pil = Image.fromarray(image_np, 'RGB')\n",
            "/tmp/ipython-input-3-1972242258.py:36: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image_pil = Image.fromarray(image_np, 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   훈련 데이터:\n",
            "     - 배치 크기: 32\n",
            "     - 이미지 shape: torch.Size([32, 3, 224, 224])\n",
            "     - 값 범위: [-2.118, 2.640]\n",
            "     - 라벨 분포: tensor([5, 4, 4, 1, 1, 2, 2, 5, 4, 4])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-1972242258.py:36: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image_pil = Image.fromarray(image_np, 'RGB')\n",
            "/tmp/ipython-input-3-1972242258.py:36: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image_pil = Image.fromarray(image_np, 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   검증 데이터:\n",
            "     - 배치 크기: 32\n",
            "     - 이미지 shape: torch.Size([32, 3, 224, 224])\n",
            "     - 값 범위: [-2.118, 2.640]\n",
            "     - 라벨 분포: tensor([2, 1, 5, 6, 2, 2, 2, 2, 5, 5])\n",
            "\n",
            "4 성능 측정...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-1972242258.py:36: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image_pil = Image.fromarray(image_np, 'RGB')\n",
            "/tmp/ipython-input-3-1972242258.py:36: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image_pil = Image.fromarray(image_np, 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     - 처리 시간: 1.183초\n",
            "     - 처리량: 270.5 샘플/초\n",
            "\n",
            " 파이프라인 실행 완료!\n",
            "\n",
            " 최종 결과 요약:\n",
            "   - 훈련 배치 수: 32\n",
            "   - 검증 배치 수: 7\n",
            "   - 처리 성능: 270.5 샘플/초\n",
            "   - Device: cuda\n"
          ]
        }
      ]
    }
  ]
}