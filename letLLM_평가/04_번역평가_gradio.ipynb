{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "No_5xJNXR8Iv"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ì„¤ì¹˜ (Colab ì „ìš©)\n",
    "# =========================\n",
    "!pip install -q openai gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "uEcAlBVBR4qU",
    "outputId": "241ae56b-221d-48ef-d738-ced04932cf53"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# =========================\n",
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import evaluate\n",
    "\n",
    "# =========================\n",
    "# ë²ˆì—­ í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)\n",
    "# =========================\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"ë„ˆëŠ” ì „ë¬¸ ë²ˆì—­ê°€ë‹¤. ë°˜ë“œì‹œ {target_lang}ë¡œë§Œ ë²ˆì—­í•´ë¼.\n",
    "[ì§€ì¹¨]\n",
    "- ì›ë¬¸ ì˜ë¯¸ë¥¼ ì •í™•íˆ ë³´ì¡´í•˜ë˜, {domain_style}\n",
    "- ê³¼ë„í•œ ì˜ì—­/ì„¤ëª… ê¸ˆì§€, ë²ˆì—­ë¬¸ë§Œ ì¶œë ¥\n",
    "- ì¤„ë°”ê¿ˆ/ë¦¬ìŠ¤íŠ¸/ë§ˆí¬ë‹¤ìš´ì€ ê°€ëŠ¥í•œ ìœ ì§€\n",
    "\"\"\"\n",
    "\n",
    "DOMAIN_STYLES = {\n",
    "    \"ì¼ìƒ\": \"ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ êµ¬ì–´ì²´ë¡œ í‘œí˜„í•œë‹¤.\",\n",
    "    \"IT\": \"ê¸°ìˆ  ìš©ì–´/ì•½ì–´/í‘œê¸°ë¥¼ ë³´ì¡´í•˜ê³ , ì •í™•í•œ ê¸°ìˆ  ë¬¸ì„œ í†¤ìœ¼ë¡œ í‘œí˜„í•œë‹¤.\"\n",
    "}\n",
    "\n",
    "def translate(text: str, direction: str, domain: str, api_key: str):\n",
    "    if not text.strip():\n",
    "        yield \" ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\"\n",
    "        return\n",
    "\n",
    "    key = api_key or os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not key:\n",
    "        yield \" OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ì¹¸ì— í‚¤ë¥¼ ë„£ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.\"\n",
    "        return\n",
    "\n",
    "    client = OpenAI(api_key=key)\n",
    "\n",
    "    target_lang = \"ì˜ì–´\" if direction == \"í•œâ†’ì˜\" else \"í•œêµ­ì–´\"\n",
    "    src_lang = \"í•œêµ­ì–´\" if direction == \"í•œâ†’ì˜\" else \"ì˜ì–´\"\n",
    "\n",
    "    sys_prompt = SYSTEM_PROMPT_TEMPLATE.format(\n",
    "        target_lang=target_lang,\n",
    "        domain_style=DOMAIN_STYLES.get(domain, \"ë¬¸ë§¥ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•œë‹¤.\")\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"ì›ë¬¸({src_lang}):\\n{text}\\n\\n\"\n",
    "                f\"ë²ˆì—­ ëŒ€ìƒ ì–¸ì–´: {target_lang}\\n\"\n",
    "                f\"ë²ˆì—­ë¬¸ë§Œ ì¶œë ¥í•´ì¤˜.\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        stream = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.2,\n",
    "            stream=True,\n",
    "        )\n",
    "        out = \"\"\n",
    "        for chunk in stream:\n",
    "            try:\n",
    "                delta = chunk.choices[0].delta\n",
    "                if delta and getattr(delta, \"content\", None):\n",
    "                    out += delta.content\n",
    "                    yield out  # Gradioì— ì‹¤ì‹œê°„ ê°±ì‹ \n",
    "            except Exception:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        yield f\" ì˜¤ë¥˜: {e}\"\n",
    "\n",
    "def evaluateByGPT(origin_str, trans_str, ref_str, direction, api_key):\n",
    "\n",
    "    lang = \"en\" if direction == \"í•œâ†’ì˜\" else \"kr\"\n",
    "    # 4. GPT í‰ê°€ í”„ë¡¬í”„íŠ¸ (í•œê¸€ ë²„ì „)\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¹ì‹ ì€ í‰ê°€ìì…ë‹ˆë‹¤. ë‹¤ìŒ ë‘ ë²ˆì—­ì„ ë¹„êµí•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "    ğŸ“Œ ì›ë¬¸:\n",
    "    {origin_str}\n",
    "\n",
    "    ğŸ“Œ ì°¸ì¡° ë²ˆì—­:\n",
    "    {ref_str}\n",
    "\n",
    "    ğŸ“Œ ëª¨ë¸ ë²ˆì—­:\n",
    "    {trans_str}\n",
    "\n",
    "    í‰ê°€ ê¸°ì¤€ (0~5ì ):\n",
    "    - 5ì  = ì™„ë²½í•˜ê²Œ ì¼ì¹˜\n",
    "    - 4ì  = ê±°ì˜ ì¼ì¹˜í•˜ë‚˜ ì‚¬ì†Œí•œ ì°¨ì´ ìˆìŒ\n",
    "    - 3ì  = ë¶€ë¶„ì ìœ¼ë¡œ ë§ì§€ë§Œ ì¤‘ìš”í•œ ì°¨ì´ê°€ ìˆìŒ\n",
    "    - 2ì  = ëŒ€ë¶€ë¶„ í‹€ë ¸ì§€ë§Œ ì¼ë¶€ ê´€ë ¨ì„± ìˆìŒ\n",
    "    - 1ì  = ê±°ì˜ í‹€ë¦¼\n",
    "    - 0ì  = ì „í˜€ ê´€ë ¨ ì—†ìŒ\n",
    "\n",
    "    ì¶œë ¥ í˜•ì‹:\n",
    "    ì ìˆ˜: X/5\n",
    "    ì´ìœ : ê°„ë‹¨í•œ ì„¤ëª…\n",
    "    \"\"\"\n",
    "\n",
    "    key = api_key or os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not key:\n",
    "        yield \" OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ì¹¸ì— í‚¤ë¥¼ ë„£ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.\"\n",
    "        return\n",
    "\n",
    "    client = OpenAI(api_key=key)\n",
    "\n",
    "    # 5. GPT API í˜¸ì¶œ\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    print(\"ğŸ” GPT í‰ê°€ ê²°ê³¼:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    out = response.choices[0].message.content\n",
    "\n",
    "    bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "    # 9. BERTScore\n",
    "    bertscore_result = bertscore.compute(predictions=[trans_str], references=[ref_str], lang=\"en\")\n",
    "    print(\"\\nBERTScore (F1):\", bertscore_result[\"f1\"][0])\n",
    "\n",
    "    out += \"\\n\" + f'\\nBERTScore (F1):{bertscore_result[\"f1\"][0]:.4f}'\n",
    "    yield out  # Gradioì— ì‹¤ì‹œê°„ ê°±ì‹ \n",
    "\n",
    "\n",
    "# =========================\n",
    "# Gradio UI\n",
    "# =========================\n",
    "with gr.Blocks(title=\"GPT í•œâ†”ì˜ ë²ˆì—­ê¸°\") as demo:\n",
    "    gr.Markdown(\"#  GPT í•œâ†”ì˜ ë²ˆì—­ê¸°\\n- GPT APIì™€ Gradioë¡œ êµ¬í˜„ëœ ê°„ë‹¨ ë²ˆì—­ê¸°\\n- ë²ˆì—­ ë°©í–¥ê³¼ ë„ë©”ì¸(ì¼ìƒ/IT)ì„ ì„ íƒí•˜ì„¸ìš”.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        api_key = gr.Textbox(\n",
    "            label=\"OpenAI API Key (ì„ íƒ)\",\n",
    "            type=\"password\",\n",
    "            placeholder=\"í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ì„¤ì • ì‹œ ìƒëµ ê°€ëŠ¥\"\n",
    "        )\n",
    "        direction = gr.Radio(\n",
    "            [\"í•œâ†’ì˜\", \"ì˜â†’í•œ\"],\n",
    "            value=\"í•œâ†’ì˜\",\n",
    "            label=\"ë²ˆì—­ ë°©í–¥\"\n",
    "        )\n",
    "        domain = gr.Dropdown(\n",
    "            [\"ì¼ìƒ\", \"IT\"],\n",
    "            value=\"ì¼ìƒ\",\n",
    "            label=\"ë„ë©”ì¸ ìŠ¤íƒ€ì¼\"\n",
    "        )\n",
    "\n",
    "    src = gr.Textbox(lines=3, label=\"ì…ë ¥ í…ìŠ¤íŠ¸\")    \n",
    "    tgt = gr.Textbox(lines=3, label=\"ë²ˆì—­ ê²°ê³¼\", interactive=False)    \n",
    "\n",
    "    with gr.Row():\n",
    "        btn = gr.Button(\"ë²ˆì—­\", variant=\"primary\")\n",
    "        clr = gr.Button(\"ì´ˆê¸°í™”\")        \n",
    "\n",
    "    ref_src = gr.Textbox(lines=2, label=\"ì°¸ì¡° ë²ˆì—­ í…ìŠ¤íŠ¸\")\n",
    "    eval = gr.Textbox(lines=8, label=\"í‰ê°€ ê²°ê³¼\", interactive=True)\n",
    "    eva = gr.Button(\"í‰ê°€\")\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"ì˜¤ëŠ˜ íšŒì˜ ìë£Œë¥¼ ê³µìœ í•´ ì£¼ì„¸ìš”.\", \"í•œâ†’ì˜\", \"ì¼ìƒ\", \"\", \"Please share today's meeting materials.\"],\n",
    "            [\"We are deploying the new API gateway this Friday.\", \"ì˜â†’í•œ\", \"IT\", \"\", \"ì´ë²ˆ ê¸ˆìš”ì¼ì— ìƒˆë¡œìš´ API ê²Œì´íŠ¸ì›¨ì´ë¥¼ ë°°í¬í•  ì˜ˆì •ì…ë‹ˆë‹¤.\"],\n",
    "        ],\n",
    "        inputs=[src, direction, domain, api_key, ref_src],\n",
    "        label=\"ì˜ˆì‹œ\"\n",
    "    )\n",
    "\n",
    "    # í´ë¦­ ì´ë²¤íŠ¸: ìŠ¤íŠ¸ë¦¬ë°(ì œë„ˆë ˆì´í„°) ì—°ê²°\n",
    "    btn.click(\n",
    "        fn=translate,\n",
    "        inputs=[src, direction, domain, api_key],\n",
    "        outputs=tgt\n",
    "    )\n",
    "\n",
    "    # í´ë¦­ ì´ë²¤íŠ¸: ìŠ¤íŠ¸ë¦¬ë°(ì œë„ˆë ˆì´í„°) ì—°ê²° í‰ê°€\n",
    "    eva.click(\n",
    "        fn=evaluateByGPT,\n",
    "        inputs=[src, tgt, ref_src, direction, api_key],\n",
    "        outputs=eval\n",
    "    )\n",
    "\n",
    "    # ì´ˆê¸°í™” ë²„íŠ¼\n",
    "    clr.click(lambda: (\"\", \"\"), None, [src, tgt])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7864\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
