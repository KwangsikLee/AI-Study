{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n79Uq9UqWvOy"
      },
      "outputs": [],
      "source": [
        "# 1. ì„¤ì¹˜\n",
        "!pip install openai -q\n",
        "\n",
        "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
        "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "client = OpenAI(api_key=API_KEY)  # <- ë³¸ì¸ API í‚¤ ì…ë ¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2C8jMDCWfuO",
        "outputId": "e9852281-a21c-47e5-eee9-187ac0c434ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” GPT í‰ê°€ ê²°ê³¼:\n",
            "ì ìˆ˜: 3/5  \n",
            "ì´ìœ : ë‘ ìš”ì•½ ëª¨ë‘ ì¸ê³µì§€ëŠ¥ì— ëŒ€í•œ ì •ì˜ë¥¼ ì œê³µí•˜ì§€ë§Œ, ì°¸ì¡° ìš”ì•½ì€ ì¸ê³µì§€ëŠ¥ì„ \"ê¸°ê³„ê°€ ë³´ì—¬ì£¼ëŠ” ì§€ëŠ¥\"ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , \"ì§€ëŠ¥ì  ì—ì´ì „íŠ¸ì˜ ì—°êµ¬ ë¶„ì•¼\"ë¼ëŠ” ì¶”ê°€ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°˜ë©´, ëª¨ë¸ ìš”ì•½ì€ ì¸ê³µì§€ëŠ¥ì„ \"ë™ë¬¼ê³¼ ê¸°ê³„ê°€ ëª¨ë‘ ê°€ì§€ëŠ” ì§€ëŠ¥\"ìœ¼ë¡œ ì„¤ëª…í•˜ë©°, í™˜ê²½ ì¸ì‹ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆì–´ ì¤‘ìš”í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë¶€ë¶„ì ìœ¼ë¡œ ë§ì§€ë§Œ ì¤‘ìš”í•œ ì°¨ì´ê°€ ìˆë‹¤ê³  í‰ê°€í–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3. ìƒ˜í”Œ ë°ì´í„° (í•œêµ­ì–´)\n",
        "document = \"\"\"\n",
        "ì¸ê³µì§€ëŠ¥(AI)ì€ ê¸°ê³„ê°€ ë³´ì—¬ì£¼ëŠ” ì§€ëŠ¥ìœ¼ë¡œ,\n",
        "ì¸ê°„ì´ë‚˜ ë™ë¬¼ì´ ê°€ì§„ ìì—° ì§€ëŠ¥ê³¼ëŠ” êµ¬ë³„ë©ë‹ˆë‹¤.\n",
        "AIëŠ” í™˜ê²½ì„ ì¸ì‹í•˜ê³  ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´\n",
        "í–‰ë™í•˜ëŠ” ì§€ëŠ¥ì  ì—ì´ì „íŠ¸ì˜ ì—°êµ¬ë¡œ ì •ì˜ë©ë‹ˆë‹¤.\n",
        "\"\"\"\n",
        "reference_summary = \"ì¸ê³µì§€ëŠ¥ì€ ê¸°ê³„ê°€ ë³´ì—¬ì£¼ëŠ” ì§€ëŠ¥ìœ¼ë¡œ, ì§€ëŠ¥ì  ì—ì´ì „íŠ¸ì˜ ì—°êµ¬ ë¶„ì•¼ì´ë‹¤.\"\n",
        "model_summary = \"ì¸ê³µì§€ëŠ¥ì€ ë™ë¬¼ê³¼ ê¸°ê³„ê°€ ëª¨ë‘ ê°€ì§€ëŠ” ì§€ëŠ¥ìœ¼ë¡œ, í™˜ê²½ì„ ì¸ì‹í•œë‹¤.\"\n",
        "\n",
        "# 4. GPT í‰ê°€ í”„ë¡¬í”„íŠ¸ (í•œê¸€ ë²„ì „)\n",
        "prompt = f\"\"\"\n",
        "ë‹¹ì‹ ì€ í‰ê°€ìì…ë‹ˆë‹¤. ë‹¤ìŒ ë‘ ìš”ì•½ì„ ë¹„êµí•´ ì£¼ì„¸ìš”.\n",
        "\n",
        "ğŸ“Œ ì°¸ì¡° ìš”ì•½:\n",
        "{reference_summary}\n",
        "\n",
        "ğŸ“Œ ëª¨ë¸ ìš”ì•½:\n",
        "{model_summary}\n",
        "\n",
        "í‰ê°€ ê¸°ì¤€ (0~5ì ):\n",
        "- 5ì  = ì™„ë²½í•˜ê²Œ ì¼ì¹˜\n",
        "- 4ì  = ê±°ì˜ ì¼ì¹˜í•˜ë‚˜ ì‚¬ì†Œí•œ ì°¨ì´ ìˆìŒ\n",
        "- 3ì  = ë¶€ë¶„ì ìœ¼ë¡œ ë§ì§€ë§Œ ì¤‘ìš”í•œ ì°¨ì´ê°€ ìˆìŒ\n",
        "- 2ì  = ëŒ€ë¶€ë¶„ í‹€ë ¸ì§€ë§Œ ì¼ë¶€ ê´€ë ¨ì„± ìˆìŒ\n",
        "- 1ì  = ê±°ì˜ í‹€ë¦¼\n",
        "- 0ì  = ì „í˜€ ê´€ë ¨ ì—†ìŒ\n",
        "\n",
        "ì¶œë ¥ í˜•ì‹:\n",
        "ì ìˆ˜: X/5\n",
        "ì´ìœ : ê°„ë‹¨í•œ ì„¤ëª…\n",
        "\"\"\"\n",
        "\n",
        "# 5. GPT API í˜¸ì¶œ\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"ğŸ” GPT í‰ê°€ ê²°ê³¼:\")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
