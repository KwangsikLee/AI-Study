{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "sRTaJlkybmr_",
        "outputId": "36f26816-dd81-47e1-d9ea-ed583a8fd84a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sp_uni_103.model\",\n          \"sp_bpe_103.model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\ucc57\\uc9c0\\ud53c\\ud2f0\\uac00 \\uc2e0\\uc870\\uc5b4\\uc640 \\uc904\\uc784\\ub9d0\\uc744 \\uc798 \\ucc98\\ub9ac\\ud558\\ub294\\uc9c0 \\ud14c\\uc2a4\\ud2b8\\ud569\\ub2c8\\ub2e4!\",\n          \"\\uc624\\ub298 \\ube44 \\uc608\\ubcf4\\uac00 \\uc788\\uc9c0\\ub9cc \\uc57c\\uc678 \\uacf5\\uc5f0\\uc740 \\uc608\\uc815\\ub300\\ub85c \\uc9c4\\ud589\\ub429\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 29,\n        \"max\": 30,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          29,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1fdc3e99-e713-464c-bbcc-3f3e815ce1bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>text</th>\n",
              "      <th>len</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fdc3e99-e713-464c-bbcc-3f3e815ce1bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fdc3e99-e713-464c-bbcc-3f3e815ce1bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fdc3e99-e713-464c-bbcc-3f3e815ce1bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aa15a028-5863-4702-b99c-a663e8aa6818\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa15a028-5863-4702-b99c-a663e8aa6818')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aa15a028-5863-4702-b99c-a663e8aa6818 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              model                             text  len  \\\n",
              "1  sp_bpe_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "3  sp_uni_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "5  sp_bpe_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "7  sp_uni_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "0  sp_bpe_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "2  sp_uni_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "4  sp_bpe_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "6  sp_uni_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "\n",
              "                                              tokens  \n",
              "1  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "3  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "5  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "7  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "0  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  \n",
              "2  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  \n",
              "4  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  \n",
              "6  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- 설치 ---\n",
        "!pip -q install sentencepiece pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: corpus.txt\n",
            "  input_format: \n",
            "  model_prefix: sp_bpe_103\n",
            "  model_type: BPE\n",
            "  vocab_size: 103\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: corpus.txt\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 6 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=181\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=94\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 6 sentences.\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 6\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 38\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: sp_bpe_103.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: sp_bpe_103.vocab\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: corpus.txt\n",
            "  input_format: \n",
            "  model_prefix: sp_uni_103\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 103\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: corpus.txt\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 6 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=181\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=94\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 6 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=37\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 100 seed sentencepieces\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 6\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 38\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 38 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=95 obj=18.3229 num_tokens=169 num_tokens/piece=1.77895\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=95 obj=19.3627 num_tokens=169 num_tokens/piece=1.77895\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: sp_uni_103.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: sp_uni_103.vocab\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: corpus.txt\n",
            "  input_format: \n",
            "  model_prefix: sp_bpe_103\n",
            "  model_type: BPE\n",
            "  vocab_size: 103\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: corpus.txt\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 6 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=181\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=94\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 6 sentences.\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 6\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 38\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: sp_bpe_103.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: sp_bpe_103.vocab\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: corpus.txt\n",
            "  input_format: \n",
            "  model_prefix: sp_uni_103\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 103\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: corpus.txt\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 6 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=181\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=94\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 6 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=37\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 100 seed sentencepieces\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 6\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 38\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 38 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=95 obj=18.3229 num_tokens=169 num_tokens/piece=1.77895\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=95 obj=19.3627 num_tokens=169 num_tokens/piece=1.77895\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: sp_uni_103.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: sp_uni_103.vocab\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>text</th>\n",
              "      <th>len</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.</td>\n",
              "      <td>30</td>\n",
              "      <td>[▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sp_bpe_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sp_uni_103.model</td>\n",
              "      <td>챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!</td>\n",
              "      <td>29</td>\n",
              "      <td>[▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              model                             text  len  \\\n",
              "1  sp_bpe_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "3  sp_uni_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "5  sp_bpe_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "7  sp_uni_103.model  오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.   30   \n",
              "0  sp_bpe_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "2  sp_uni_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "4  sp_bpe_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "6  sp_uni_103.model  챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!   29   \n",
              "\n",
              "                                              tokens  \n",
              "1  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "3  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "5  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "7  [▁오, 늘, ▁, 비, ▁, 예, 보, 가, ▁, 있, 지, 만, ▁, 야, 외,...  \n",
              "0  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  \n",
              "2  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  \n",
              "4  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  \n",
              "6  [▁, 챗, 지, 피티, 가, ▁, 신, 조, 어, 와, ▁, 줄, 임말, 을, ▁...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "\n",
        "# --- 말뭉치 저장 ---\n",
        "SENTS = [\n",
        "    \"오늘은 비가 오지만, 축구 경기는 예정대로 진행됐다.\",\n",
        "    \"한글 토큰화는 조사와 어미 때문에 영어보다 까다롭다.\",\n",
        "    \"서브워드 방식은 OOV를 줄이는 데 유리하다.\",\n",
        "    \"신조어와 외래어가 많은 SNS 텍스트는 전처리가 중요하다.\",\n",
        "    \"도메인에 따라 최적 토크나이저가 달라진다.\",\n",
        "    \"SentencePiece는 공백을 특수문자로 다뤄 언어 중립적이다.\",\n",
        "]\n",
        "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in SENTS: f.write(s+\"\\n\")\n",
        "\n",
        "# --- 두 가지 모델 학습: BPE vs Unigram, vocab=800 & 3200 ---\n",
        "def train_sp(model_prefix, model_type, vocab_size=800):\n",
        "    spm.SentencePieceTrainer.Train(\n",
        "        input=\"corpus.txt\",\n",
        "        model_prefix=model_prefix,\n",
        "        model_type=model_type,   # \"bpe\" or \"unigram\"\n",
        "        vocab_size=vocab_size,\n",
        "        character_coverage=0.9995 # 한글 권장\n",
        "    )\n",
        "\n",
        "train_sp(\"sp_bpe_103\", \"bpe\", 103)\n",
        "train_sp(\"sp_uni_103\", \"unigram\", 103)\n",
        "train_sp(\"sp_bpe_103\", \"bpe\", 103)\n",
        "train_sp(\"sp_uni_103\", \"unigram\", 103)\n",
        "\n",
        "\n",
        "def analyze(model_file, samples):\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.load(model_file)\n",
        "    rows = []\n",
        "    for s in samples:\n",
        "        toks = sp.EncodeAsPieces(s)\n",
        "        rows.append({\"model\": model_file, \"text\": s, \"len\": len(toks), \"tokens\": toks[:25]})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "samples = [\n",
        "    \"챗지피티가 신조어와 줄임말을 잘 처리하는지 테스트합니다!\",\n",
        "    \"오늘 비 예보가 있지만 야외 공연은 예정대로 진행됩니다.\",\n",
        "]\n",
        "df = pd.concat([\n",
        "    analyze(\"sp_bpe_103.model\", samples),\n",
        "    analyze(\"sp_uni_103.model\", samples),\n",
        "    analyze(\"sp_bpe_103.model\", samples),\n",
        "    analyze(\"sp_uni_103.model\", samples),\n",
        "], ignore_index=True)\n",
        "\n",
        "display(df.sort_values([\"text\",\"len\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
