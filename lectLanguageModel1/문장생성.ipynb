{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcoxQlWUZo1T",
        "outputId": "28e01600-3f5a-49bd-e570-7194099731c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# [1] 준비: PyTorch 설치\n",
        "!pip install torch --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz5euKqAULHW",
        "outputId": "634d9904-9ecd-4990-c7f5-412b4e3ba5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['오늘도', '좋은', '하루']\n",
            "['좋은', '하루', '되세요']\n",
            "['행복은', '마음속에', '있어요']\n",
            "['내일은', '더', '나아질']\n",
            "['더', '나아질', '거예요']\n",
            "['희망은', '포기하지', '않는']\n",
            "['포기하지', '않는', '마음입니다']\n",
            "['슬픔은', '곧', '지나갈']\n",
            "['곧', '지나갈', '거예요']\n",
            "['사랑은', '모든', '것을']\n",
            "['모든', '것을', '이겨냅니다']\n",
            "['지금', '이', '순간을']\n",
            "['이', '순간을', '소중히']\n",
            "['순간을', '소중히', '하세요']\n",
            "['용기는', '두려움을', '이기는']\n",
            "['두려움을', '이기는', '힘입니다']\n",
            "['고마운', '마음을', '잊지']\n",
            "['마음을', '잊지', '마세요']\n",
            "['친구는', '소중한', '보물입니다']\n",
            "torch.Size([19, 2])\n",
            "Epoch 50: loss=0.0125\n",
            "Epoch 100: loss=0.0036\n",
            "Epoch 150: loss=0.0022\n",
            "Epoch 200: loss=0.0015\n",
            "Epoch 250: loss=0.0011\n",
            "Epoch 300: loss=0.0009\n",
            "생성 예시: 오늘도 좋은 하루 되세요 힘입니다 보물입니다 거예요\n",
            "생성 예시: 희망은 포기하지 않는 마음입니다 마음입니다 되세요 힘입니다\n",
            "생성 예시: 고마운 마음을 잊지 마세요 마세요 않는 마음입니다\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# [2] 한글 데이터셋 예시 (직접 가사, 명언 등 추가 가능)\n",
        "corpus = [\n",
        "    \"오늘도 좋은 하루 되세요\",\n",
        "    \"행복은 마음속에 있어요\",\n",
        "    \"내일은 더 나아질 거예요\",\n",
        "    \"희망은 포기하지 않는 마음입니다\",\n",
        "    \"슬픔은 곧 지나갈 거예요\",\n",
        "    \"사랑은 모든 것을 이겨냅니다\",\n",
        "    \"지금 이 순간을 소중히 하세요\",\n",
        "    \"용기는 두려움을 이기는 힘입니다\",\n",
        "    \"고마운 마음을 잊지 마세요\",\n",
        "    \"친구는 소중한 보물입니다\"\n",
        "]\n",
        "text = ' '.join(corpus)\n",
        "words = list(set(text.split()))\n",
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "# [3] 시퀀스 데이터 생성 (2-gram 기준)\n",
        "seq_length = 2\n",
        "sequences = []\n",
        "for sent in corpus:\n",
        "    tokens = sent.split()\n",
        "    for i in range(len(tokens) - seq_length):\n",
        "        seq = tokens[i:i+seq_length+1]\n",
        "        print(seq)\n",
        "        sequences.append([word2idx[w] for w in seq])\n",
        "\n",
        "import torch\n",
        "X = [s[:-1] for s in sequences]\n",
        "y = [s[-1] for s in sequences]\n",
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "# [4] LSTM 언어모델 정의\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, emb_size)\n",
        "        self.lstm = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        _, (h, _) = self.lstm(x)\n",
        "        out = self.fc(h.squeeze(0))\n",
        "        return out\n",
        "\n",
        "# [5] 모델 학습\n",
        "model = LSTMModel(len(words), 16, 32)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(300):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(X)\n",
        "    loss = loss_fn(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch+1}: loss={loss.item():.4f}\")\n",
        "\n",
        "# [6] 문장 생성 함수\n",
        "def generate(seed_text, max_len=5):\n",
        "    tokens = seed_text.split()\n",
        "    for _ in range(max_len):\n",
        "        seq = [word2idx.get(w, 0) for w in tokens[-2:]]\n",
        "        inp = torch.tensor([seq])\n",
        "        out = model(inp)\n",
        "        pred = out.argmax().item()\n",
        "        next_word = idx2word[pred]\n",
        "        tokens.append(next_word)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# [7] 문장 생성 예시\n",
        "print(\"생성 예시:\", generate(\"오늘도 좋은\"))\n",
        "print(\"생성 예시:\", generate(\"희망은 포기하지\"))\n",
        "print(\"생성 예시:\", generate(\"고마운 마음을\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
