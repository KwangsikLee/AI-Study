{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc1E90j88uCu",
        "outputId": "da8242d2-d52c-4de2-9eec-d31f4bd86f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# OpenAI API 클라이언트 생성\n",
        "API_KEY = userdata.get('api_key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Few-shot : 단 몇 개의 예시(examples)를 프롬프트(지시문)에 포함하여 제공하는 방법(In-context Learning)\n",
        "\n",
        "| 개념              | 설명                                                                 | 예시 (감정 분석) |\n",
        "|-------------------|----------------------------------------------------------------------|------------------|\n",
        "| **Zero-shot (제로샷)** | 예시 없이, 오직 지시만으로 작업을 요청. 모델의 기존 지식에 전적으로 의존. | \"이 문장은 긍정이야 부정이야?\" |\n",
        "| **One-shot (원샷)**    | 단 하나의 예시를 제공. 원하는 출력 형식을 명확히 할 때 유용.            | 입력: \"배송 빨라요.\" -> 긍정<br>입력: \"별로네요.\" -> ? |\n",
        "| **Few-shot (퓨샷)**    | 몇 개(2~5개)의 예시를 제공. 더 복잡한 패턴이나 뉘앙스를 학습시키기에 효과적. | (위의 구체적인 예시와 동일) |\n",
        "| **Fine-tuning (파인튜닝)** | 수백~수천 개 이상의 많은 데이터를 사용해 모델의 가중치(weights)를 직접 업데이트. 모델을 특정 작업에 깊게 전문화시키는 과정. | 감정분석 데이터셋으로 모델을 재훈련 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W2sRglG8vjW",
        "outputId": "fc22790b-983a-420c-ad29-2ddcf6cadd2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Zero-shot 결과:\n",
            "감정: 긍정\n",
            "\n",
            "==================================================\n",
            "\n",
            " Few-shot 결과:\n",
            "긍정\n",
            "\n",
            "==================================================\n",
            "\n",
            " Chain of Thought 결과:\n",
            "문제를 단계별로 풀어보겠습니다.\n",
            "\n",
            "### 1단계: 문제 이해\n",
            "사과와 배가 주어져 있으며, 사과를 친구에게 주고 배를 먹는 상황입니다. 남은 과일의 개수를 구하는 것이 목표입니다.\n",
            "\n",
            "### 2단계: 필요한 정보 파악\n",
            "- 처음 사과의 개수: 5개\n",
            "- 처음 배의 개수: 3개\n",
            "- 친구에게 준 사과의 개수: 2개\n",
            "- 먹은 배의 개수: 1개\n",
            "\n",
            "### 3단계: 계산 과정\n",
            "1. 사과의 남은 개수 계산:\n",
            "   - 처음 사과: 5개\n",
            "   - 친구에게 준 사과: 2개\n",
            "   - 남은 사과 = 5 - 2 = 3개\n",
            "\n",
            "2. 배의 남은 개수 계산:\n",
            "   - 처음 배: 3개\n",
            "   - 먹은 배: 1개\n",
            "   - 남은 배 = 3 - 1 = 2개\n",
            "\n",
            "3. 남은 과일의 총 개수 계산:\n",
            "   - 남은 사과: 3개\n",
            "   - 남은 배: 2개\n",
            "   - 남은 과일의 총 개수 = 3 + 2 = 5개\n",
            "\n",
            "### 4단계: 최종 답\n",
            "남은 과일은 총 5개입니다.\n"
          ]
        }
      ],
      "source": [
        "class PromptEngineering:\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(api_key=API_KEY)  # <- 본인 API 키 입력\n",
        "\n",
        "    def zero_shot(self, text):\n",
        "        \"\"\"Zero-shot 분류 예제\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        다음 텍스트의 감정을 분석하세요.\n",
        "\n",
        "        텍스트: {text}\n",
        "        감정 (긍정/부정/중립):\n",
        "        \"\"\"\n",
        "        return self._call_api(prompt)\n",
        "\n",
        "    def few_shot(self, text):\n",
        "        \"\"\"Few-shot 학습 예제\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        다음 예시를 참고하여 텍스트를 분류하세요.\n",
        "\n",
        "        예시 1: \"오늘 날씨가 정말 좋네요!\" → 긍정\n",
        "        예시 2: \"서비스가 너무 실망스러웠어요.\" → 부정\n",
        "        예시 3: \"평범한 하루였습니다.\" → 중립\n",
        "\n",
        "        텍스트: {text}\n",
        "        분류:\n",
        "        \"\"\"\n",
        "        return self._call_api(prompt)\n",
        "\n",
        "    def chain_of_thought(self, problem):\n",
        "        \"\"\"Chain of Thought 추론 예제\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        다음 문제를 단계별로 풀어주세요.\n",
        "\n",
        "        문제: {problem}\n",
        "\n",
        "        풀이 과정:\n",
        "        1단계: 문제 이해\n",
        "        2단계: 필요한 정보 파악\n",
        "        3단계: 계산 과정\n",
        "        4단계: 최종 답\n",
        "        \"\"\"\n",
        "        return self._call_api(prompt)\n",
        "\n",
        "    def _call_api(self, prompt):\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# 테스트\n",
        "pe = PromptEngineering()\n",
        "\n",
        "print(\" Zero-shot 결과:\")\n",
        "print(pe.zero_shot(\"이 제품 정말 마음에 들어요!\"))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\" Few-shot 결과:\")\n",
        "print(pe.few_shot(\"가격대비 괜찮은 것 같아요\"))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\" Chain of Thought 결과:\")\n",
        "print(pe.chain_of_thought(\"사과 5개와 배 3개가 있습니다. 친구에게 사과 2개를 주고, 배 1개를 먹었다면 남은 과일은 몇 개인가요?\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
