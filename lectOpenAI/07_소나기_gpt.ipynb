{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rYAmnYabWDw"
      },
      "outputs": [],
      "source": [
        "# ==================================\n",
        "# 1) 설치\n",
        "# ==================================\n",
        "!pip install -q openai gradio dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5_Y6FzvbYmM"
      },
      "outputs": [],
      "source": [
        "# ==================================\n",
        "# 2) 라이브러리 임포트\n",
        "# ==================================\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API 클라이언트 생성\n",
        "API_KEY = os.getenv(\"API_KEY\")\n",
        "\n",
        "# OpenAI API 클라이언트 생성\n",
        "client = OpenAI(api_key=API_KEY)  # <- 본인 API 키 입력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "MbsMykrNbSUT",
        "outputId": "ed8a2e29-f982-486d-9ebb-02e385693aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1f9a74a78a4816345f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://1f9a74a78a4816345f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# ==================================\n",
        "# 3) 소설 파일 불러오기\n",
        "# ==================================\n",
        "with open(\"/content/소나기.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    sonagi_text = f.read()\n",
        "\n",
        "# ==================================\n",
        "# 4) GPT 요약 함수\n",
        "# ==================================\n",
        "def summarize_story():\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"너는 한국 문학 작품을 요약하는 전문가다.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"다음 소설 '소나기'를 5문단 이내로 요약해줘.\\n\\n{sonagi_text}\"}\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# ==================================\n",
        "# 5) GPT 질의응답 함수\n",
        "# ==================================\n",
        "def qa_story(question):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"너는 한국 소설 전문가다. 반드시 소설 '소나기' 본문 내용을 근거로 답해야 한다.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"소설 '소나기' 내용:\\n{sonagi_text}\\n\\n질문: {question}\"}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# ==================================\n",
        "# 6) Gradio 인터페이스\n",
        "# ==================================\n",
        "with gr.Blocks(title=\"소나기 요약 & Q&A\") as demo:\n",
        "    gr.Markdown(\"##  소나기 (황순원) - 요약 & 질의응답\\nGPT API를 이용하여 소설을 요약하고 자유롭게 질문할 수 있습니다.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            summary_btn = gr.Button(\" 소설 요약 보기\")\n",
        "            summary_output = gr.Textbox(lines=12, label=\"소설 요약\", interactive=False)\n",
        "\n",
        "        with gr.Column():\n",
        "            question_input = gr.Textbox(label=\"질문 입력\", placeholder=\"예: 소녀가 병에 걸린 이유는 무엇인가?\")\n",
        "            answer_output = gr.Textbox(lines=6, label=\"답변\", interactive=False)\n",
        "            qa_btn = gr.Button(\"질문하기\")\n",
        "\n",
        "    # 이벤트 연결\n",
        "    summary_btn.click(fn=summarize_story, inputs=None, outputs=summary_output)\n",
        "    qa_btn.click(fn=qa_story, inputs=question_input, outputs=answer_output)\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
