{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9PsUa1lhi1lV",
        "outputId": "f9c3d1de-5536-45d7-c8ed-12d426c04147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipython-input-4060551584.py:326: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 51200, 'bos_token_id': 51200, 'pad_token_id': 51200}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,179,648 || all params: 126,345,984 || trainable%: 0.9337\n",
            "[증강] 원본 21 → 증강 후 84 샘플\n",
            "샘플 5개 미리보기:\n",
            "- 한 줄 요약: 연준 발표 이후 주식시장이 상승했다.  ///  연준 발표 이후 주가가 상승했다.\n",
            "- 한 줄 요약: 연준 발표 이후 주식시장이 상승했다. (명확하게)  ///  연준 발표 이후 주가가 상승했다.\n",
            "- 규칙: 한 줄 요약: 연준 발표 이후 주식시장이 상승했다.  ///  연준 발표 이후 주가가 상승했다.\n",
            "- 요청: 한 문장 요약: 연준 발표 이후 주식시장이 상승했다.  ///  연준 발표 이후 주가가 상승했다.\n",
            "- 한 줄 요약(이모지 금지, 25자 이내): 비가 오고 교통 혼잡이 심해졌다.  ///  비로 인해 교통 혼잡이 심해졌다.\n",
            "학습 시작...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='380' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [380/380 00:42, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.810000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.301100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.012600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.929400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.860500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 종료.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저장: ./lora_adapter_ko_sft_aug\n",
            "\n",
            "=== 데모 ===\n",
            "Q: 한 줄 요약: 배터리 수명이 길어 사용자 만족도가 높아졌다.\n",
            "A: {\"배터리 수명\"}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\n",
            "----------------------------------------\n",
            "Q: 정중한 메일 시작 문장: 일정 재조율 요청\n",
            "A: 안녕하세요, 일정 관련하여 부득이하게 연장을 요청드리고자 연락드립니다.00139<unk>hanmail.com에서 확인할 수 있습니다.00139<unk>00139<unk>00139<unk>00139<unk>00139<unk>00139<unk>00139<unk>00139<unk>00139<unk>00139<unk>00139<unk>0013\n",
            "----------------------------------------\n",
            "Q: 핵심 키워드 3개: 신규 기능 출시로 사용자 유입이 증가했다.\n",
            "A: • 신규 기능 출시로 사용자 유입이 증가했다.</d> #201809139 #미세먼지 #초미세먼지 #초미세먼지종말론 #초미세먼지종말론 #초미세먼지정체성 #초미세먼지정체성폭포틱한정도로 인해 성능 저\n",
            "----------------------------------------\n",
            "Q: JSON 형식으로 요약(키: title, sentiment): '배송 지연 이슈가 사라져 평점이 올랐다.'\n",
            "A: {\"title\":\"배송 지연 이슈가 사라져 평점이 상승했다.}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\n",
            "----------------------------------------\n",
            "Q: 요약(한 문장): 서버 과부하로 장애 발생, 임시 확장 적용.\n",
            "A: {\"positive\":\"positive\":\"positive\"}¶{\"positive\"}¶{\"positive\"}¶{\"positive\"}¶{\"positive\"}¶{\"positive\"}¶{\"positive\"}¶{\"p\n",
            "----------------------------------------\n",
            "Q: 불릿 세 개로 정리: 업무 집중력을 높이는 실천 팁\n",
            "A: • 방해 요소 제거\n",
            "• 짧은 목표 설정\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한 휴식\n",
            "• 일정한\n",
            "----------------------------------------\n",
            "Q: 문장을 공손체로 바꾸기: 회의 일정 조율 부탁드립니다.\n",
            "A: 안녕하세요, 회의 일정 관련하여 가능한 시간을 여쭙고자 연락드립니다.¶안녕하세요, 회의 일정 관련하여 가능한 시간을 여쭙고자 연락드립니다.¶안녕하세요, 회의 일정 관련하여 가능한 시간을 여쭙고자 연락드립니다.¶안녕하세요, 회의 일정 관련하여 가능한 시간을 여쭙고자 연락드립니다.¶안녕하세요, 회의 일정 관련하여\n",
            "----------------------------------------\n",
            "Q: 한 줄 정의: 과소적합.\n",
            "A: 과소적합은 학습 데이터에만 지나치게 맞춰져 새로운 데이터에서 성능이 떨어지는 현상이다.¶과소적합은 데이터에만 지나치게 맞춰져 성능이 떨어지는 현상이다.¶과소적합은 데이터에만 지나치게 맞춰져 성능이 떨어지는 현상이다.¶과소적합은 데이터에만 지나치게 맞춰져 성능이 떨어지는 현상이다.¶과소적합은 데이터에만 지나치게 맞춰져 성능이 떨어지는 현상이다.¶과\n",
            "----------------------------------------\n",
            "Q: 감정 판정(긍/부정): '포장이 엉망이라 실망스러웠다.'\n",
            "A: 부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶부정적으로 성능 저하가 발생한다.¶\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# LoRA fine-tuning (Korean SFT)\n",
        "# ================================\n",
        "!pip -q install -U transformers peft accelerate torch\n",
        "\n",
        "import os, random, re, json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, set_seed\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# (중복 방어) W&B 비활성화\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
        "\n",
        "# 1) 기본 설정\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "rng = random.Random(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# 2) 모델/토크나이저\n",
        "# ── 한국어 품질 권장: KoGPT2\n",
        "BASE_MODEL = \"skt/kogpt2-base-v2\"\n",
        "# 필요 시 distilgpt2로 바꾸실 수 있어요(한국어 성능은 낮을 수 있음):\n",
        "# BASE_MODEL = \"distilgpt2\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "    tok.pad_token_id = tok.eos_token_id\n",
        "\n",
        "# 템플릿 태그(토큰 경계 안정)\n",
        "INST_TAG = \"### 지시문:\"\n",
        "RESP_TAG = \"### 응답:\"\n",
        "tok.add_special_tokens({\"additional_special_tokens\":[INST_TAG, RESP_TAG]})\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL)\n",
        "model.resize_token_embeddings(len(tok))\n",
        "model.to(device)\n",
        "\n",
        "# 3) LoRA 설정 (GPT-2 계열 핵심 선형층만)\n",
        "#   - c_attn : Q/K/V 합성 선형층\n",
        "#   - c_proj : 어텐션/MLP 출력 선형층\n",
        "#   - c_fc   : MLP 확장 선형층(mlp.c_fc를 넓게 매칭)\n",
        "lora_cfg = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    inference_mode=False,\n",
        "    r=8, lora_alpha=16, lora_dropout=0.05,\n",
        "    target_modules=[\"c_attn\",\"c_proj\",\"c_fc\"]\n",
        ")\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# 4) 기본 한국어 지시문/응답 페어 (작지만 폭넓게)\n",
        "pairs = [\n",
        "    # 요약/한줄요약\n",
        "    (\"한 줄 요약: 연준 발표 이후 주식시장이 상승했다.\", \"연준 발표 이후 주가가 상승했다.\"),\n",
        "    (\"한 줄 요약(이모지 금지, 25자 이내): 비가 오고 교통 혼잡이 심해졌다.\", \"비로 인해 교통 혼잡이 심해졌다.\"),\n",
        "\n",
        "    # 형식/톤 변환\n",
        "    (\"메일 첫 문장(공손체): 회의 일정 조율을 정중히 요청\", \"안녕하세요. 회의 일정 관련하여 가능한 시간을 여쭙고자 연락드립니다.\"),\n",
        "    (\"문장을 더 공손하게: 내일까지 자료 주세요.\", \"번거로우시겠지만 내일까지 자료를 공유해 주실 수 있을까요?\"),\n",
        "    (\"반말로 바꾸기: 오늘 일정 확인 부탁드립니다.\", \"오늘 일정 확인해줘.\"),\n",
        "    # 키워드/추출\n",
        "    (\"키워드 3개 추출: 인공지능이 의료 영상 판독을 보조해 정확도를 높였다.\", \"인공지능, 의료 영상, 정확도\"),\n",
        "    (\"해시태그 3개 생성: 여름철 수분 섭취의 중요성\", \"#여름건강 #수분섭취 #열사병예방\"),\n",
        "    # 구조화(JSON)\n",
        "    (\"JSON으로 요약(키: title, sentiment): '서비스 개선 공지에 고객 반응이 대체로 긍정적이다.'\",\n",
        "     '{\"title\":\"서비스 개선 공지 반응\",\"sentiment\":\"positive\"}'),\n",
        "    (\"항목별 요약(JSON: pros, cons): '배터리 오래가나 무게가 조금 무겁다.'\",\n",
        "     '{\"pros\":[\"배터리 오래감\"],\"cons\":[\"무게가 다소 무거움\"]}'),\n",
        "    # 규칙/제약\n",
        "    (\"규칙: 한 문장, 마침표로 끝내기 — 딥러닝을 정의해줘.\", \"딥러닝은 다층 신경망으로 복잡한 패턴을 학습하는 기계학습 기법이다.\"),\n",
        "    (\"불릿 3개로 정리: 집중력을 높이는 방법\", \"• 방해 요소 제거\\n• 짧은 목표 설정\\n• 일정한 휴식\"),\n",
        "    # 설명/정의\n",
        "    (\"한 문장 정의: 머신러닝.\", \"머신러닝은 데이터에서 패턴을 학습해 예측을 수행하는 기술이다.\"),\n",
        "    (\"초보자에게 설명: 과적합이 뭐야?\", \"과적합은 학습 데이터에만 지나치게 맞춰져 새로운 데이터에서 성능이 떨어지는 현상이다.\"),\n",
        "    # 분류/판정(간단)\n",
        "    (\"감정 분류(긍/부정 중 하나): '이 제품 정말 마음에 든다.'\", \"긍정\"),\n",
        "    (\"감정 분류(긍/부정 중 하나): '배송이 너무 느려서 실망했다.'\", \"부정\"),\n",
        "    # 변환/요청\n",
        "    (\"문장을 더 간결하게: 본 건과 관련하여 검토 결과를 전달드립니다.\", \"관련 검토 결과를 전달드립니다.\"),\n",
        "    (\"숫자만 추출: 주문번호 A-001-39\", \"00139\"),\n",
        "    # 일정/비즈니스\n",
        "    (\"회의 아젠다 3개 제안(한 줄식): 온라인 세미나 준비 회의\", \"목표 확인\\n역할 분담\\n타임라인 확정\"),\n",
        "    (\"납기 연장 요청 메일 첫 문장(공손체, 한 문장):\", \"안녕하세요, 납기 일정 관련하여 부득이하게 연장을 요청드리고자 연락드립니다.\"),\n",
        "    # 스타일/재구성\n",
        "    (\"문장을 더 명확하게: 데이터 처리 속도가 부족하다.\", \"데이터 처리 속도가 느려 성능 저하가 발생한다.\"),\n",
        "    (\"두 문장을 한 문장으로: 모델은 정확하지만 느리다. 배치 크기를 줄였다.\", \"정확하지만 느린 모델을 개선하기 위해 배치 크기를 줄였다.\"),\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# 4-1) 자동 증강 모듈\n",
        "# ---------------------------\n",
        "# 안전을 위해 \"응답이 그대로 유효\"한 형태의 지시문 변형만 수행합니다.\n",
        "SYNSETS = [\n",
        "    # 요약 계열\n",
        "    (r\"한 줄 요약\", [\"한 문장 요약\", \"한 줄로 요약\", \"요약(한 문장)\"]),\n",
        "    (r\"\\(이모지 금지, 25자 이내\\)\", [\"(이모지 없이, 25자 이하)\", \"(25자 이내, 이모지 금지)\"]),\n",
        "\n",
        "    # 톤/형식\n",
        "    (r\"메일 첫 문장\\(공손체\\)\", [\"정중한 메일 시작 문장\", \"공손한 메일 첫 문장\", \"공손체 메일 서두\"]),\n",
        "    (r\"문장을 더 공손하게\", [\"문장을 정중하게 표현\", \"문장을 공손체로 바꾸기\", \"더 공손한 표현으로\"]),\n",
        "    (r\"반말로 바꾸기\", [\"반말로 변경\", \"반말체로 바꾸기\", \"반말 표현으로\"]),\n",
        "    # 추출/구조화\n",
        "    (r\"키워드 3개 추출\", [\"핵심어 3개 뽑기\", \"키워드 세 가지\", \"핵심 키워드 3개\"]),\n",
        "    (r\"해시태그 3개 생성\", [\"해시태그 세 개 생성\", \"해시태그 3개 추천\"]),\n",
        "    (r\"JSON으로 요약\", [\"JSON 형식으로 요약\", \"요약(JSON 포맷)\"]),\n",
        "    (r\"항목별 요약\", [\"항목별 정리\", \"카테고리별 요약\"]),\n",
        "    # 규칙/제약\n",
        "    (r\"불릿 3개로 정리\", [\"불릿 세 개로 정리\", \"세 줄 불릿으로 정리\"]),\n",
        "    (r\"규칙: 한 문장, 마침표로 끝내기\", [\"규칙: 한 문장으로, 마침표 필수\", \"규칙: 한 문장·마침표\"]),\n",
        "    # 정의/설명\n",
        "    (r\"한 문장 정의\", [\"한 줄 정의\", \"한 문장으로 정의\"]),\n",
        "    (r\"초보자에게 설명\", [\"처음 배우는 사람에게 설명\", \"입문자에게 설명\"]),\n",
        "    # 분류\n",
        "    (r\"감정 분류\\(긍/부정 중 하나\\)\", [\"감정 판정(긍/부정)\", \"감정 분류(긍정/부정)\"]),\n",
        "    # 변환\n",
        "    (r\"문장을 더 간결하게\", [\"문장을 간결하게\", \"간결한 문장으로 바꾸기\"]),\n",
        "    (r\"숫자만 추출\", [\"숫자만 남기기\", \"숫자만 출력하기\"]),\n",
        "    # 일정/비즈니스\n",
        "    (r\"회의 아젠다 3개 제안\\(한 줄식\\)\", [\"회의 아젠다 3가지(한 줄씩)\", \"회의 주제 3개(한 줄씩)\"]),\n",
        "    (r\"납기 연장 요청 메일 첫 문장\\(공손체, 한 문장\\)\", [\"납기 연장 요청(공손체, 한 문장)\", \"납기 일정 연장 요청(공손체)\"]),\n",
        "    # 스타일\n",
        "    (r\"문장을 더 명확하게\", [\"문장을 명확하게\", \"더 명확한 문장으로\"]),\n",
        "    (r\"두 문장을 한 문장으로\", [\"두 문장을 합쳐 한 문장으로\", \"두 문장을 하나로\"]),\n",
        "]\n",
        "\n",
        "EMOJI_PATTERN = re.compile(\n",
        "    \"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    \"\\U0001F300-\\U0001F5FF\"    # symbols & pictographs\n",
        "    \"\\U0001F680-\\U0001F6FF\"    # transport & map\n",
        "    \"\\U0001F1E0-\\U0001F1FF\"    # flags (iOS)\n",
        "    \"]+\", flags=re.UNICODE\n",
        ")\n",
        "\n",
        "def has_emoji(s: str) -> bool:\n",
        "    return bool(EMOJI_PATTERN.search(s))\n",
        "\n",
        "def is_valid_json(s: str) -> bool:\n",
        "    try:\n",
        "        json.loads(s)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def bullets_count(s: str) -> int:\n",
        "    lines = [ln.strip() for ln in s.splitlines() if ln.strip()]\n",
        "    # •, -, * 를 불릿으로 인정\n",
        "    return sum(1 for ln in lines if ln.startswith(\"•\") or ln.startswith(\"-\") or ln.startswith(\"*\"))\n",
        "\n",
        "def digits_only(s: str) -> bool:\n",
        "    return bool(re.fullmatch(r\"[0-9]+\", s.strip()))\n",
        "\n",
        "def ends_with_period_one_sentence(s: str) -> bool:\n",
        "    # 매우 단순한 검증: 마침표로 끝나고 문장부호가 여러 번 안 나오는지\n",
        "    return s.strip().endswith(\".\")\n",
        "\n",
        "def enforce_constraints_if_any(instr: str, resp: str) -> bool:\n",
        "    \"\"\"지시문에 담긴 제약 조건을 응답이 만족하는지 간단히 검증.\"\"\"\n",
        "    # 이모지 금지\n",
        "    if \"이모지\" in instr and has_emoji(resp):\n",
        "        return False\n",
        "    # 글자 수 제한: '25자' / '25자 이내' 등 → 숫자 추출\n",
        "    m = re.search(r\"(\\d+)\\s*자\", instr)\n",
        "    if m:\n",
        "        limit = int(m.group(1))\n",
        "        if len(resp) > limit:\n",
        "            return False\n",
        "    # 불릿 3개\n",
        "    if (\"불릿 3\" in instr or \"불릿 세\" in instr) and bullets_count(resp) != 3:\n",
        "        return False\n",
        "    # JSON\n",
        "    if \"JSON\" in instr or \"Json\" in instr or \"json\" in instr:\n",
        "        if not is_valid_json(resp):\n",
        "            return False\n",
        "    # 숫자만\n",
        "    if \"숫자만\" in instr:\n",
        "        if not digits_only(resp):\n",
        "            return False\n",
        "    # 한 문장 + 마침표\n",
        "    if (\"한 문장\" in instr or \"한 문장으로\" in instr) and (\"마침표\" in instr or \"마침표로\" in instr):\n",
        "        if not ends_with_period_one_sentence(resp):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def paraphrase_one(instr: str) -> str:\n",
        "    \"\"\"사전 정의된 동의어 패턴 중 일부를 랜덤 적용하여 지시문을 변형.\"\"\"\n",
        "    out = instr\n",
        "    # 0~3개 랜덤 적용\n",
        "    n_apply = rng.randint(0, 3)\n",
        "    cand = rng.sample(SYNSETS, k=min(n_apply, len(SYNSETS)))\n",
        "    for pat, repls in cand:\n",
        "        if rng.random() < 0.7:  # 적용 확률\n",
        "            out = re.sub(pat, rng.choice(repls), out)\n",
        "    # 가벼운 접두/접미 변형\n",
        "    add_prefix = rng.choice([\"\", \"요청: \", \"지시: \", \"규칙: \"])\n",
        "    add_suffix = rng.choice([\"\", \"\", \"\", \" (간단히)\", \" (한 줄)\", \" (명확하게)\"])\n",
        "    out = f\"{add_prefix}{out}{add_suffix}\".strip()\n",
        "    return out\n",
        "\n",
        "def augment_pairs(pairs, per_src=3, max_trials=10):\n",
        "    \"\"\"각 (instr, resp)에 대해 의미를 해치지 않는 선에서 지시문을 per_src개 생성.\"\"\"\n",
        "    aug = []\n",
        "    for instr, resp in pairs:\n",
        "        seen = set([instr])\n",
        "        aug.append((instr, resp))  # 원본 포함\n",
        "        trials = 0\n",
        "        made = 0\n",
        "        while made < per_src and trials < max_trials:\n",
        "            trials += 1\n",
        "            cand = paraphrase_one(instr)\n",
        "            if cand in seen:\n",
        "                continue\n",
        "            # 응답은 동일하게 유지 가능한 변형만 사용 → 제약 검증 통과해야 채택\n",
        "            if enforce_constraints_if_any(cand, resp):\n",
        "                aug.append((cand, resp))\n",
        "                seen.add(cand)\n",
        "                made += 1\n",
        "    return aug\n",
        "\n",
        "# 증강 실행\n",
        "PER_SRC = 3  # 각 원본 지시문당 증강 개수(원본+3 = 4배)\n",
        "aug_pairs = augment_pairs(pairs, per_src=PER_SRC)\n",
        "\n",
        "print(f\"[증강] 원본 {len(pairs)} → 증강 후 {len(aug_pairs)} 샘플\")\n",
        "print(\"샘플 5개 미리보기:\")\n",
        "for i, (ins, out) in enumerate(aug_pairs[:5]):\n",
        "    print(f\"- {ins}  ///  {out}\")\n",
        "\n",
        "# 템플릿 결합 함수\n",
        "def ex(prompt, answer):\n",
        "    return f\"{INST_TAG}\\n{prompt}\\n\\n{RESP_TAG}\\n{answer}{tok.eos_token}\"\n",
        "\n",
        "# 텍스트화\n",
        "texts = [ex(p, a) for p, a in aug_pairs]\n",
        "\n",
        "# 데이터가 충분히 늘었으므로 REPEAT는 낮게 유지\n",
        "REPEAT = 10\n",
        "texts = texts * REPEAT\n",
        "\n",
        "# 5) 커스텀 데이터셋 (토큰화는 collator에서 배치로 처리)\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, texts): self.texts = texts\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i): return {\"text\": self.texts[i]}\n",
        "\n",
        "split = int(len(texts)*0.9)\n",
        "train_ds = TextOnlyDS(texts[:split])\n",
        "val_ds   = TextOnlyDS(texts[split:])\n",
        "\n",
        "# 6) Collator: 배치 토큰화 + \"응답만 로스\" 마스킹 + 안전 패딩\n",
        "RESP_TAG_WITH_NL = RESP_TAG + \"\\n\"\n",
        "resp_ids = tok(RESP_TAG_WITH_NL, add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "def find_subseq(seq, sub):\n",
        "    L, l = len(seq), len(sub)\n",
        "    for i in range(L - l + 1):\n",
        "        if seq[i:i+l] == sub:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "def response_only_collate(features, tokenizer=tok, max_length=384):\n",
        "    # 텍스트 배치 토큰화\n",
        "    texts = [f[\"text\"] for f in features]\n",
        "    enc = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
        "    input_ids = enc[\"input_ids\"]\n",
        "    attn = enc[\"attention_mask\"]\n",
        "\n",
        "    # labels 초기화(-100), \"응답:\" 이후만 정답 복사\n",
        "    labels = torch.full_like(input_ids, -100)\n",
        "    B = input_ids.size(0)\n",
        "    for i in range(B):\n",
        "        ids = input_ids[i].tolist()\n",
        "        pos = find_subseq(ids, resp_ids)\n",
        "        if pos != -1:\n",
        "            start = pos + len(resp_ids)\n",
        "            seq_len = int(attn[i].sum().item())  # pad 제외\n",
        "            start = min(start, seq_len)\n",
        "            labels[i, start:seq_len] = input_ids[i, start:seq_len]\n",
        "\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attn, \"labels\": labels}\n",
        "\n",
        "def collate(batch):\n",
        "    return response_only_collate(batch)\n",
        "\n",
        "# 7) 학습 인자 (버전 호환: 최신/구버전 자동 fallback)\n",
        "model.config.use_cache = False  # Trainer 경고 방지\n",
        "def make_args():\n",
        "    try:\n",
        "        return TrainingArguments(\n",
        "            output_dir=\"./out_lora\",\n",
        "            overwrite_output_dir=True,\n",
        "            num_train_epochs=4,\n",
        "            per_device_train_batch_size=4,\n",
        "            gradient_accumulation_steps=2,\n",
        "            learning_rate=1e-4,\n",
        "            lr_scheduler_type=\"cosine\",\n",
        "            weight_decay=0.0,\n",
        "            logging_steps=50,\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=200,\n",
        "            save_strategy=\"no\",\n",
        "            remove_unused_columns=False,\n",
        "            report_to=\"none\",\n",
        "            bf16=(torch.cuda.is_available() and getattr(torch.cuda, \"is_bf16_supported\", lambda: False)()),\n",
        "            fp16=(torch.cuda.is_available() and not getattr(torch.cuda, \"is_bf16_supported\", lambda: False)()),\n",
        "        )\n",
        "    except TypeError:\n",
        "        return TrainingArguments(\n",
        "            output_dir=\"./out_lora\",\n",
        "            overwrite_output_dir=True,\n",
        "            num_train_epochs=4,\n",
        "            per_device_train_batch_size=4,\n",
        "            gradient_accumulation_steps=2,\n",
        "            learning_rate=1e-4,\n",
        "            logging_steps=50,\n",
        "            remove_unused_columns=False,\n",
        "        )\n",
        "\n",
        "args = make_args()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model, args=args,\n",
        "    train_dataset=train_ds, eval_dataset=val_ds,\n",
        "    data_collator=collate, tokenizer=tok\n",
        ")\n",
        "\n",
        "print(\"학습 시작...\")\n",
        "trainer.train()\n",
        "print(\"학습 종료.\")\n",
        "\n",
        "# 8) 어댑터 저장\n",
        "save_dir = \"./lora_adapter_ko_sft_aug\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "model.save_pretrained(save_dir)\n",
        "tok.save_pretrained(save_dir)\n",
        "print(\"저장:\", save_dir)\n",
        "\n",
        "# 9) 추론 함수(학습 템플릿과 동일하게!)\n",
        "@torch.inference_mode()\n",
        "def generate_ko(prompt, max_new_tokens=80, temperature=0.7, top_p=0.9, do_sample=False):\n",
        "    model.eval()\n",
        "    prefix = f\"{INST_TAG}\\n{prompt}\\n\\n{RESP_TAG}\\n\"\n",
        "    inputs = tok(prefix, return_tensors=\"pt\").to(model.device)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample, temperature=temperature, top_p=top_p,\n",
        "        pad_token_id=tok.eos_token_id, eos_token_id=tok.eos_token_id\n",
        "    )\n",
        "    txt = tok.decode(out[0], skip_special_tokens=False)\n",
        "    return txt.split(RESP_TAG, 1)[-1].strip() if RESP_TAG in txt else txt.strip()\n",
        "\n",
        "print(\"\\n=== 데모 ===\")\n",
        "tests = [\n",
        "    # 학습 분포와 유사(일반화 체크)\n",
        "    \"한 줄 요약: 배터리 수명이 길어 사용자 만족도가 높아졌다.\",\n",
        "    \"정중한 메일 시작 문장: 일정 재조율 요청\",\n",
        "    \"핵심 키워드 3개: 신규 기능 출시로 사용자 유입이 증가했다.\",\n",
        "    \"JSON 형식으로 요약(키: title, sentiment): '배송 지연 이슈가 사라져 평점이 올랐다.'\",\n",
        "    # 새 변형(증강 전이 성능 체크)\n",
        "    \"요약(한 문장): 서버 과부하로 장애 발생, 임시 확장 적용.\",\n",
        "    \"불릿 세 개로 정리: 업무 집중력을 높이는 실천 팁\",\n",
        "    \"문장을 공손체로 바꾸기: 회의 일정 조율 부탁드립니다.\",\n",
        "    \"한 줄 정의: 과소적합.\",\n",
        "    \"감정 판정(긍/부정): '포장이 엉망이라 실망스러웠다.'\",\n",
        "]\n",
        "for p in tests:\n",
        "    print(\"Q:\", p)\n",
        "    print(\"A:\", generate_ko(p))\n",
        "    print(\"-\"*40)\n"
      ]
    }
  ]
}