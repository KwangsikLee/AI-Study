{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9DggwNWQ89Y",
        "outputId": "8c52cb37-ec67-4d8d-ecab-90a76bfb5ddd"
      },
      "outputs": [],
      "source": [
        "# Google Colab에서 실행하는 RAG 및 파인튜닝 코드\n",
        "\n",
        "# ============================\n",
        "# 1. 필요한 라이브러리 설치\n",
        "# ============================\n",
        "!pip install -q langchain langchain-community\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q chromadb\n",
        "!pip install -q transformers accelerate bitsandbytes\n",
        "!pip install -q peft datasets\n",
        "!pip install -q pypdf\n",
        "!pip install -q torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981,
          "referenced_widgets": [
            "a1931332cba44dce8b3eb97a54c17a9d",
            "b8541c14925c4235baba2807efa4f7e0",
            "8ee9fec3ed694adb9a422afb699a9644",
            "2508d6e1c0c84acdbd54a8dab50d3b77",
            "2aeb9dce35b347c0b48ba3de10a18f7f",
            "001233a9786047528cabb011ee6b7cef",
            "d51eca32a7d84f5096205377a6b89b83",
            "3cc405af45724c2bbb2e10b9b140ccd1",
            "ddb6447cca88420b9e6834e3a06a5569",
            "12bb97d5128a40a3a6ed1cf4955ea81c",
            "de1f6f9a1b87469ba85d18a8a009556b",
            "f5674897c3014f7ca771de8254cc5d55",
            "596f6e061fdc4853864c162bf2b1c314",
            "78761757cc08479f9ae22284c1bdd623",
            "ba6ee50e255742eb88e119008a415fa9",
            "a1e6480e80b5485b84024ac65e09c3df",
            "0388fb10e35945ffa4dda63029188a69",
            "1536a1a8aade444c9cbe7a5ea01e1b98",
            "290b6162d66e4aeca69aa67d9f0edd2b",
            "5465918d7ba74e8780424db3cbe25d57",
            "6b7f22e7c52d44c3a48a2fd8fe5303d0",
            "ae92f2a5a6ef4478a5d710f047f9b1a5",
            "f85dfe1de1724b568a1dccfe43f36bc1",
            "c8f7a5ea3428456c8400ba9007f8f497",
            "1375ab38ba1845c7a9d67472a180e210",
            "292ab210672548f69c2be6603d4e9cde",
            "c3a6e2fcf50345498b75e0092b6528bf",
            "ab130e864f774d98a949346de3af377f",
            "175c63ef40ec43e486c46ec85a237533",
            "60eac9e0eb8741c3a94cb826e68cd14b",
            "c95cd7f14c944b93a4717ed1978e0cc7",
            "63318d34f615456392904de7ea35ae06",
            "69eba4a3b2c941bababc2bf132c9a08f"
          ]
        },
        "id": "Syz-yuYnQ6o7",
        "outputId": "3e823255-39f5-40b5-ba2b-9ba73da3a017"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-83522d1d-9db4-42df-a65a-612636a2dae9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-83522d1d-9db4-42df-a65a-612636a2dae9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving SPRi AI Brief_8월호_산업동향_F.pdf to SPRi AI Brief_8월호_산업동향_F (4).pdf\n",
            "업로드된 파일: SPRi AI Brief_8월호_산업동향_F (4).pdf\n",
            "\n",
            "[1/5] 문서를 로드하고 처리합니다...\n",
            "문서를 127개의 청크로 분할했습니다.\n",
            "\n",
            "[2/5] 벡터 데이터베이스를 생성합니다...\n",
            "벡터 데이터베이스가 생성되었습니다.\n",
            "\n",
            "[3/5] RAG 시스템을 초기화합니다...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1931332cba44dce8b3eb97a54c17a9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[4/5] RAG 시스템을 테스트합니다...\n",
            "\n",
            "질문: AI 산업의 최신 동향은 무엇인가요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "답변: 1. [인공지능 스타트업 투자는 2021년 1분기](https://www.cbinsights.com/research/report/ai-startup-투자-2021/)\n",
            "2. [미국에서 대형 AI 스타트업에 대한 투자가 증가함에 따라 전문가들 사이에 관심이 높아지고 있다.] (https://nasa.gov/acquisition/firmware/radiation-and-data-technology-projects/us-approves-largest-alternative-artificial-intelligence-software-proje...\n",
            "\n",
            "질문: 오픈AI의 최근 소식은?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "답변: 아래 사이트를 확인하세요.\n",
            "https://www.openai.com/content/fulltext/20257/15570196_1d13b032e2c09?vType=rollout...\n",
            "\n",
            "질문: 구글 딥마인드의 연구 내용은?\n",
            "답변: GPT는 Generative Pre-trained Transformer의 약자로, 기존의 모든 언어 모델보다 더욱 발전된 모델입니다. GPT는 단어의 의미, 문법 및 관대한 해석 등을 학습할 수 있어서 다양한 분야에서 널리 사용됩니다. 예를 들어, 자연어 처리 및 기계 번역 분야에서 많은 성과를 내고 있습니다. 또한, 최근에는 인공지능 기반의 음성인식 소프트웨어도 출시되었습니다. 이러한 다양한 분야에서 GPT가 적용될 수 있는 가능성이 높아지면서 관심을 받고 있습니다....\n",
            "\n",
            "[5/5] 파인튜닝을 준비합니다...\n",
            "파인튜닝 데이터셋 크기: 88\n",
            "\n",
            "파인튜닝을 진행하시겠습니까? (y/n): y\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5674897c3014f7ca771de8254cc5d55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 3,670,016 || all params: 5,888,729,088 || trainable%: 0.0623\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f85dfe1de1724b568a1dccfe43f36bc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/88 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파인튜닝을 시작합니다...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [66/66 00:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.205500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파인튜닝이 완료되었습니다!\n",
            "\n",
            "파인튜닝이 완료되었습니다!\n",
            "\n",
            "모든 작업이 완료되었습니다!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# WandB 비활성화 (API 키 불필요)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader # Corrected import\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "# ============================\n",
        "# 2. 문서 로드 및 전처리\n",
        "# ============================\n",
        "\n",
        "def load_and_process_document(file_path):\n",
        "    \"\"\"PDF 문서를 로드하고 청크로 분할\"\"\"\n",
        "\n",
        "    # PDF 로더 사용\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # 텍스트 분할기 설정\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    # 문서를 청크로 분할\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "    print(f\"문서를 {len(chunks)}개의 청크로 분할했습니다.\")\n",
        "    return chunks\n",
        "\n",
        "# ============================\n",
        "# 3. 벡터 데이터베이스 구축\n",
        "# ============================\n",
        "\n",
        "def create_vector_database(chunks):\n",
        "    \"\"\"문서 청크를 임베딩하고 벡터 DB 생성\"\"\"\n",
        "\n",
        "    # 한국어 지원 임베딩 모델 사용\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"jhgan/ko-sroberta-multitask\",\n",
        "        model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'},\n",
        "        encode_kwargs={'normalize_embeddings': True}\n",
        "    )\n",
        "\n",
        "    # ChromaDB 벡터 스토어 생성\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=\"./chroma_db\"\n",
        "    )\n",
        "\n",
        "    print(\"벡터 데이터베이스가 생성되었습니다.\")\n",
        "    return vectorstore\n",
        "\n",
        "# ============================\n",
        "# 4. RAG 시스템 구현\n",
        "# ============================\n",
        "\n",
        "class SimpleRAG:\n",
        "    def __init__(self, vectorstore, model_name=\"beomi/KoAlpaca-Polyglot-5.8B\"):\n",
        "        self.vectorstore = vectorstore\n",
        "        self.retriever = vectorstore.as_retriever(\n",
        "            search_type=\"similarity\",\n",
        "            search_kwargs={\"k\": 3}\n",
        "        )\n",
        "\n",
        "        # 4비트 양자화 설정\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True\n",
        "        )\n",
        "\n",
        "        # 모델 로드 (메모리 효율적)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # 패딩 토큰 설정\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "    def retrieve_context(self, query):\n",
        "        \"\"\"질문과 관련된 문서 검색\"\"\"\n",
        "        docs = self.retriever.get_relevant_documents(query)\n",
        "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "        return context\n",
        "\n",
        "    def generate_answer(self, query, max_length=512):\n",
        "        \"\"\"컨텍스트를 활용한 답변 생성\"\"\"\n",
        "        # 관련 문서 검색\n",
        "        context = self.retrieve_context(query)\n",
        "\n",
        "        # 프롬프트 구성\n",
        "        prompt = f\"\"\"다음 문서를 참고하여 질문에 답변해주세요.\n",
        "\n",
        "문서:\n",
        "{context}\n",
        "\n",
        "질문: {query}\n",
        "\n",
        "답변:\"\"\"\n",
        "\n",
        "        # 토크나이징\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        # 답변 생성\n",
        "        with torch.no_grad():\n",
        "            # Filter out 'token_type_ids' if present\n",
        "            inputs_dict = {k: v for k, v in inputs.items() if k != 'token_type_ids'}\n",
        "            outputs = self.model.generate(\n",
        "                **inputs_dict,\n",
        "                max_new_tokens=max_length,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                top_p=0.9,\n",
        "                repetition_penalty=1.2\n",
        "            )\n",
        "\n",
        "        # 디코딩\n",
        "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        answer = answer.split(\"답변:\")[-1].strip()\n",
        "\n",
        "        return answer\n",
        "\n",
        "# ============================\n",
        "# 5. 파인튜닝 데이터셋 준비\n",
        "# ============================\n",
        "\n",
        "def prepare_finetuning_dataset(chunks):\n",
        "    \"\"\"문서 청크를 파인튜닝용 데이터셋으로 변환\"\"\"\n",
        "\n",
        "    dataset_list = []\n",
        "\n",
        "    for chunk in chunks[:100]:  # 메모리 제약으로 100개만 사용\n",
        "        text = chunk.page_content\n",
        "\n",
        "        # 간단한 Q&A 형식으로 변환\n",
        "        if len(text) > 50:\n",
        "            # 질문 생성 (간단한 예시)\n",
        "            question = \"다음 내용을 요약해주세요.\"\n",
        "            answer = text[:200] if len(text) > 200 else text\n",
        "\n",
        "            dataset_list.append({\n",
        "                \"instruction\": question,\n",
        "                \"input\": text,\n",
        "                \"output\": answer\n",
        "            })\n",
        "\n",
        "    # Dataset 객체로 변환\n",
        "    dataset = Dataset.from_list(dataset_list)\n",
        "\n",
        "    print(f\"파인튜닝 데이터셋 크기: {len(dataset)}\")\n",
        "    return dataset\n",
        "\n",
        "# ============================\n",
        "# 6. LoRA 파인튜닝\n",
        "# ============================\n",
        "\n",
        "def finetune_with_lora(model_name=\"beomi/KoAlpaca-Polyglot-5.8B\", dataset=None):\n",
        "    \"\"\"LoRA를 사용한 효율적인 파인튜닝\"\"\"\n",
        "\n",
        "    # 4비트 양자화 설정\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True\n",
        "    )\n",
        "\n",
        "    # 모델과 토크나이저 로드\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # LoRA 설정 - Adjusted target_modules for KoAlpaca\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,  # LoRA rank\n",
        "        lora_alpha=32,\n",
        "        target_modules=[\"query_key_value\"], # Corrected target modules\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.CAUSAL_LM\n",
        "    )\n",
        "\n",
        "    # LoRA 적용\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    # 데이터 전처리 함수\n",
        "    def preprocess_function(examples):\n",
        "        prompts = []\n",
        "        for inst, inp, out in zip(examples[\"instruction\"], examples[\"input\"], examples[\"output\"]):\n",
        "            prompt = f\"### 질문: {inst}\\n### 입력: {inp}\\n### 답변: {out}\"\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        model_inputs = tokenizer(\n",
        "            prompts,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        )\n",
        "        model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "        return model_inputs\n",
        "\n",
        "    # 데이터셋 전처리\n",
        "    tokenized_dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "        remove_columns=dataset.column_names\n",
        "    )\n",
        "\n",
        "    # 학습 설정\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./lora_model\",\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=100,\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"epoch\",\n",
        "        # Removed evaluation_strategy=\"no\"\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        push_to_hub=False,\n",
        "    )\n",
        "\n",
        "    # 데이터 콜레이터\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False\n",
        "    )\n",
        "\n",
        "    # 트레이너 생성\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # 학습 시작\n",
        "    print(\"파인튜닝을 시작합니다...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # 모델 저장\n",
        "    model.save_pretrained(\"./lora_model\")\n",
        "    tokenizer.save_pretrained(\"./lora_model\")\n",
        "\n",
        "    print(\"파인튜닝이 완료되었습니다!\")\n",
        "    return model, tokenizer\n",
        "\n",
        "# ============================\n",
        "# 7. 실행 코드\n",
        "# ============================\n",
        "\n",
        "def main():\n",
        "    # 파일 경로 설정 (Colab에 업로드한 PDF 파일 경로)\n",
        "    # 먼저 파일을 업로드하세요:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # 업로드된 파일 이름 확인\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "    print(f\"업로드된 파일: {file_path}\")\n",
        "\n",
        "    # 1. 문서 로드 및 처리\n",
        "    print(\"\\n[1/5] 문서를 로드하고 처리합니다...\")\n",
        "    chunks = load_and_process_document(file_path)\n",
        "\n",
        "    # 2. 벡터 데이터베이스 생성\n",
        "    print(\"\\n[2/5] 벡터 데이터베이스를 생성합니다...\")\n",
        "    vectorstore = create_vector_database(chunks)\n",
        "\n",
        "    # 3. RAG 시스템 초기화\n",
        "    print(\"\\n[3/5] RAG 시스템을 초기화합니다...\")\n",
        "    rag_system = SimpleRAG(vectorstore)\n",
        "\n",
        "    # 4. RAG 테스트\n",
        "    print(\"\\n[4/5] RAG 시스템을 테스트합니다...\")\n",
        "    test_queries = [\n",
        "        \"AI 산업의 최신 동향은 무엇인가요?\",\n",
        "        \"오픈AI의 최근 소식은?\",\n",
        "        \"구글 딥마인드의 연구 내용은?\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\n질문: {query}\")\n",
        "        answer = rag_system.generate_answer(query)\n",
        "        print(f\"답변: {answer[:300]}...\")  # 답변 일부만 출력\n",
        "\n",
        "    # 5. 파인튜닝 (선택사항 - 메모리가 충분한 경우)\n",
        "    print(\"\\n[5/5] 파인튜닝을 준비합니다...\")\n",
        "    dataset = prepare_finetuning_dataset(chunks)\n",
        "\n",
        "    # 파인튜닝 실행 (주의: 시간이 오래 걸릴 수 있음)\n",
        "    user_input = input(\"\\n파인튜닝을 진행하시겠습니까? (y/n): \")\n",
        "    if user_input.lower() == 'y':\n",
        "        model, tokenizer = finetune_with_lora(dataset=dataset)\n",
        "        print(\"\\n파인튜닝이 완료되었습니다!\")\n",
        "    else:\n",
        "        print(\"\\n파인튜닝을 건너뜁니다.\")\n",
        "\n",
        "    print(\"\\n모든 작업이 완료되었습니다!\")\n",
        "    return rag_system\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    rag_system = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bIiBF53iTSwH",
        "outputId": "4a51c41f-6ed4-457b-93b4-6c5ad29946c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 기존 rag_system을 사용합니다.\n",
            "🚀 Gradio 인터페이스를 시작합니다...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://11cdd8b3e94d19c6ac.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://11cdd8b3e94d19c6ac.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Gradio 인터페이스가 성공적으로 실행되었습니다!\n",
            "\n",
            "📌 사용 방법:\n",
            "1. 질문을 입력하거나 예시 질문을 선택하세요\n",
            "2. '답변 생성' 버튼을 클릭하거나 Enter를 누르세요\n",
            "3. 고급 설정에서 파라미터를 조정할 수 있습니다\n",
            "4. 대화 기록은 JSON 형식으로 내보낼 수 있습니다\n",
            "\n",
            "🔗 공유 링크를 통해 다른 사용자도 접속할 수 있습니다.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ====================================\n",
        "# 이전 셀에서 학습된 RAG 시스템을 활용한 Gradio 인터페이스\n",
        "# ====================================\n",
        "\n",
        "# Gradio 설치 (이미 설치되어 있으면 건너뜀)\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# ====================================\n",
        "# 1. 이전 셀의 rag_system 확인 및 래퍼 클래스 생성\n",
        "# ====================================\n",
        "\n",
        "# 이전 셀에서 생성된 rag_system이 있는지 확인\n",
        "try:\n",
        "    if 'rag_system' not in globals():\n",
        "        print(\"⚠️ rag_system이 없습니다. 새로 생성합니다...\")\n",
        "\n",
        "        # 기존 벡터 DB가 있으면 로드\n",
        "        if os.path.exists(\"./chroma_db\"):\n",
        "            vectorstore = Chroma(\n",
        "                persist_directory=\"./chroma_db\",\n",
        "                embedding_function=HuggingFaceEmbeddings(\n",
        "                    model_name=\"jhgan/ko-sroberta-multitask\",\n",
        "                    model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
        "                )\n",
        "            )\n",
        "            rag_system = SimpleRAG(vectorstore)\n",
        "            print(\"✅ 기존 벡터 DB를 사용하여 RAG 시스템을 재구성했습니다.\")\n",
        "        else:\n",
        "            print(\"❌ 벡터 DB가 없습니다. 먼저 문서를 처리해주세요.\")\n",
        "    else:\n",
        "        print(\"✅ 기존 rag_system을 사용합니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ 시스템 확인 중 오류: {e}\")\n",
        "\n",
        "# ====================================\n",
        "# 2. Gradio용 인터페이스 함수들\n",
        "# ====================================\n",
        "\n",
        "# 대화 기록 저장용\n",
        "conversation_history = []\n",
        "\n",
        "def process_question(question, temperature=0.7, max_tokens=512, use_context=True):\n",
        "    \"\"\"사용자 질문을 처리하고 답변 생성\"\"\"\n",
        "\n",
        "    if not question.strip():\n",
        "        return \"질문을 입력해주세요.\", \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        # 시작 시간 기록\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        # 컨텍스트 검색\n",
        "        context = \"\"\n",
        "        if use_context and hasattr(rag_system, 'retrieve_context'):\n",
        "            context = rag_system.retrieve_context(question)\n",
        "            context_display = f\"📚 **참고된 문서:**\\n```\\n{context[:500]}{'...' if len(context) > 500 else ''}\\n```\"\n",
        "        else:\n",
        "            context_display = \"컨텍스트를 사용하지 않았습니다.\"\n",
        "\n",
        "        # 답변 생성\n",
        "        answer = rag_system.generate_answer(\n",
        "            question,\n",
        "            max_length=max_tokens\n",
        "        )\n",
        "\n",
        "        # 처리 시간 계산\n",
        "        process_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "        # 대화 기록 저장\n",
        "        conversation_history.append({\n",
        "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'process_time': process_time\n",
        "        })\n",
        "\n",
        "        # 결과 포맷팅\n",
        "        answer_display = f\"\"\"\n",
        "## 💡 답변\n",
        "\n",
        "{answer}\n",
        "\n",
        "---\n",
        "*처리 시간: {process_time:.2f}초*\n",
        "\"\"\"\n",
        "\n",
        "        # 통계 정보\n",
        "        stats = f\"\"\"\n",
        "- 총 대화 수: {len(conversation_history)}\n",
        "- 평균 처리 시간: {sum(h['process_time'] for h in conversation_history) / len(conversation_history):.2f}초\n",
        "- 현재 세션 시작: {conversation_history[0]['timestamp'] if conversation_history else 'N/A'}\n",
        "\"\"\"\n",
        "\n",
        "        return answer_display, context_display, stats\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ 오류 발생: {str(e)}\"\n",
        "        return error_msg, \"\", \"\"\n",
        "\n",
        "def get_sample_questions():\n",
        "    \"\"\"예시 질문 목록 반환\"\"\"\n",
        "    return [\n",
        "        \"AI 산업의 최신 동향은 무엇인가요?\",\n",
        "        \"오픈AI의 챗GPT 에이전트 기능에 대해 설명해주세요.\",\n",
        "        \"구글 딥마인드의 최근 연구 성과는?\",\n",
        "        \"미국의 AI 정책 현황은 어떻게 되나요?\",\n",
        "        \"AI가 노동 시장에 미치는 영향은?\",\n",
        "        \"생성형 AI의 주요 기업들은?\",\n",
        "        \"한국의 AI 관련 정책은?\",\n",
        "        \"AI 파인튜닝이란 무엇인가요?\"\n",
        "    ]\n",
        "\n",
        "def export_history():\n",
        "    \"\"\"대화 기록을 JSON 형식으로 내보내기\"\"\"\n",
        "    if not conversation_history:\n",
        "        return \"대화 기록이 없습니다.\"\n",
        "\n",
        "    return json.dumps(conversation_history, ensure_ascii=False, indent=2)\n",
        "\n",
        "def clear_history():\n",
        "    \"\"\"대화 기록 초기화\"\"\"\n",
        "    global conversation_history\n",
        "    conversation_history = []\n",
        "    return \"대화 기록이 초기화되었습니다.\", \"\", \"\"\n",
        "\n",
        "# ====================================\n",
        "# 3. Gradio 인터페이스 구성\n",
        "# ====================================\n",
        "\n",
        "# CSS 스타일링\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "    font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, Roboto, sans-serif;\n",
        "}\n",
        ".contain {\n",
        "    max-width: 1200px !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Gradio 인터페이스 생성\n",
        "with gr.Blocks(title=\"SPRi AI Brief 질의응답 시스템\", theme=gr.themes.Soft(), css=custom_css) as demo:\n",
        "\n",
        "    # 헤더\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🤖 SPRi AI Brief 질의응답 시스템\n",
        "\n",
        "    학습된 문서를 기반으로 AI가 질문에 답변합니다.\n",
        "    파인튜닝된 모델과 RAG(Retrieval-Augmented Generation) 기술을 활용합니다.\n",
        "    \"\"\")\n",
        "\n",
        "    # 메인 인터페이스\n",
        "    with gr.Row():\n",
        "        # 왼쪽 패널 - 입력\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 📝 질문 입력\")\n",
        "\n",
        "            question_input = gr.Textbox(\n",
        "                label=\"질문\",\n",
        "                placeholder=\"AI 관련 질문을 입력하세요...\",\n",
        "                lines=4\n",
        "            )\n",
        "\n",
        "            # 파라미터 설정\n",
        "            with gr.Accordion(\"⚙️ 고급 설정\", open=False):\n",
        "                temperature_slider = gr.Slider(\n",
        "                    minimum=0.1,\n",
        "                    maximum=1.0,\n",
        "                    value=0.7,\n",
        "                    step=0.1,\n",
        "                    label=\"Temperature (창의성)\"\n",
        "                )\n",
        "\n",
        "                max_tokens_slider = gr.Slider(\n",
        "                    minimum=128,\n",
        "                    maximum=1024,\n",
        "                    value=512,\n",
        "                    step=64,\n",
        "                    label=\"최대 토큰 수\"\n",
        "                )\n",
        "\n",
        "                use_context_checkbox = gr.Checkbox(\n",
        "                    value=True,\n",
        "                    label=\"문서 컨텍스트 사용\"\n",
        "                )\n",
        "\n",
        "            # 버튼들\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"🚀 답변 생성\", variant=\"primary\", scale=2)\n",
        "                clear_btn = gr.Button(\"🗑️ 초기화\", scale=1)\n",
        "\n",
        "            # 예시 질문\n",
        "            gr.Markdown(\"### 💭 예시 질문\")\n",
        "            example_questions = gr.Dropdown(\n",
        "                choices=get_sample_questions(),\n",
        "                label=\"선택하세요\",\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "        # 오른쪽 패널 - 출력\n",
        "        with gr.Column(scale=2):\n",
        "            # 답변 영역\n",
        "            answer_output = gr.Markdown(\n",
        "                label=\"답변\",\n",
        "                value=\"질문을 입력하고 '답변 생성' 버튼을 클릭하세요.\"\n",
        "            )\n",
        "\n",
        "            # 컨텍스트 표시\n",
        "            with gr.Accordion(\"📖 참고 문서\", open=False):\n",
        "                context_output = gr.Markdown(\n",
        "                    label=\"검색된 컨텍스트\"\n",
        "                )\n",
        "\n",
        "            # 통계 정보\n",
        "            with gr.Accordion(\"📊 세션 통계\", open=False):\n",
        "                stats_output = gr.Textbox(\n",
        "                    label=\"통계\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "    # 대화 기록 탭\n",
        "    with gr.Tab(\"📜 대화 기록\"):\n",
        "        history_output = gr.Textbox(\n",
        "            label=\"대화 기록 (JSON)\",\n",
        "            lines=10,\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            export_btn = gr.Button(\"💾 내보내기\")\n",
        "            refresh_btn = gr.Button(\"🔄 새로고침\")\n",
        "\n",
        "    # 정보 탭\n",
        "    with gr.Tab(\"ℹ️ 정보\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### 시스템 정보\n",
        "\n",
        "        - **모델**: KoAlpaca-Polyglot-5.8B (파인튜닝됨)\n",
        "        - **임베딩**: ko-sroberta-multitask\n",
        "        - **벡터 DB**: ChromaDB\n",
        "        - **청크 크기**: 500 토큰\n",
        "        - **검색 문서 수**: 3개\n",
        "\n",
        "        ### 사용 팁\n",
        "\n",
        "        1. 구체적인 질문일수록 정확한 답변을 받을 수 있습니다\n",
        "        2. Temperature를 낮추면 일관된 답변, 높이면 창의적인 답변을 얻습니다\n",
        "        3. 컨텍스트를 사용하면 문서 기반 답변, 사용하지 않으면 모델의 일반 지식 활용\n",
        "        \"\"\")\n",
        "\n",
        "    # 이벤트 핸들러 연결\n",
        "    submit_btn.click(\n",
        "        fn=process_question,\n",
        "        inputs=[question_input, temperature_slider, max_tokens_slider, use_context_checkbox],\n",
        "        outputs=[answer_output, context_output, stats_output]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_history,\n",
        "        outputs=[answer_output, context_output, stats_output]\n",
        "    )\n",
        "\n",
        "    # 예시 질문 선택 시 입력창에 자동 입력\n",
        "    example_questions.change(\n",
        "        fn=lambda x: x,\n",
        "        inputs=[example_questions],\n",
        "        outputs=[question_input]\n",
        "    )\n",
        "\n",
        "    # 엔터키로 제출\n",
        "    question_input.submit(\n",
        "        fn=process_question,\n",
        "        inputs=[question_input, temperature_slider, max_tokens_slider, use_context_checkbox],\n",
        "        outputs=[answer_output, context_output, stats_output]\n",
        "    )\n",
        "\n",
        "    # 대화 기록 관련\n",
        "    export_btn.click(\n",
        "        fn=export_history,\n",
        "        outputs=[history_output]\n",
        "    )\n",
        "\n",
        "    refresh_btn.click(\n",
        "        fn=export_history,\n",
        "        outputs=[history_output]\n",
        "    )\n",
        "\n",
        "# ====================================\n",
        "# 4. Gradio 실행\n",
        "# ====================================\n",
        "\n",
        "# Colab에서 실행\n",
        "print(\"🚀 Gradio 인터페이스를 시작합니다...\")\n",
        "demo.launch(\n",
        "    share=True,  # 외부 접속 가능한 링크 생성\n",
        "    debug=False,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "print(\"\"\"\n",
        "✅ Gradio 인터페이스가 성공적으로 실행되었습니다!\n",
        "\n",
        "📌 사용 방법:\n",
        "1. 질문을 입력하거나 예시 질문을 선택하세요\n",
        "2. '답변 생성' 버튼을 클릭하거나 Enter를 누르세요\n",
        "3. 고급 설정에서 파라미터를 조정할 수 있습니다\n",
        "4. 대화 기록은 JSON 형식으로 내보낼 수 있습니다\n",
        "\n",
        "🔗 공유 링크를 통해 다른 사용자도 접속할 수 있습니다.\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "001233a9786047528cabb011ee6b7cef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0388fb10e35945ffa4dda63029188a69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bb97d5128a40a3a6ed1cf4955ea81c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1375ab38ba1845c7a9d67472a180e210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60eac9e0eb8741c3a94cb826e68cd14b",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c95cd7f14c944b93a4717ed1978e0cc7",
            "value": 88
          }
        },
        "1536a1a8aade444c9cbe7a5ea01e1b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "175c63ef40ec43e486c46ec85a237533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2508d6e1c0c84acdbd54a8dab50d3b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bb97d5128a40a3a6ed1cf4955ea81c",
            "placeholder": "​",
            "style": "IPY_MODEL_de1f6f9a1b87469ba85d18a8a009556b",
            "value": " 13/13 [00:13&lt;00:00,  1.09it/s]"
          }
        },
        "290b6162d66e4aeca69aa67d9f0edd2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292ab210672548f69c2be6603d4e9cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63318d34f615456392904de7ea35ae06",
            "placeholder": "​",
            "style": "IPY_MODEL_69eba4a3b2c941bababc2bf132c9a08f",
            "value": " 88/88 [00:00&lt;00:00, 1846.11 examples/s]"
          }
        },
        "2aeb9dce35b347c0b48ba3de10a18f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc405af45724c2bbb2e10b9b140ccd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5465918d7ba74e8780424db3cbe25d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "596f6e061fdc4853864c162bf2b1c314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0388fb10e35945ffa4dda63029188a69",
            "placeholder": "​",
            "style": "IPY_MODEL_1536a1a8aade444c9cbe7a5ea01e1b98",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "60eac9e0eb8741c3a94cb826e68cd14b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63318d34f615456392904de7ea35ae06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69eba4a3b2c941bababc2bf132c9a08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b7f22e7c52d44c3a48a2fd8fe5303d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78761757cc08479f9ae22284c1bdd623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290b6162d66e4aeca69aa67d9f0edd2b",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5465918d7ba74e8780424db3cbe25d57",
            "value": 13
          }
        },
        "8ee9fec3ed694adb9a422afb699a9644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc405af45724c2bbb2e10b9b140ccd1",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb6447cca88420b9e6834e3a06a5569",
            "value": 13
          }
        },
        "a1931332cba44dce8b3eb97a54c17a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8541c14925c4235baba2807efa4f7e0",
              "IPY_MODEL_8ee9fec3ed694adb9a422afb699a9644",
              "IPY_MODEL_2508d6e1c0c84acdbd54a8dab50d3b77"
            ],
            "layout": "IPY_MODEL_2aeb9dce35b347c0b48ba3de10a18f7f"
          }
        },
        "a1e6480e80b5485b84024ac65e09c3df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab130e864f774d98a949346de3af377f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae92f2a5a6ef4478a5d710f047f9b1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8541c14925c4235baba2807efa4f7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001233a9786047528cabb011ee6b7cef",
            "placeholder": "​",
            "style": "IPY_MODEL_d51eca32a7d84f5096205377a6b89b83",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ba6ee50e255742eb88e119008a415fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7f22e7c52d44c3a48a2fd8fe5303d0",
            "placeholder": "​",
            "style": "IPY_MODEL_ae92f2a5a6ef4478a5d710f047f9b1a5",
            "value": " 13/13 [00:14&lt;00:00,  1.07it/s]"
          }
        },
        "c3a6e2fcf50345498b75e0092b6528bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f7a5ea3428456c8400ba9007f8f497": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab130e864f774d98a949346de3af377f",
            "placeholder": "​",
            "style": "IPY_MODEL_175c63ef40ec43e486c46ec85a237533",
            "value": "Map: 100%"
          }
        },
        "c95cd7f14c944b93a4717ed1978e0cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d51eca32a7d84f5096205377a6b89b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb6447cca88420b9e6834e3a06a5569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de1f6f9a1b87469ba85d18a8a009556b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5674897c3014f7ca771de8254cc5d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_596f6e061fdc4853864c162bf2b1c314",
              "IPY_MODEL_78761757cc08479f9ae22284c1bdd623",
              "IPY_MODEL_ba6ee50e255742eb88e119008a415fa9"
            ],
            "layout": "IPY_MODEL_a1e6480e80b5485b84024ac65e09c3df"
          }
        },
        "f85dfe1de1724b568a1dccfe43f36bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8f7a5ea3428456c8400ba9007f8f497",
              "IPY_MODEL_1375ab38ba1845c7a9d67472a180e210",
              "IPY_MODEL_292ab210672548f69c2be6603d4e9cde"
            ],
            "layout": "IPY_MODEL_c3a6e2fcf50345498b75e0092b6528bf"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
