{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9DggwNWQ89Y",
        "outputId": "8c52cb37-ec67-4d8d-ecab-90a76bfb5ddd"
      },
      "outputs": [],
      "source": [
        "# Google Colabì—ì„œ ì‹¤í–‰í•˜ëŠ” RAG ë° íŒŒì¸íŠœë‹ ì½”ë“œ\n",
        "\n",
        "# ============================\n",
        "# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "# ============================\n",
        "!pip install -q langchain langchain-community\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q chromadb\n",
        "!pip install -q transformers accelerate bitsandbytes\n",
        "!pip install -q peft datasets\n",
        "!pip install -q pypdf\n",
        "!pip install -q torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981,
          "referenced_widgets": [
            "a1931332cba44dce8b3eb97a54c17a9d",
            "b8541c14925c4235baba2807efa4f7e0",
            "8ee9fec3ed694adb9a422afb699a9644",
            "2508d6e1c0c84acdbd54a8dab50d3b77",
            "2aeb9dce35b347c0b48ba3de10a18f7f",
            "001233a9786047528cabb011ee6b7cef",
            "d51eca32a7d84f5096205377a6b89b83",
            "3cc405af45724c2bbb2e10b9b140ccd1",
            "ddb6447cca88420b9e6834e3a06a5569",
            "12bb97d5128a40a3a6ed1cf4955ea81c",
            "de1f6f9a1b87469ba85d18a8a009556b",
            "f5674897c3014f7ca771de8254cc5d55",
            "596f6e061fdc4853864c162bf2b1c314",
            "78761757cc08479f9ae22284c1bdd623",
            "ba6ee50e255742eb88e119008a415fa9",
            "a1e6480e80b5485b84024ac65e09c3df",
            "0388fb10e35945ffa4dda63029188a69",
            "1536a1a8aade444c9cbe7a5ea01e1b98",
            "290b6162d66e4aeca69aa67d9f0edd2b",
            "5465918d7ba74e8780424db3cbe25d57",
            "6b7f22e7c52d44c3a48a2fd8fe5303d0",
            "ae92f2a5a6ef4478a5d710f047f9b1a5",
            "f85dfe1de1724b568a1dccfe43f36bc1",
            "c8f7a5ea3428456c8400ba9007f8f497",
            "1375ab38ba1845c7a9d67472a180e210",
            "292ab210672548f69c2be6603d4e9cde",
            "c3a6e2fcf50345498b75e0092b6528bf",
            "ab130e864f774d98a949346de3af377f",
            "175c63ef40ec43e486c46ec85a237533",
            "60eac9e0eb8741c3a94cb826e68cd14b",
            "c95cd7f14c944b93a4717ed1978e0cc7",
            "63318d34f615456392904de7ea35ae06",
            "69eba4a3b2c941bababc2bf132c9a08f"
          ]
        },
        "id": "Syz-yuYnQ6o7",
        "outputId": "3e823255-39f5-40b5-ba2b-9ba73da3a017"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-83522d1d-9db4-42df-a65a-612636a2dae9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-83522d1d-9db4-42df-a65a-612636a2dae9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving SPRi AI Brief_8ì›”í˜¸_ì‚°ì—…ë™í–¥_F.pdf to SPRi AI Brief_8ì›”í˜¸_ì‚°ì—…ë™í–¥_F (4).pdf\n",
            "ì—…ë¡œë“œëœ íŒŒì¼: SPRi AI Brief_8ì›”í˜¸_ì‚°ì—…ë™í–¥_F (4).pdf\n",
            "\n",
            "[1/5] ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤...\n",
            "ë¬¸ì„œë¥¼ 127ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "[2/5] ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\n",
            "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "[3/5] RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1931332cba44dce8b3eb97a54c17a9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[4/5] RAG ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\n",
            "\n",
            "ì§ˆë¬¸: AI ì‚°ì—…ì˜ ìµœì‹  ë™í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë‹µë³€: 1. [ì¸ê³µì§€ëŠ¥ ìŠ¤íƒ€íŠ¸ì—… íˆ¬ìëŠ” 2021ë…„ 1ë¶„ê¸°](https://www.cbinsights.com/research/report/ai-startup-íˆ¬ì-2021/)\n",
            "2. [ë¯¸êµ­ì—ì„œ ëŒ€í˜• AI ìŠ¤íƒ€íŠ¸ì—…ì— ëŒ€í•œ íˆ¬ìê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì „ë¬¸ê°€ë“¤ ì‚¬ì´ì— ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆë‹¤.] (https://nasa.gov/acquisition/firmware/radiation-and-data-technology-projects/us-approves-largest-alternative-artificial-intelligence-software-proje...\n",
            "\n",
            "ì§ˆë¬¸: ì˜¤í”ˆAIì˜ ìµœê·¼ ì†Œì‹ì€?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë‹µë³€: ì•„ë˜ ì‚¬ì´íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
            "https://www.openai.com/content/fulltext/20257/15570196_1d13b032e2c09?vType=rollout...\n",
            "\n",
            "ì§ˆë¬¸: êµ¬ê¸€ ë”¥ë§ˆì¸ë“œì˜ ì—°êµ¬ ë‚´ìš©ì€?\n",
            "ë‹µë³€: GPTëŠ” Generative Pre-trained Transformerì˜ ì•½ìë¡œ, ê¸°ì¡´ì˜ ëª¨ë“  ì–¸ì–´ ëª¨ë¸ë³´ë‹¤ ë”ìš± ë°œì „ëœ ëª¨ë¸ì…ë‹ˆë‹¤. GPTëŠ” ë‹¨ì–´ì˜ ì˜ë¯¸, ë¬¸ë²• ë° ê´€ëŒ€í•œ í•´ì„ ë“±ì„ í•™ìŠµí•  ìˆ˜ ìˆì–´ì„œ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìì—°ì–´ ì²˜ë¦¬ ë° ê¸°ê³„ ë²ˆì—­ ë¶„ì•¼ì—ì„œ ë§ì€ ì„±ê³¼ë¥¼ ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ìµœê·¼ì—ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ìŒì„±ì¸ì‹ ì†Œí”„íŠ¸ì›¨ì–´ë„ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ GPTê°€ ì ìš©ë  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§€ë©´ì„œ ê´€ì‹¬ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤....\n",
            "\n",
            "[5/5] íŒŒì¸íŠœë‹ì„ ì¤€ë¹„í•©ë‹ˆë‹¤...\n",
            "íŒŒì¸íŠœë‹ ë°ì´í„°ì…‹ í¬ê¸°: 88\n",
            "\n",
            "íŒŒì¸íŠœë‹ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): y\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5674897c3014f7ca771de8254cc5d55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 3,670,016 || all params: 5,888,729,088 || trainable%: 0.0623\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f85dfe1de1724b568a1dccfe43f36bc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/88 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [66/66 00:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.205500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "íŒŒì¸íŠœë‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "\n",
            "íŒŒì¸íŠœë‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "\n",
            "ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# WandB ë¹„í™œì„±í™” (API í‚¤ ë¶ˆí•„ìš”)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader # Corrected import\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "# ============================\n",
        "# 2. ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "# ============================\n",
        "\n",
        "def load_and_process_document(file_path):\n",
        "    \"\"\"PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• \"\"\"\n",
        "\n",
        "    # PDF ë¡œë” ì‚¬ìš©\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• \n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "    print(f\"ë¬¸ì„œë¥¼ {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.\")\n",
        "    return chunks\n",
        "\n",
        "# ============================\n",
        "# 3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•\n",
        "# ============================\n",
        "\n",
        "def create_vector_database(chunks):\n",
        "    \"\"\"ë¬¸ì„œ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  ë²¡í„° DB ìƒì„±\"\"\"\n",
        "\n",
        "    # í•œêµ­ì–´ ì§€ì› ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"jhgan/ko-sroberta-multitask\",\n",
        "        model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'},\n",
        "        encode_kwargs={'normalize_embeddings': True}\n",
        "    )\n",
        "\n",
        "    # ChromaDB ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=\"./chroma_db\"\n",
        "    )\n",
        "\n",
        "    print(\"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    return vectorstore\n",
        "\n",
        "# ============================\n",
        "# 4. RAG ì‹œìŠ¤í…œ êµ¬í˜„\n",
        "# ============================\n",
        "\n",
        "class SimpleRAG:\n",
        "    def __init__(self, vectorstore, model_name=\"beomi/KoAlpaca-Polyglot-5.8B\"):\n",
        "        self.vectorstore = vectorstore\n",
        "        self.retriever = vectorstore.as_retriever(\n",
        "            search_type=\"similarity\",\n",
        "            search_kwargs={\"k\": 3}\n",
        "        )\n",
        "\n",
        "        # 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì •\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True\n",
        "        )\n",
        "\n",
        "        # ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # íŒ¨ë”© í† í° ì„¤ì •\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "    def retrieve_context(self, query):\n",
        "        \"\"\"ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰\"\"\"\n",
        "        docs = self.retriever.get_relevant_documents(query)\n",
        "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "        return context\n",
        "\n",
        "    def generate_answer(self, query, max_length=512):\n",
        "        \"\"\"ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ë‹µë³€ ìƒì„±\"\"\"\n",
        "        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
        "        context = self.retrieve_context(query)\n",
        "\n",
        "        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "        prompt = f\"\"\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ë¬¸ì„œ:\n",
        "{context}\n",
        "\n",
        "ì§ˆë¬¸: {query}\n",
        "\n",
        "ë‹µë³€:\"\"\"\n",
        "\n",
        "        # í† í¬ë‚˜ì´ì§•\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        # ë‹µë³€ ìƒì„±\n",
        "        with torch.no_grad():\n",
        "            # Filter out 'token_type_ids' if present\n",
        "            inputs_dict = {k: v for k, v in inputs.items() if k != 'token_type_ids'}\n",
        "            outputs = self.model.generate(\n",
        "                **inputs_dict,\n",
        "                max_new_tokens=max_length,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                top_p=0.9,\n",
        "                repetition_penalty=1.2\n",
        "            )\n",
        "\n",
        "        # ë””ì½”ë”©\n",
        "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        answer = answer.split(\"ë‹µë³€:\")[-1].strip()\n",
        "\n",
        "        return answer\n",
        "\n",
        "# ============================\n",
        "# 5. íŒŒì¸íŠœë‹ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
        "# ============================\n",
        "\n",
        "def prepare_finetuning_dataset(chunks):\n",
        "    \"\"\"ë¬¸ì„œ ì²­í¬ë¥¼ íŒŒì¸íŠœë‹ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
        "\n",
        "    dataset_list = []\n",
        "\n",
        "    for chunk in chunks[:100]:  # ë©”ëª¨ë¦¬ ì œì•½ìœ¼ë¡œ 100ê°œë§Œ ì‚¬ìš©\n",
        "        text = chunk.page_content\n",
        "\n",
        "        # ê°„ë‹¨í•œ Q&A í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "        if len(text) > 50:\n",
        "            # ì§ˆë¬¸ ìƒì„± (ê°„ë‹¨í•œ ì˜ˆì‹œ)\n",
        "            question = \"ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\n",
        "            answer = text[:200] if len(text) > 200 else text\n",
        "\n",
        "            dataset_list.append({\n",
        "                \"instruction\": question,\n",
        "                \"input\": text,\n",
        "                \"output\": answer\n",
        "            })\n",
        "\n",
        "    # Dataset ê°ì²´ë¡œ ë³€í™˜\n",
        "    dataset = Dataset.from_list(dataset_list)\n",
        "\n",
        "    print(f\"íŒŒì¸íŠœë‹ ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}\")\n",
        "    return dataset\n",
        "\n",
        "# ============================\n",
        "# 6. LoRA íŒŒì¸íŠœë‹\n",
        "# ============================\n",
        "\n",
        "def finetune_with_lora(model_name=\"beomi/KoAlpaca-Polyglot-5.8B\", dataset=None):\n",
        "    \"\"\"LoRAë¥¼ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ íŒŒì¸íŠœë‹\"\"\"\n",
        "\n",
        "    # 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì •\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True\n",
        "    )\n",
        "\n",
        "    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # LoRA ì„¤ì • - Adjusted target_modules for KoAlpaca\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,  # LoRA rank\n",
        "        lora_alpha=32,\n",
        "        target_modules=[\"query_key_value\"], # Corrected target modules\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.CAUSAL_LM\n",
        "    )\n",
        "\n",
        "    # LoRA ì ìš©\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    # ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "    def preprocess_function(examples):\n",
        "        prompts = []\n",
        "        for inst, inp, out in zip(examples[\"instruction\"], examples[\"input\"], examples[\"output\"]):\n",
        "            prompt = f\"### ì§ˆë¬¸: {inst}\\n### ì…ë ¥: {inp}\\n### ë‹µë³€: {out}\"\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        model_inputs = tokenizer(\n",
        "            prompts,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        )\n",
        "        model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "        return model_inputs\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
        "    tokenized_dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "        remove_columns=dataset.column_names\n",
        "    )\n",
        "\n",
        "    # í•™ìŠµ ì„¤ì •\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./lora_model\",\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=100,\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"epoch\",\n",
        "        # Removed evaluation_strategy=\"no\"\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        push_to_hub=False,\n",
        "    )\n",
        "\n",
        "    # ë°ì´í„° ì½œë ˆì´í„°\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False\n",
        "    )\n",
        "\n",
        "    # íŠ¸ë ˆì´ë„ˆ ìƒì„±\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # í•™ìŠµ ì‹œì‘\n",
        "    print(\"íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # ëª¨ë¸ ì €ì¥\n",
        "    model.save_pretrained(\"./lora_model\")\n",
        "    tokenizer.save_pretrained(\"./lora_model\")\n",
        "\n",
        "    print(\"íŒŒì¸íŠœë‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    return model, tokenizer\n",
        "\n",
        "# ============================\n",
        "# 7. ì‹¤í–‰ ì½”ë“œ\n",
        "# ============================\n",
        "\n",
        "def main():\n",
        "    # íŒŒì¼ ê²½ë¡œ ì„¤ì • (Colabì— ì—…ë¡œë“œí•œ PDF íŒŒì¼ ê²½ë¡œ)\n",
        "    # ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # ì—…ë¡œë“œëœ íŒŒì¼ ì´ë¦„ í™•ì¸\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "    print(f\"ì—…ë¡œë“œëœ íŒŒì¼: {file_path}\")\n",
        "\n",
        "    # 1. ë¬¸ì„œ ë¡œë“œ ë° ì²˜ë¦¬\n",
        "    print(\"\\n[1/5] ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤...\")\n",
        "    chunks = load_and_process_document(file_path)\n",
        "\n",
        "    # 2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±\n",
        "    print(\"\\n[2/5] ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
        "    vectorstore = create_vector_database(chunks)\n",
        "\n",
        "    # 3. RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
        "    print(\"\\n[3/5] RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...\")\n",
        "    rag_system = SimpleRAG(vectorstore)\n",
        "\n",
        "    # 4. RAG í…ŒìŠ¤íŠ¸\n",
        "    print(\"\\n[4/5] RAG ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\")\n",
        "    test_queries = [\n",
        "        \"AI ì‚°ì—…ì˜ ìµœì‹  ë™í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "        \"ì˜¤í”ˆAIì˜ ìµœê·¼ ì†Œì‹ì€?\",\n",
        "        \"êµ¬ê¸€ ë”¥ë§ˆì¸ë“œì˜ ì—°êµ¬ ë‚´ìš©ì€?\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\nì§ˆë¬¸: {query}\")\n",
        "        answer = rag_system.generate_answer(query)\n",
        "        print(f\"ë‹µë³€: {answer[:300]}...\")  # ë‹µë³€ ì¼ë¶€ë§Œ ì¶œë ¥\n",
        "\n",
        "    # 5. íŒŒì¸íŠœë‹ (ì„ íƒì‚¬í•­ - ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œ ê²½ìš°)\n",
        "    print(\"\\n[5/5] íŒŒì¸íŠœë‹ì„ ì¤€ë¹„í•©ë‹ˆë‹¤...\")\n",
        "    dataset = prepare_finetuning_dataset(chunks)\n",
        "\n",
        "    # íŒŒì¸íŠœë‹ ì‹¤í–‰ (ì£¼ì˜: ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)\n",
        "    user_input = input(\"\\níŒŒì¸íŠœë‹ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
        "    if user_input.lower() == 'y':\n",
        "        model, tokenizer = finetune_with_lora(dataset=dataset)\n",
        "        print(\"\\níŒŒì¸íŠœë‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    else:\n",
        "        print(\"\\níŒŒì¸íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "\n",
        "    print(\"\\nëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    return rag_system\n",
        "\n",
        "# ì‹¤í–‰\n",
        "if __name__ == \"__main__\":\n",
        "    rag_system = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bIiBF53iTSwH",
        "outputId": "4a51c41f-6ed4-457b-93b4-6c5ad29946c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ê¸°ì¡´ rag_systemì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
            "ğŸš€ Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://11cdd8b3e94d19c6ac.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://11cdd8b3e94d19c6ac.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Gradio ì¸í„°í˜ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "\n",
            "ğŸ“Œ ì‚¬ìš© ë°©ë²•:\n",
            "1. ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”\n",
            "2. 'ë‹µë³€ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”\n",
            "3. ê³ ê¸‰ ì„¤ì •ì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
            "4. ëŒ€í™” ê¸°ë¡ì€ JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
            "\n",
            "ğŸ”— ê³µìœ  ë§í¬ë¥¼ í†µí•´ ë‹¤ë¥¸ ì‚¬ìš©ìë„ ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ====================================\n",
        "# ì´ì „ ì…€ì—ì„œ í•™ìŠµëœ RAG ì‹œìŠ¤í…œì„ í™œìš©í•œ Gradio ì¸í„°í˜ì´ìŠ¤\n",
        "# ====================================\n",
        "\n",
        "# Gradio ì„¤ì¹˜ (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ê±´ë„ˆëœ€)\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# ====================================\n",
        "# 1. ì´ì „ ì…€ì˜ rag_system í™•ì¸ ë° ë˜í¼ í´ë˜ìŠ¤ ìƒì„±\n",
        "# ====================================\n",
        "\n",
        "# ì´ì „ ì…€ì—ì„œ ìƒì„±ëœ rag_systemì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "try:\n",
        "    if 'rag_system' not in globals():\n",
        "        print(\"âš ï¸ rag_systemì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "        # ê¸°ì¡´ ë²¡í„° DBê°€ ìˆìœ¼ë©´ ë¡œë“œ\n",
        "        if os.path.exists(\"./chroma_db\"):\n",
        "            vectorstore = Chroma(\n",
        "                persist_directory=\"./chroma_db\",\n",
        "                embedding_function=HuggingFaceEmbeddings(\n",
        "                    model_name=\"jhgan/ko-sroberta-multitask\",\n",
        "                    model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
        "                )\n",
        "            )\n",
        "            rag_system = SimpleRAG(vectorstore)\n",
        "            print(\"âœ… ê¸°ì¡´ ë²¡í„° DBë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì‹œìŠ¤í…œì„ ì¬êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
        "        else:\n",
        "            print(\"âŒ ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\")\n",
        "    else:\n",
        "        print(\"âœ… ê¸°ì¡´ rag_systemì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ ì‹œìŠ¤í…œ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "# ====================================\n",
        "# 2. Gradioìš© ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜ë“¤\n",
        "# ====================================\n",
        "\n",
        "# ëŒ€í™” ê¸°ë¡ ì €ì¥ìš©\n",
        "conversation_history = []\n",
        "\n",
        "def process_question(question, temperature=0.7, max_tokens=512, use_context=True):\n",
        "    \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ë‹µë³€ ìƒì„±\"\"\"\n",
        "\n",
        "    if not question.strip():\n",
        "        return \"ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\", \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        # ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        # ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰\n",
        "        context = \"\"\n",
        "        if use_context and hasattr(rag_system, 'retrieve_context'):\n",
        "            context = rag_system.retrieve_context(question)\n",
        "            context_display = f\"ğŸ“š **ì°¸ê³ ëœ ë¬¸ì„œ:**\\n```\\n{context[:500]}{'...' if len(context) > 500 else ''}\\n```\"\n",
        "        else:\n",
        "            context_display = \"ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        # ë‹µë³€ ìƒì„±\n",
        "        answer = rag_system.generate_answer(\n",
        "            question,\n",
        "            max_length=max_tokens\n",
        "        )\n",
        "\n",
        "        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°\n",
        "        process_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "        # ëŒ€í™” ê¸°ë¡ ì €ì¥\n",
        "        conversation_history.append({\n",
        "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'process_time': process_time\n",
        "        })\n",
        "\n",
        "        # ê²°ê³¼ í¬ë§·íŒ…\n",
        "        answer_display = f\"\"\"\n",
        "## ğŸ’¡ ë‹µë³€\n",
        "\n",
        "{answer}\n",
        "\n",
        "---\n",
        "*ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ*\n",
        "\"\"\"\n",
        "\n",
        "        # í†µê³„ ì •ë³´\n",
        "        stats = f\"\"\"\n",
        "- ì´ ëŒ€í™” ìˆ˜: {len(conversation_history)}\n",
        "- í‰ê·  ì²˜ë¦¬ ì‹œê°„: {sum(h['process_time'] for h in conversation_history) / len(conversation_history):.2f}ì´ˆ\n",
        "- í˜„ì¬ ì„¸ì…˜ ì‹œì‘: {conversation_history[0]['timestamp'] if conversation_history else 'N/A'}\n",
        "\"\"\"\n",
        "\n",
        "        return answer_display, context_display, stats\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "        return error_msg, \"\", \"\"\n",
        "\n",
        "def get_sample_questions():\n",
        "    \"\"\"ì˜ˆì‹œ ì§ˆë¬¸ ëª©ë¡ ë°˜í™˜\"\"\"\n",
        "    return [\n",
        "        \"AI ì‚°ì—…ì˜ ìµœì‹  ë™í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "        \"ì˜¤í”ˆAIì˜ ì±—GPT ì—ì´ì „íŠ¸ ê¸°ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
        "        \"êµ¬ê¸€ ë”¥ë§ˆì¸ë“œì˜ ìµœê·¼ ì—°êµ¬ ì„±ê³¼ëŠ”?\",\n",
        "        \"ë¯¸êµ­ì˜ AI ì •ì±… í˜„í™©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
        "        \"AIê°€ ë…¸ë™ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?\",\n",
        "        \"ìƒì„±í˜• AIì˜ ì£¼ìš” ê¸°ì—…ë“¤ì€?\",\n",
        "        \"í•œêµ­ì˜ AI ê´€ë ¨ ì •ì±…ì€?\",\n",
        "        \"AI íŒŒì¸íŠœë‹ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "    ]\n",
        "\n",
        "def export_history():\n",
        "    \"\"\"ëŒ€í™” ê¸°ë¡ì„ JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
        "    if not conversation_history:\n",
        "        return \"ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "    return json.dumps(conversation_history, ensure_ascii=False, indent=2)\n",
        "\n",
        "def clear_history():\n",
        "    \"\"\"ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\"\"\"\n",
        "    global conversation_history\n",
        "    conversation_history = []\n",
        "    return \"ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\", \"\", \"\"\n",
        "\n",
        "# ====================================\n",
        "# 3. Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±\n",
        "# ====================================\n",
        "\n",
        "# CSS ìŠ¤íƒ€ì¼ë§\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "    font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, Roboto, sans-serif;\n",
        "}\n",
        ".contain {\n",
        "    max-width: 1200px !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
        "with gr.Blocks(title=\"SPRi AI Brief ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\", theme=gr.themes.Soft(), css=custom_css) as demo:\n",
        "\n",
        "    # í—¤ë”\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¤– SPRi AI Brief ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\n",
        "\n",
        "    í•™ìŠµëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.\n",
        "    íŒŒì¸íŠœë‹ëœ ëª¨ë¸ê³¼ RAG(Retrieval-Augmented Generation) ê¸°ìˆ ì„ í™œìš©í•©ë‹ˆë‹¤.\n",
        "    \"\"\")\n",
        "\n",
        "    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤\n",
        "    with gr.Row():\n",
        "        # ì™¼ìª½ íŒ¨ë„ - ì…ë ¥\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### ğŸ“ ì§ˆë¬¸ ì…ë ¥\")\n",
        "\n",
        "            question_input = gr.Textbox(\n",
        "                label=\"ì§ˆë¬¸\",\n",
        "                placeholder=\"AI ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...\",\n",
        "                lines=4\n",
        "            )\n",
        "\n",
        "            # íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "            with gr.Accordion(\"âš™ï¸ ê³ ê¸‰ ì„¤ì •\", open=False):\n",
        "                temperature_slider = gr.Slider(\n",
        "                    minimum=0.1,\n",
        "                    maximum=1.0,\n",
        "                    value=0.7,\n",
        "                    step=0.1,\n",
        "                    label=\"Temperature (ì°½ì˜ì„±)\"\n",
        "                )\n",
        "\n",
        "                max_tokens_slider = gr.Slider(\n",
        "                    minimum=128,\n",
        "                    maximum=1024,\n",
        "                    value=512,\n",
        "                    step=64,\n",
        "                    label=\"ìµœëŒ€ í† í° ìˆ˜\"\n",
        "                )\n",
        "\n",
        "                use_context_checkbox = gr.Checkbox(\n",
        "                    value=True,\n",
        "                    label=\"ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©\"\n",
        "                )\n",
        "\n",
        "            # ë²„íŠ¼ë“¤\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"ğŸš€ ë‹µë³€ ìƒì„±\", variant=\"primary\", scale=2)\n",
        "                clear_btn = gr.Button(\"ğŸ—‘ï¸ ì´ˆê¸°í™”\", scale=1)\n",
        "\n",
        "            # ì˜ˆì‹œ ì§ˆë¬¸\n",
        "            gr.Markdown(\"### ğŸ’­ ì˜ˆì‹œ ì§ˆë¬¸\")\n",
        "            example_questions = gr.Dropdown(\n",
        "                choices=get_sample_questions(),\n",
        "                label=\"ì„ íƒí•˜ì„¸ìš”\",\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "        # ì˜¤ë¥¸ìª½ íŒ¨ë„ - ì¶œë ¥\n",
        "        with gr.Column(scale=2):\n",
        "            # ë‹µë³€ ì˜ì—­\n",
        "            answer_output = gr.Markdown(\n",
        "                label=\"ë‹µë³€\",\n",
        "                value=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  'ë‹µë³€ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.\"\n",
        "            )\n",
        "\n",
        "            # ì»¨í…ìŠ¤íŠ¸ í‘œì‹œ\n",
        "            with gr.Accordion(\"ğŸ“– ì°¸ê³  ë¬¸ì„œ\", open=False):\n",
        "                context_output = gr.Markdown(\n",
        "                    label=\"ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸\"\n",
        "                )\n",
        "\n",
        "            # í†µê³„ ì •ë³´\n",
        "            with gr.Accordion(\"ğŸ“Š ì„¸ì…˜ í†µê³„\", open=False):\n",
        "                stats_output = gr.Textbox(\n",
        "                    label=\"í†µê³„\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "    # ëŒ€í™” ê¸°ë¡ íƒ­\n",
        "    with gr.Tab(\"ğŸ“œ ëŒ€í™” ê¸°ë¡\"):\n",
        "        history_output = gr.Textbox(\n",
        "            label=\"ëŒ€í™” ê¸°ë¡ (JSON)\",\n",
        "            lines=10,\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            export_btn = gr.Button(\"ğŸ’¾ ë‚´ë³´ë‚´ê¸°\")\n",
        "            refresh_btn = gr.Button(\"ğŸ”„ ìƒˆë¡œê³ ì¹¨\")\n",
        "\n",
        "    # ì •ë³´ íƒ­\n",
        "    with gr.Tab(\"â„¹ï¸ ì •ë³´\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### ì‹œìŠ¤í…œ ì •ë³´\n",
        "\n",
        "        - **ëª¨ë¸**: KoAlpaca-Polyglot-5.8B (íŒŒì¸íŠœë‹ë¨)\n",
        "        - **ì„ë² ë”©**: ko-sroberta-multitask\n",
        "        - **ë²¡í„° DB**: ChromaDB\n",
        "        - **ì²­í¬ í¬ê¸°**: 500 í† í°\n",
        "        - **ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜**: 3ê°œ\n",
        "\n",
        "        ### ì‚¬ìš© íŒ\n",
        "\n",
        "        1. êµ¬ì²´ì ì¸ ì§ˆë¬¸ì¼ìˆ˜ë¡ ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "        2. Temperatureë¥¼ ë‚®ì¶”ë©´ ì¼ê´€ëœ ë‹µë³€, ë†’ì´ë©´ ì°½ì˜ì ì¸ ë‹µë³€ì„ ì–»ìŠµë‹ˆë‹¤\n",
        "        3. ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€, ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë¸ì˜ ì¼ë°˜ ì§€ì‹ í™œìš©\n",
        "        \"\"\")\n",
        "\n",
        "    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°\n",
        "    submit_btn.click(\n",
        "        fn=process_question,\n",
        "        inputs=[question_input, temperature_slider, max_tokens_slider, use_context_checkbox],\n",
        "        outputs=[answer_output, context_output, stats_output]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_history,\n",
        "        outputs=[answer_output, context_output, stats_output]\n",
        "    )\n",
        "\n",
        "    # ì˜ˆì‹œ ì§ˆë¬¸ ì„ íƒ ì‹œ ì…ë ¥ì°½ì— ìë™ ì…ë ¥\n",
        "    example_questions.change(\n",
        "        fn=lambda x: x,\n",
        "        inputs=[example_questions],\n",
        "        outputs=[question_input]\n",
        "    )\n",
        "\n",
        "    # ì—”í„°í‚¤ë¡œ ì œì¶œ\n",
        "    question_input.submit(\n",
        "        fn=process_question,\n",
        "        inputs=[question_input, temperature_slider, max_tokens_slider, use_context_checkbox],\n",
        "        outputs=[answer_output, context_output, stats_output]\n",
        "    )\n",
        "\n",
        "    # ëŒ€í™” ê¸°ë¡ ê´€ë ¨\n",
        "    export_btn.click(\n",
        "        fn=export_history,\n",
        "        outputs=[history_output]\n",
        "    )\n",
        "\n",
        "    refresh_btn.click(\n",
        "        fn=export_history,\n",
        "        outputs=[history_output]\n",
        "    )\n",
        "\n",
        "# ====================================\n",
        "# 4. Gradio ì‹¤í–‰\n",
        "# ====================================\n",
        "\n",
        "# Colabì—ì„œ ì‹¤í–‰\n",
        "print(\"ğŸš€ Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "demo.launch(\n",
        "    share=True,  # ì™¸ë¶€ ì ‘ì† ê°€ëŠ¥í•œ ë§í¬ ìƒì„±\n",
        "    debug=False,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "print(\"\"\"\n",
        "âœ… Gradio ì¸í„°í˜ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "ğŸ“Œ ì‚¬ìš© ë°©ë²•:\n",
        "1. ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”\n",
        "2. 'ë‹µë³€ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”\n",
        "3. ê³ ê¸‰ ì„¤ì •ì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "4. ëŒ€í™” ê¸°ë¡ì€ JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "\n",
        "ğŸ”— ê³µìœ  ë§í¬ë¥¼ í†µí•´ ë‹¤ë¥¸ ì‚¬ìš©ìë„ ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "001233a9786047528cabb011ee6b7cef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0388fb10e35945ffa4dda63029188a69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bb97d5128a40a3a6ed1cf4955ea81c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1375ab38ba1845c7a9d67472a180e210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60eac9e0eb8741c3a94cb826e68cd14b",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c95cd7f14c944b93a4717ed1978e0cc7",
            "value": 88
          }
        },
        "1536a1a8aade444c9cbe7a5ea01e1b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "175c63ef40ec43e486c46ec85a237533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2508d6e1c0c84acdbd54a8dab50d3b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bb97d5128a40a3a6ed1cf4955ea81c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_de1f6f9a1b87469ba85d18a8a009556b",
            "value": "â€‡13/13â€‡[00:13&lt;00:00,â€‡â€‡1.09it/s]"
          }
        },
        "290b6162d66e4aeca69aa67d9f0edd2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292ab210672548f69c2be6603d4e9cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63318d34f615456392904de7ea35ae06",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_69eba4a3b2c941bababc2bf132c9a08f",
            "value": "â€‡88/88â€‡[00:00&lt;00:00,â€‡1846.11â€‡examples/s]"
          }
        },
        "2aeb9dce35b347c0b48ba3de10a18f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc405af45724c2bbb2e10b9b140ccd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5465918d7ba74e8780424db3cbe25d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "596f6e061fdc4853864c162bf2b1c314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0388fb10e35945ffa4dda63029188a69",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1536a1a8aade444c9cbe7a5ea01e1b98",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "60eac9e0eb8741c3a94cb826e68cd14b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63318d34f615456392904de7ea35ae06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69eba4a3b2c941bababc2bf132c9a08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b7f22e7c52d44c3a48a2fd8fe5303d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78761757cc08479f9ae22284c1bdd623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290b6162d66e4aeca69aa67d9f0edd2b",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5465918d7ba74e8780424db3cbe25d57",
            "value": 13
          }
        },
        "8ee9fec3ed694adb9a422afb699a9644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc405af45724c2bbb2e10b9b140ccd1",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb6447cca88420b9e6834e3a06a5569",
            "value": 13
          }
        },
        "a1931332cba44dce8b3eb97a54c17a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8541c14925c4235baba2807efa4f7e0",
              "IPY_MODEL_8ee9fec3ed694adb9a422afb699a9644",
              "IPY_MODEL_2508d6e1c0c84acdbd54a8dab50d3b77"
            ],
            "layout": "IPY_MODEL_2aeb9dce35b347c0b48ba3de10a18f7f"
          }
        },
        "a1e6480e80b5485b84024ac65e09c3df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab130e864f774d98a949346de3af377f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae92f2a5a6ef4478a5d710f047f9b1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8541c14925c4235baba2807efa4f7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001233a9786047528cabb011ee6b7cef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d51eca32a7d84f5096205377a6b89b83",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "ba6ee50e255742eb88e119008a415fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7f22e7c52d44c3a48a2fd8fe5303d0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ae92f2a5a6ef4478a5d710f047f9b1a5",
            "value": "â€‡13/13â€‡[00:14&lt;00:00,â€‡â€‡1.07it/s]"
          }
        },
        "c3a6e2fcf50345498b75e0092b6528bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f7a5ea3428456c8400ba9007f8f497": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab130e864f774d98a949346de3af377f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_175c63ef40ec43e486c46ec85a237533",
            "value": "Map:â€‡100%"
          }
        },
        "c95cd7f14c944b93a4717ed1978e0cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d51eca32a7d84f5096205377a6b89b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb6447cca88420b9e6834e3a06a5569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de1f6f9a1b87469ba85d18a8a009556b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5674897c3014f7ca771de8254cc5d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_596f6e061fdc4853864c162bf2b1c314",
              "IPY_MODEL_78761757cc08479f9ae22284c1bdd623",
              "IPY_MODEL_ba6ee50e255742eb88e119008a415fa9"
            ],
            "layout": "IPY_MODEL_a1e6480e80b5485b84024ac65e09c3df"
          }
        },
        "f85dfe1de1724b568a1dccfe43f36bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8f7a5ea3428456c8400ba9007f8f497",
              "IPY_MODEL_1375ab38ba1845c7a9d67472a180e210",
              "IPY_MODEL_292ab210672548f69c2be6603d4e9cde"
            ],
            "layout": "IPY_MODEL_c3a6e2fcf50345498b75e0092b6528bf"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
