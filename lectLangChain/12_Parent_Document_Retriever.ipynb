{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAZst8IJfIgK",
        "outputId": "761048a2-9ea7-4e43-cd56-3430793d1670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# 1) ì„¤ì¹˜\n",
        "# ============================================\n",
        "!pip -q install langchain langchain-community langchain-text-splitters faiss-cpu sentence-transformers pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1jB-z-Ter2a",
        "outputId": "7c3b5709-5d1d-45f8-dd6a-ebdb9a1c7214"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 2) PDF ë‹¤ìš´ë¡œë“œ (ìš”ì²­í•˜ì‹  ë™ì¼ íŒŒì¼ & ì¬ì‹œë„ ë¡œì§)\n",
        "# ============================================\n",
        "import requests, os, time\n",
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\"https://github.com/chatgpt-kr/openai-api-tutorial/raw/main/ch07/2020_%EA%B2%BD%EC%A0%9C%EA%B8%88%EC%9C%B5%EC%9A%A9%EC%96%B4%20700%EC%84%A0_%EA%B2%8C%EC%8B%9C.pdf\", filename=\"2020_ê²½ì œê¸ˆìœµìš©ì–´ 700ì„ _ê²Œì‹œ.pdf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parent Document Retriever ì ‘ê·¼ë°©ë²• ìš”ì•½\n",
        "\n",
        "  ğŸ¯ í•µì‹¬ ë¬¸ì œ\n",
        "\n",
        "  - ì‘ì€ ì²­í¬: ê²€ìƒ‰ì€ ì •í™•í•˜ì§€ë§Œ ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±\n",
        "  - í° ì²­í¬: ì»¨í…ìŠ¤íŠ¸ëŠ” í’ë¶€í•˜ì§€ë§Œ ê²€ìƒ‰ ì •í™•ë„ ì €í•˜\n",
        "\n",
        "  ğŸ”„ í•´ê²° ì „ëµ\n",
        "\n",
        "  ì´ì¤‘ ë¶„í•  êµ¬ì¡°ë¡œ ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ í’ë¶€í•¨ì„ ë™ì‹œ í™•ë³´\n",
        "\n",
        "  í•µì‹¬ ì•„í‚¤í…ì²˜\n",
        "\n",
        "  ì›ë³¸ ë¬¸ì„œ\n",
        "      â†“\n",
        "  Parent ì²­í¬ (1200ì) â† ì‹¤ì œ ë°˜í™˜ë˜ëŠ” ë¬¸ì„œ\n",
        "      â†“\n",
        "  Child ì²­í¬ (400ì)   â† ê²€ìƒ‰ì— ì‚¬ìš©ë˜ëŠ” ë¬¸ì„œ\n",
        "\n",
        "  ì§ˆë¬¸ â†’ vectorstore(ìì‹ ê²€ìƒ‰) â†’ ê´€ë ¨ ë¶€ëª¨ doc_id ì°¾ê¸° â†’ docstoreì—ì„œ ë¶€ëª¨ ì²­í¬ êº¼ë‚´ ë°˜í™˜\n",
        "\n",
        "  ğŸ›  êµ¬í˜„ ë©”ì»¤ë‹ˆì¦˜\n",
        "\n",
        "  1. ì´ì¤‘ ë¶„í• : Parent(1200ì) + Child(400ì) ì²­í¬ ìƒì„±\n",
        "  2. ì´ì¤‘ ì €ì¥ì†Œ:\n",
        "    - VectorStore: Child ì²­í¬ ì„ë² ë”© ì €ì¥ (ê²€ìƒ‰ìš©)\n",
        "    - InMemoryStore: Parent ì²­í¬ ì›ë³¸ ì €ì¥ (ë°˜í™˜ìš©)\n",
        "  3. ê²€ìƒ‰ íë¦„: Childë¡œ ê²€ìƒ‰ â†’ ë§¤ì¹­ëœ Parent ë°˜í™˜\n",
        "\n",
        "  ğŸ’¡ í•µì‹¬ ì¥ì \n",
        "\n",
        "  - ì •í™•í•œ ê²€ìƒ‰: ì‘ì€ Child ì²­í¬ë¡œ ì •ë°€ ê²€ìƒ‰\n",
        "  - í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸: í° Parent ì²­í¬ë¡œ ì¶©ë¶„í•œ ì •ë³´ ì œê³µ\n",
        "  - ìë™ ë§¤í•‘: Child-Parent ê´€ê³„ ìë™ ê´€ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " PDF ready: 2020_ê²½ì œê¸ˆìœµìš©ì–´ 700ì„ _ê²Œì‹œ.pdf\n",
            " ì „ì²´ í˜ì´ì§€ ìˆ˜: 371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë¶€ëª¨-ìì‹ ì²­í¬ ìƒ‰ì¸ ì¤‘...\n",
            " ìƒ‰ì¸ ì™„ë£Œ\n",
            "\n",
            " Q: ì¸í”Œë ˆì´ì…˜ì˜ ì •ì˜ì™€ ì›ì¸, ê·¸ë¦¬ê³  ê¸°ì¤€ê¸ˆë¦¬ì™€ì˜ ê´€ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
            "--- Top-3 ë¶€ëª¨ ë¬¸ì„œ ---\n",
            " 1. p.212 | 196 ê²½ì œê¸ˆìœµìš©ì–´ 700ì„  ì›ë¦¬ê¸ˆ ì—°ì²´ ë“± ê°ê´€ì ì¸ ì†ìƒ(impairment)ì˜ ì¦ê±°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ëŒ€ì†ì¶©ë‹¹ê¸ˆ ì ë¦½ì„  í—ˆìš©í•˜ê³  ìˆì–´ ëŒ€ì†ì¶©ë‹¹ê¸ˆì— ì˜ˆìƒì†ì‹¤ì„ ë°˜ì˜í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆì—ˆë‹¤. ì´ì— ë”°ë¼ ë°”ì ¤  ìë³¸ê·œì œëŠ” ëŒ€ì†ì¶©ë‹¹ê¸ˆì´ ì˜ˆìƒì†ì‹¤ì— ë¯¸ë‹¬(shortfall)ì‹œ ë™ ê¸ˆì•¡ì„ ê¸°ë³¸ì...\n",
            " 2. p.344 | 328 ê²½ì œê¸ˆìœµìš©ì–´ 700ì„  í˜„ì¬ ìš°ë¦¬ë‚˜ë¼ ì€í–‰ê¶Œì—ëŠ” ì˜¤ë§Œì›ê¶Œì— ë í˜• í™€ë¡œê·¸ë¨ì´, ë§Œì›ê³¼ ì˜¤ì²œì›ê¶Œì—ëŠ” íŒ¨ì¹˜í˜•  í™€ë¡œê·¸ë¨ì´ ê°ê° ì ìš©ë˜ì–´ ìˆë‹¤. ì˜¤ë§Œì›ê¶Œì˜ ë í˜• í™€ë¡œê·¸ë¨ì€ ì•ë©´ ì™¼ìª½ ë ë¶€ë¶„ì— ë¶€ì°©ë˜ ì–´ ìˆìœ¼ë©° ë³´ëŠ” ê°ë„ì— ë”°ë¼ ìƒï½¥ì¤‘ï½¥í•˜ 3ê³³ì—ì„œ â‘  ìš°ë¦¬ë‚˜ë¼ ì§€ë„ â‘¡ íƒœê·¹ â‘¢ 4ê´˜ ë¬´ëŠ¬...\n",
            " 3. p.336 | 320 ê²½ì œê¸ˆìœµìš©ì–´ 700ì„  ëœ»í•œë‹¤. ì´ëŠ” í˜ì‹ ì˜ ì •ë„ì— ë”°ë¼ ì „í†µì (traditional) í•€í…Œí¬ì™€ ì‹ í¥(emergent) í•€í…Œí¬ë¡œ  êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤. ì „í†µì  í•€í…Œí¬ëŠ” ê¸°ì¡´ ê¸ˆìœµì„œë¹„ìŠ¤ì˜ ê°€ì¹˜ì‚¬ìŠ¬ ì•ˆì—ì„œ ê·¸ ì„œë¹„ìŠ¤ì˜  íš¨ìœ¨ì„ ë†’ì´ëŠ” ì—­í• ì„ í•œë‹¤. ì¦‰ ê¸°ì¡´ ê¸ˆìœµì„œë¹„ìŠ¤ë¥¼ ìë™í™”í•˜ë ¤ëŠ” ê¸ˆìœµíšŒ...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "pdf_path = \"2020_ê²½ì œê¸ˆìœµìš©ì–´ 700ì„ _ê²Œì‹œ.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_path) or os.path.getsize(pdf_path) == 0:\n",
        "    r = requests.get(url, stream=True)\n",
        "    r.raise_for_status()\n",
        "    with open(pdf_path, \"wb\") as f:\n",
        "        for chunk in r.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "print(\" PDF ready:\", pdf_path)\n",
        "\n",
        "# ============================================\n",
        "# 3) PDF ë¡œë“œ & Parent/Child ì²­í¬ ë¶„í• \n",
        "# ============================================\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "docs = loader.load()\n",
        "print(f\" ì „ì²´ í˜ì´ì§€ ìˆ˜: {len(docs)}\")\n",
        "\n",
        "# Parent = ê¸´ ë©ì–´ë¦¬, Child = ê²€ìƒ‰ìš© ì‘ì€ ë©ì–´ë¦¬\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=120)\n",
        "child_splitter  = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=40)\n",
        "\n",
        "# ============================================\n",
        "# 4) ì„ë² ë”© & ë¹ˆ FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
        "# ============================================\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "# embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\", chunk_size=100)\n",
        "\n",
        "# ì •ì„: IndexFlatL2ë¡œ ë¹ˆ ì¸ë±ìŠ¤ ìƒì„±\n",
        "from langchain_community.vectorstores.faiss import FAISS, dependable_faiss_import\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "\n",
        "faiss = dependable_faiss_import()\n",
        "dim = len(embedding.embed_query(\"dummy\"))  # ì„ë² ë”© ì°¨ì›\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "vectorstore = FAISS(embedding.embed_query, index, InMemoryDocstore(), {})\n",
        "\n",
        "# ============================================\n",
        "# 5) InMemoryStore (ë¶€ëª¨ ë¬¸ì„œ ì €ì¥ì†Œ)\n",
        "# ============================================\n",
        "try:\n",
        "    from langchain.storage import InMemoryStore\n",
        "except ImportError:\n",
        "    class InMemoryStore(dict):\n",
        "        def mset(self, items):\n",
        "            for k, v in items:\n",
        "                self[k] = v\n",
        "docstore = InMemoryStore()\n",
        "\n",
        "# ============================================\n",
        "# 6) ParentDocumentRetriever ìƒì„±\n",
        "# ============================================\n",
        "try:\n",
        "    from langchain.retrievers import ParentDocumentRetriever\n",
        "except ImportError:\n",
        "    from langchain_community.retrievers import ParentDocumentRetriever\n",
        "\n",
        "parent_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=docstore,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# 7) ë¬¸ì„œ ìƒ‰ì¸\n",
        "# ============================================\n",
        "print(\"ë¶€ëª¨-ìì‹ ì²­í¬ ìƒ‰ì¸ ì¤‘...\")\n",
        "parent_retriever.add_documents(docs)\n",
        "print(\" ìƒ‰ì¸ ì™„ë£Œ\")\n",
        "\n",
        "# ============================================\n",
        "# 8) ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "# ============================================\n",
        "def ask(q, k=3):\n",
        "    hits = parent_retriever.get_relevant_documents(q)\n",
        "    print(f\"\\n Q: {q}\\n--- Top-{min(k,len(hits))} ë¶€ëª¨ ë¬¸ì„œ ---\")\n",
        "    for i, d in enumerate(hits[:k], 1):\n",
        "        page = d.metadata.get(\"page\", \"?\")\n",
        "        context = d.page_content[:160].replace('\\n',' ')\n",
        "        print(f\"{i:>2}. p.{page} | {context}...\")\n",
        "\n",
        "ask(\"ì¸í”Œë ˆì´ì…˜ì˜ ì •ì˜ì™€ ì›ì¸, ê·¸ë¦¬ê³  ê¸°ì¤€ê¸ˆë¦¬ì™€ì˜ ê´€ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\")\n",
        "# ask(\"í™˜ìœ¨ ë³€ë™ì´ ë¬¼ê°€ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ë‚˜ìš”?\")\n",
        "# ask(\"ìŠ¤íƒœê·¸í”Œë ˆì´ì…˜ì´ ë¬´ì—‡ì´ë©° ì •ì±… ëŒ€ì‘ì˜ ì–´ë ¤ì›€ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Q: ê°€ê³„ì‹ ìš©í†µê³„ ì— ëŒ€í•´ ì„¤ëª…í•´\n",
            "--- Top-3 ë¶€ëª¨ ë¬¸ì„œ ---\n",
            " 1. p.213 | 197 ã…‡  ì˜µì…˜ë§¤ë„ìì—ê²Œ í”„ë¦¬ë¯¸ì—„ì„ ì§€ê¸‰í•˜ë©° ë°˜ëŒ€ë¡œ ì˜µì…˜ë§¤ë„ìëŠ” í”„ë¦¬ë¯¸ì—„ì„ ë°›ëŠ” ëŒ€ì‹  ì˜µì…˜ ë§¤ì…ìì˜ ì˜µì…˜ í–‰ì‚¬ì— ë”°ë¼ ë°œìƒí•˜ëŠ” ìì‹ ì˜ ì˜ë¬´ë¥¼ ì´í–‰í•  ì±…ì„ì„ ë¶€ë‹´í•œë‹¤. ì˜µì…˜ê±°ë˜ ì˜ ì†ìµì€ í–‰ì‚¬ê°€ê²©, í˜„ì¬ê°€ê²© ë° í”„ë¦¬ë¯¸ì—„ì— ì˜í•´ ê²°ì •ëœë‹¤. í•œí¸ ì˜µì…˜ì˜ ê°€ê²©ì´ ì–´ë–»ê²Œ  ê²°ì •ë˜ëŠ”ê°€ì— ëŒ€í•´ì„œëŠ”...\n",
            " 2. p.271 | 255 ã…ˆ  ì œ1ì°¨ í†µí™”ì¡°ì¹˜  í•œêµ­ì „ìŸì˜ ì—¬íŒŒë¡œ ì‚°ì—…í™œë™ì´ í¬ê²Œ ìœ„ì¶•ë˜ê³  ë¬¼ê°€ê°€ ê¸‰ë“±í•˜ëŠ” ë“± ê²½ì œê°€ í° í˜¼ë€ì—  ë¹ ì§ì— ë”°ë¼ ì´ë¥¼ íƒ€ê°œí•˜ê¸° ìœ„í•˜ì—¬ 1953ë…„ 2ì›” 15ì¼ í™”íë‹¨ìœ„ë¥¼ â€˜ì›(åœ“)â€™ì—ì„œ â€˜í™˜(åœœ)â€™ìœ¼ë¡œ  ë³€ê²½í•˜ê³  100ëŒ€ 1ë¡œ ì ˆí•˜(100åœ“ â†’ 1åœœ)í•˜ëŠ” ê¸´ê¸‰í†µí™”ì¡°ì¹˜ë¥¼ ë‹¨í–‰í•˜...\n",
            " 3. p.116 | 100 ê²½ì œê¸ˆìœµìš©ì–´ 700ì„   ì—°ê´€ê²€ìƒ‰ì–´ : ì¡°ì„¸ë¶€ë‹´ë¥  ë ˆê·¸í…Œí¬ ë ˆê·¸í…Œí¬(RT; RegTech, Regulatory Technology)ëŠ” ê¸ˆìœµì—… ë“± ì‚°ì—… ì „ë°˜ì— ê±¸ì³ í˜ì‹   ì •ë³´ê¸°ìˆ (IT)ê³¼ ê·œì œë¥¼ ê²°í•©í•˜ì—¬ ê·œì œê´€ë ¨ ìš”êµ¬ì‚¬í•­ ë° ì ˆì°¨ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ  ë˜ëŠ”  íšŒì‚¬ë¥¼ ëœ»í•œë‹¤. ì´ëŠ” ê¸ˆìœµ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ask(\"ê°€ê³„ì‹ ìš©í†µê³„ ì— ëŒ€í•´ ì„¤ëª…í•´\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tracers.stdout import ConsoleCallbackHandler\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "template = \"\"\"ë‹¹ì‹ ì€ í•œêµ­ì€í–‰ì—ì„œ ë§Œë“  ê¸ˆìœµ ìš©ì–´ë¥¼ ì„¤ëª…í•´ì£¼ëŠ” ê¸ˆìœµí•´ì„¤ìì…ë‹ˆë‹¤.\n",
        "ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n",
        "ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ ë‹µë³€í•  ìˆ˜ ì—†ë‹¤ê³  í•˜ì„¸ìš”. ë°˜ë§ë¡œ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        "    retriever=parent_retriever,\n",
        "    return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(label=\"ê²½ì œê¸ˆìœµìš©ì–´ ì±—ë´‡\") # ì±—ë´‡ ë ˆì´ë¸”ì„ ì¢Œì¸¡ ìƒë‹¨ì— êµ¬ì„±\n",
        "    msg = gr.Textbox(label=\"ì§ˆë¬¸í•´ì£¼ì„¸ìš”!\")  # í•˜ë‹¨ì˜ ì±„íŒ…ì°½ ë ˆì´ë¸”\n",
        "    clear = gr.Button(\"ëŒ€í™” ì´ˆê¸°í™”\")  # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼\n",
        "\n",
        "    # ì±—ë´‡ì˜ ë‹µë³€ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
        "    def respond(message, chat_history):\n",
        "      result = qa_chain(message, \n",
        "                        callbacks=[ConsoleCallbackHandler()])\n",
        "      bot_message = result['result']\n",
        "\n",
        "      # ì±„íŒ… ê¸°ë¡ì— ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì™€ ë´‡ì˜ ì‘ë‹µì„ ì¶”ê°€\n",
        "      chat_history.append((message, bot_message))\n",
        "      return \"\", chat_history\n",
        "\n",
        "    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì œì¶œ(submit)í•˜ë©´ respond í•¨ìˆ˜ê°€ í˜¸ì¶œ\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "    # 'ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì±„íŒ… ê¸°ë¡ì„ ì´ˆê¸°í™”\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
