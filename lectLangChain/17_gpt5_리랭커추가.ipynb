{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vXOkR1mTQPPW",
        "outputId": "40e057b9-3ba1-4873-8248-b45d9cbf10e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.28)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.32)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.0)\n",
            "Requirement already satisfied: FlagEmbedding in /usr/local/lib/python3.12/dist-packages (1.3.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.100.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (4.55.2)\n",
            "Requirement already satisfied: datasets>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (4.0.0)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (1.10.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (0.17.0)\n",
            "Requirement already satisfied: ir-datasets in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (0.5.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.70.16)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44.2->FlagEmbedding) (0.21.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (4.13.4)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (2.6.0)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (5.4.0)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (2.6)\n",
            "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (4.4.4)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (0.2.5)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (0.2.5)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (0.1.9)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (3.4.0)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (0.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding) (2.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding) (1.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langchain langchain-community langchain-openai pypdf faiss-cpu gradio FlagEmbedding sentence-transformers tiktoken rank_bm25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJl9UcJnYa2o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# OpenAI API ÌÇ§ ÏÑ§Ï†ï (Î≥∏Ïù∏Ïùò API ÌÇ§Î°ú Î≥ÄÍ≤Ω)\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±\n",
        "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# from google.colab import userdata\n",
        "# api_key=userdata.get('api_key')\n",
        "# os.environ[\"OPENAI_API_KEY\"] = api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "5TH0mN7uQJYk",
        "outputId": "16f38421-299c-423f-9f07-3aab6f3301fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pages: 742 from 2 PDF(s)\n",
            "Chunks: 2306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4230254922.py:204: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  out = gr.Chatbot(label=\"ÎãµÎ≥Ä\", bubble_full_width=False)\n",
            "/tmp/ipython-input-4230254922.py:204: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
            "  out = gr.Chatbot(label=\"ÎãµÎ≥Ä\", bubble_full_width=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0907ce7358b6b15ef9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0907ce7358b6b15ef9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "# üöÄ Colab Chatbot: Ensemble Retriever (BM25 + FAISS) + Cross-Encoder Reranker\n",
        "# - 1Ï∞®: ÏïôÏÉÅÎ∏î Î¶¨Ìä∏Î¶¨Î≤Ñ (FAISS dense + BM25 sparse)\n",
        "# - 2Ï∞®: Cross-Encoder reranking (BAAI/bge-reranker-large)\n",
        "# - ÏµúÏ¢Ö ÏßàÏùòÏùëÎãµ: OpenAI Chat(Í∏∞Î≥∏)\n",
        "# - Gradio UI Ï†úÍ≥µ\n",
        "#\n",
        "# ‚ö†Ô∏è ÏÑ§Ïπò Î™ÖÎ†πÏùÄ Î≥∏ Ïä§ÌÅ¨Î¶ΩÌä∏ÏóêÏÑú Ïã§ÌñâÌïòÏßÄ ÏïäÏäµÎãàÎã§. ColabÏóêÏÑúÎäî ÏïÑÎûòÎ•º Î≥ÑÎèÑ ÏÖÄÎ°ú Ïã§ÌñâÌïòÏÑ∏Ïöî:\n",
        "# %pip install -U langchain langchain-community langchain-openai pypdf faiss-cpu gradio FlagEmbedding sentence-transformers rank-bm25 tiktoken\n",
        "\n",
        "# ==========================\n",
        "# 1) Imports & Env Checks\n",
        "# ==========================\n",
        "import os, urllib.request, glob, textwrap\n",
        "from typing import List\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from FlagEmbedding import FlagReranker\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "from rank_bm25 import BM25Okapi\n",
        "import gradio as gr\n",
        "\n",
        "# ==========================\n",
        "# 2) Load Documents\n",
        "# ==========================\n",
        "\n",
        "PDF_URL = \"https://github.com/chatgpt-kr/openai-api-tutorial/raw/main/ch07/2020_%EA%B2%BD%EC%A0%9C%EA%B8%88%EC%9C%B5%EC%9A%94%EC%96%B4%20700%EC%84%A0_%EA%B2%8C%EC%8B%9C.pdf\"\n",
        "PDF_PATH = \"2020_Í≤ΩÏ†úÍ∏àÏúµÏö©Ïñ¥ 700ÏÑ†_Í≤åÏãú.pdf\"\n",
        "\n",
        "try:\n",
        "    if not os.path.exists(PDF_PATH):\n",
        "        urllib.request.urlretrieve(PDF_URL, PDF_PATH)\n",
        "except Exception as e:\n",
        "    print(\"[Warn] PDF download error:\", e)\n",
        "\n",
        "pdf_files = sorted(glob.glob(\"*.pdf\"))\n",
        "if not pdf_files:\n",
        "    raise FileNotFoundError(\"No PDFs found ‚Äì please upload or place PDFs in the working directory.\")\n",
        "\n",
        "all_docs: List[Document] = []\n",
        "for f in pdf_files:\n",
        "    try:\n",
        "        loader = PyPDFLoader(f)\n",
        "        all_docs.extend(loader.load())\n",
        "    except Exception as e:\n",
        "        print(f\"[Warn] Failed to load {f}: {e}\")\n",
        "\n",
        "print(f\"Loaded pages: {len(all_docs)} from {len(pdf_files)} PDF(s)\")\n",
        "\n",
        "# ==========================\n",
        "# 3) Chunking\n",
        "# ==========================\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,   # smaller chunks to avoid hitting token limits\n",
        "    chunk_overlap=100,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        ")\n",
        "chunked_docs = text_splitter.split_documents(all_docs)\n",
        "print(\"Chunks:\", len(chunked_docs))\n",
        "\n",
        "# ==========================\n",
        "# 4) Build FAISS index (Dense Retriever)\n",
        "# ==========================\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "\n",
        "# Process documents in batches to avoid exceeding token limits\n",
        "batch_size = 500 # Adjust batch size based on your document length and token limit\n",
        "vectordb = None\n",
        "\n",
        "for i in range(0, len(chunked_docs), batch_size):\n",
        "    batch = chunked_docs[i : i + batch_size]\n",
        "    if vectordb is None:\n",
        "        vectordb = FAISS.from_documents(batch, embeddings)\n",
        "    else:\n",
        "        vectordb.add_documents(batch)\n",
        "\n",
        "# ==========================\n",
        "# 5) Build BM25 index (Sparse Retriever)\n",
        "# ==========================\n",
        "tokenized_corpus = [doc.page_content.split() for doc in chunked_docs]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# ==========================\n",
        "# 6) Ensemble Retriever (Dense + Sparse)\n",
        "# ==========================\n",
        "def make_doc_key(doc: Document) -> str:\n",
        "    \"\"\"Í∞Å DocumentÎ•º ÎåÄÌëúÌï† Í≥†Ïú† key ÏÉùÏÑ±\"\"\"\n",
        "    src = doc.metadata.get(\"source\", \"\")\n",
        "    page = str(doc.metadata.get(\"page\", \"\"))\n",
        "    snippet = (doc.page_content or \"\")[:50]  # ÏïûÎ∂ÄÎ∂Ñ 50ÏûêÎßå\n",
        "    return f\"{src}-{page}-{snippet}\"\n",
        "\n",
        "def ensemble_retrieve(query: str, k: int = 20, alpha: float = 0.5) -> List[Document]:\n",
        "    \"\"\"\n",
        "    ÏïôÏÉÅÎ∏î Î¶¨Ìä∏Î¶¨Î≤Ñ: FAISS (dense) + BM25 (sparse)\n",
        "    alpha: dense Ï†êÏàò Í∞ÄÏ§ëÏπò (0~1)\n",
        "    \"\"\"\n",
        "    # Dense\n",
        "    dense_docs = vectordb.similarity_search_with_score(query, k=k)\n",
        "    dense_scores = {make_doc_key(d): s for d, s in dense_docs}\n",
        "\n",
        "    # Sparse\n",
        "    bm25_scores = bm25.get_scores(query.split())\n",
        "    bm25_ranked = sorted(zip(chunked_docs, bm25_scores), key=lambda x: x[1], reverse=True)[:k]\n",
        "    bm25_scores_dict = {make_doc_key(d): s for d, s in bm25_ranked}\n",
        "\n",
        "    # Í≤∞Ìï©\n",
        "    combined = {}\n",
        "    doc_map = {}\n",
        "    for doc in chunked_docs:\n",
        "        key = make_doc_key(doc)\n",
        "        d_score = dense_scores.get(key, 0.0)\n",
        "        b_score = bm25_scores_dict.get(key, 0.0)\n",
        "        score = alpha * d_score + (1 - alpha) * b_score\n",
        "        if score > 0:\n",
        "            combined[key] = score\n",
        "            doc_map[key] = doc\n",
        "\n",
        "    ranked = sorted(combined.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "    return [doc_map[key] for key, _ in ranked]\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# 7) Cross-Encoder Reranker (Stage 2)\n",
        "# ==========================\n",
        "reranker = FlagReranker(\"BAAI/bge-reranker-large\", use_fp16=True)\n",
        "\n",
        "def rerank_with_bge(query: str, docs: List[Document], top_k: int = 5) -> List[Document]:\n",
        "    pairs = [[query, d.page_content] for d in docs]\n",
        "    scores = reranker.compute_score(pairs, normalize=True)\n",
        "    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
        "    return [d for d, _ in ranked[:top_k]]\n",
        "\n",
        "# ==========================\n",
        "# 8) LLM & Prompt\n",
        "# ==========================\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=512)\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"ÎãπÏã†ÏùÄ Ïã†Î¢∞Ìï† Ïàò ÏûàÎäî ÌïúÍµ≠Ïñ¥ Ï†ÑÎ¨∏Í∞Ä ÎπÑÏÑúÏûÖÎãàÎã§. Îã§Ïùå Î¨∏ÏÑúÎ•º Î∞îÌÉïÏúºÎ°ú ÏßàÎ¨∏Ïóê Ï†ïÌôïÌïòÍ≥† Í∞ÑÍ≤∞ÌïòÍ≤å ÎãµÌïòÏÑ∏Ïöî.\\n\"\n",
        "    \"- Ï£ºÏñ¥ÏßÑ Î¨∏Îß•Îßå ÏÇ¨Ïö©ÌïòÍ≥†, Î™®Î•¥Î©¥ Î™®Î•∏Îã§Í≥† ÎßêÌïòÏÑ∏Ïöî.\\n\"\n",
        "    \"- Í¥ÄÎ†® Ï°∞Ìï≠/Ïö©Ïñ¥/Ï†ïÏùòÍ∞Ä ÏûàÏúºÎ©¥ Ïù∏Ïö© ÌòïÌÉúÎ°ú ÏßßÍ≤å ÌëúÏãúÌïòÏÑ∏Ïöî.\\n\"\n",
        ")\n",
        "\n",
        "USER_PROMPT_TEMPLATE = (\n",
        "    \"ÏßàÎ¨∏: {question}\\n\\n\"\n",
        "    \"Ï∞∏Í≥† Î¨∏Îß•:\\n{context}\\n\\n\"\n",
        "    \"ÏßÄÏπ®:\\n- ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥Ä\\n- ÌïµÏã¨ bullet 3~5Í∞ú\\n- ÌïÑÏöîÌïú Í≤ΩÏö∞ Ìïú Ï§Ñ Ïù∏Ïö© Ìè¨Ìï®\\n\"\n",
        ")\n",
        "\n",
        "# ==========================\n",
        "# 9) Helpers\n",
        "# ==========================\n",
        "def build_context(docs: List[Document], max_chars: int = 1500) -> str:\n",
        "    ctx = []\n",
        "    total_len = 0\n",
        "    for i, d in enumerate(docs, 1):\n",
        "        meta = d.metadata\n",
        "        loc = f\"p{meta.get('page', '?')}\" if isinstance(meta.get('page'), int) else \"\"\n",
        "        snippet = textwrap.shorten(d.page_content, width=500, placeholder=\" ‚Ä¶\")\n",
        "        if total_len + len(snippet) > max_chars:\n",
        "            break\n",
        "        ctx.append(f\"[Î¨∏ÏÑú {i}{' '+loc if loc else ''}]\\n\" + snippet)\n",
        "        total_len += len(snippet)\n",
        "    return \"\\n\\n\".join(ctx)\n",
        "\n",
        "# ==========================\n",
        "# 10) QA function (Ensemble + Reranker)\n",
        "# ==========================\n",
        "def answer_question(query: str, k1: int = 20, k2: int = 5, alpha: float = 0.5):\n",
        "    initial_docs = ensemble_retrieve(query, k=k1, alpha=alpha)\n",
        "    reranked = rerank_with_bge(query, initial_docs, top_k=k2)\n",
        "    context = build_context(reranked)\n",
        "    user_prompt = USER_PROMPT_TEMPLATE.format(question=query, context=context)\n",
        "    messages = [\n",
        "        SystemMessage(content=SYSTEM_PROMPT),\n",
        "        HumanMessage(content=user_prompt),\n",
        "    ]\n",
        "    resp = llm.invoke(messages)\n",
        "    return resp.content, reranked\n",
        "\n",
        "# ==========================\n",
        "# 11) Gradio Chat UI\n",
        "# ==========================\n",
        "with gr.Blocks(title=\"Ensemble + BGE Rerank QA\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üìö Ensemble (FAISS + BM25) + BGE Cross‚ÄëEncoder Rerank QA\n",
        "        1Ï∞®: ÏïôÏÉÅÎ∏î Î¶¨Ìä∏Î¶¨Î≤Ñ(FAISS + BM25) ‚Üí 2Ï∞®: **BAAI/bge-reranker-large**Î°ú Ï†ïÎ∞Ä Ïû¨Ï†ïÎ†¨ ‚Üí LLM ÏµúÏ¢Ö ÎãµÎ≥Ä\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        inp = gr.Textbox(label=\"ÏßàÎ¨∏ ÏûÖÎ†•\", placeholder=\"Ïòà: Í∏àÏúµÌÜµÌôîÏúÑÏõêÌöåÏùò Ïó≠Ìï†ÏùÄ?\")\n",
        "    with gr.Row():\n",
        "        k1_slider = gr.Slider(5, 50, value=20, step=1, label=\"k1: 1Ï∞® Í≤ÄÏÉâ Í∞úÏàò\")\n",
        "        k2_slider = gr.Slider(1, 10, value=5, step=1, label=\"k2: 2Ï∞® Ïª®ÌÖçÏä§Ìä∏ Í∞úÏàò\")\n",
        "        alpha_slider = gr.Slider(0, 1, value=0.5, step=0.1, label=\"alpha: Dense/Sparse Í∞ÄÏ§ëÏπò\")\n",
        "    with gr.Row():\n",
        "        btn = gr.Button(\"ÏßàÎ¨∏ÌïòÍ∏∞\", variant=\"primary\")\n",
        "    out = gr.Chatbot(label=\"ÎãµÎ≥Ä\", bubble_full_width=False)\n",
        "    with gr.Accordion(\"üìé ÏÇ¨Ïö©Îêú Í∑ºÍ±∞ Î¨∏Îß• (Top-k)\", open=False):\n",
        "        ctx = gr.JSON(label=\"Reranked Context Metadata\")\n",
        "\n",
        "    def _run(q, k1, k2, alpha, history):\n",
        "        if not q or not q.strip():\n",
        "            return history, None\n",
        "        try:\n",
        "            ans, used_docs = answer_question(q, int(k1), int(k2), float(alpha))\n",
        "            meta_view = [\n",
        "                {\n",
        "                    \"source\": d.metadata.get(\"source\"),\n",
        "                    \"page\": d.metadata.get(\"page\"),\n",
        "                    \"chars\": len(d.page_content),\n",
        "                }\n",
        "                for d in used_docs\n",
        "            ]\n",
        "            history = (history or []) + [(q, ans)]\n",
        "            return history, meta_view\n",
        "        except Exception as e:\n",
        "            history = (history or []) + [(q, f\"Ïò§Î•ò: {e}\")]\n",
        "            return history, None\n",
        "\n",
        "    btn.click(_run, [inp, k1_slider, k2_slider, alpha_slider, out], [out, ctx])\n",
        "    inp.submit(_run, [inp, k1_slider, k2_slider, alpha_slider, out], [out, ctx])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
