{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 텍스트 요약\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "DocumentEncoder\n",
        "\n",
        "입력 문서(문장)를 임베딩 후 양방향 LSTM으로 인코딩합니다.\n",
        "LSTM의 출력(각 토큰별 특징)과 마지막 hidden state를 hidden_size로 변환해 반환합니다.\n",
        "즉, 문서 전체를 벡터 시퀀스로 변환해 요약에 필요한 정보를 추출합니다.\n",
        "\n",
        "\n",
        "SummaryDecoder\n",
        "\n",
        "인코더의 출력과 이전 hidden state를 받아 어텐션(attention)으로 컨텍스트 벡터를 계산합니다.\n",
        "임베딩된 입력 토큰과 컨텍스트 벡터를 결합해 LSTM에 입력합니다.\n",
        "LSTM의 출력을 통해 다음 요약 토큰을 예측합니다.\n",
        "어텐션을 사용해 인코더의 중요한 부분을 동적으로 참고하며 요약을 생성합니다.\n",
        "즉, DocumentEncoder는 문서의 의미를 벡터로 추출하고, SummaryDecoder는 그 정보를 바탕으로 어텐션을 활용해 요약을 생성하는 역할입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os8fTEv-Ue7M",
        "outputId": "cb5d739b-31f0-4de7-efbb-d40b629cf3a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UpwOvWfUb1C",
        "outputId": "0860603e-fe85-4441-8215-835797e5cd1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서 어휘 크기: 195\n",
            "요약 어휘 크기: 62\n",
            "요약 모델 훈련 시작...\n",
            "Epoch 0, Loss: 20.8162\n",
            "Epoch 40, Loss: 0.0663\n",
            "Epoch 80, Loss: 0.0228\n",
            "Epoch 120, Loss: 0.0121\n",
            "Epoch 160, Loss: 0.0076\n",
            "\n",
            "=== 텍스트 요약 결과 ===\n",
            "문서 1:\n",
            "원문: 스마트폰은 현대인의 필수품이 되었습니다. \n",
            "    통화, 메시지 전송뿐만 아니라 인터넷 검색, 사진 촬영, \n",
            "    게임, 음악 감상 등 다양한 기능을 제공합니다.\n",
            "    특히 모바일 앱의 발달로 은행 업무, 쇼핑, \n",
            "    교육 등의 활동도 스마트폰으로 가능해졌습니다.\n",
            "요약: 전자상거래는 코로나19 이후 급성장하며 모바일 쇼핑과 새로운 판매 방식이 등장하고 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 필요하다 증가로 인한 지구 온난화\n",
            "--------------------------------------------------\n",
            "문서 2:\n",
            "원문: 건강한 식습관은 우리 몸에 매우 중요합니다.\n",
            "    균형 잡힌 영양소 섭취와 규칙적인 식사가 필요합니다.\n",
            "    과도한 당분과 지방 섭취는 피하고 신선한 채소와 \n",
            "    과일을 많이 먹어야 합니다. 충분한 수분 섭취도 잊지 말아야 합니다.\n",
            "요약: 전자상거래는 코로나19 이후 급성장하며 모바일 쇼핑과 새로운 판매 방식이 등장하고 있다 있다 있다 있다 있다 있다 필요하다 증가로 인한 지구 온난화 현상으로 재생에너지 확대가 필요하다\n",
            "--------------------------------------------------\n",
            "\n",
            "=== 훈련 데이터 요약 성능 ===\n",
            "문서 1 ROUGE-1 F1: 1.000\n",
            "참조: AI는 우리 생활 곳곳에 활용되고 있으며 딥러닝 발전으로 다양한 분야에서 혁신을 이루고 있다\n",
            "생성: ai는 우리 생활 곳곳에 활용되고 있으며 딥러닝 발전으로 다양한 분야에서 혁신을 이루고 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다\n",
            "------------------------------\n",
            "문서 2 ROUGE-1 F1: 1.000\n",
            "참조: 기후 변화는 이산화탄소 증가로 인한 지구 온난화 현상으로 재생에너지 확대가 필요하다\n",
            "생성: 기후 변화는 이산화탄소 증가로 인한 지구 온난화 현상으로 재생에너지 확대가 필요하다 필요하다 필요하다 필요하다 필요하다 인한 지구 온난화 현상으로 재생에너지 확대가 필요하다 필요하다 필요하다 필요하다\n",
            "------------------------------\n",
            "문서 3 ROUGE-1 F1: 1.000\n",
            "참조: 코로나19로 인해 재택근무 온라인 수업 등 디지털 기술 기반의 언택트 문화가 확산되었다\n",
            "생성: 코로나19로 인해 재택근무 온라인 수업 등 디지털 기술 기반의 언택트 문화가 확산되었다 확산되었다 확산되었다 확산되었다 기반의 언택트 문화가 확산되었다 확산되었다 확산되었다 기반의 언택트 문화가 확산되었다\n",
            "------------------------------\n",
            "문서 4 ROUGE-1 F1: 1.000\n",
            "참조: 전자상거래는 코로나19 이후 급성장하며 모바일 쇼핑과 새로운 판매 방식이 등장하고 있다\n",
            "생성: 전자상거래는 코로나19 이후 급성장하며 모바일 쇼핑과 새로운 판매 방식이 등장하고 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다 있다\n",
            "------------------------------\n",
            "문서 5 ROUGE-1 F1: 1.000\n",
            "참조: 환경 보호를 위해 개인과 정부 기업의 노력이 필요하며 지속가능한 발전을 위한 참여가 중요하다\n",
            "생성: 환경 보호를 위해 개인과 정부 기업의 노력이 필요하며 지속가능한 발전을 위한 참여가 중요하다 중요하다 참여가 중요하다 중요하다 참여가 중요하다 중요하다 참여가 중요하다 중요하다 참여가 중요하다\n",
            "------------------------------\n",
            "평균 ROUGE-1 F1: 1.000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# 샘플 텍스트 요약 데이터 (문서-요약 쌍)\n",
        "documents = [\n",
        "    \"\"\"\n",
        "    인공지능은 현재 우리 생활의 많은 부분에 영향을 미치고 있습니다.\n",
        "    스마트폰의 음성 인식, 검색 엔진의 결과 추천, 온라인 쇼핑의 상품 추천 등이\n",
        "    모두 AI 기술의 응용 사례입니다. 특히 딥러닝의 발전으로 이미지 인식,\n",
        "    자연어 처리, 게임 AI 등 다양한 분야에서 혁신적인 성과를 보이고 있습니다.\n",
        "    앞으로 AI는 의료, 교육, 교통 등 더 많은 분야에서 활용될 것으로 예상됩니다.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    기후 변화는 지구 온난화로 인해 발생하는 현상으로, 전 세계적으로 심각한\n",
        "    문제가 되고 있습니다. 이산화탄소 배출량 증가가 주요 원인이며, 이로 인해\n",
        "    극지방의 빙하가 녹고 해수면이 상승하고 있습니다. 또한 극한 기후 현상이\n",
        "    빈번해지면서 가뭄, 홍수, 태풍 등의 자연재해가 증가하고 있습니다.\n",
        "    이를 해결하기 위해서는 재생에너지 사용 확대와 탄소 배출 감소가 필요합니다.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    코로나19 팬데믹은 전 세계 사람들의 생활 방식을 크게 바꾸어 놓았습니다.\n",
        "    재택근무와 온라인 수업이 일반화되면서 디지털 기술의 중요성이 더욱 부각되었습니다.\n",
        "    또한 언택트 문화가 확산되면서 온라인 쇼핑, 배달 서비스, 화상 회의 등이\n",
        "    급속히 성장했습니다. 백신 개발과 보급을 통해 상황이 개선되고 있지만,\n",
        "    팬데믹이 가져온 변화들은 앞으로도 지속될 것으로 보입니다.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    전자상거래 시장은 코로나19 이후 급속한 성장을 보이고 있습니다.\n",
        "    온라인 쇼핑의 편의성과 다양한 상품 선택권으로 인해 소비자들의\n",
        "    선호도가 높아지고 있습니다. 특히 모바일 쇼핑의 증가가 두드러지며,\n",
        "    소셜 커머스와 라이브 쇼핑 등 새로운 형태의 판매 방식도 등장하고 있습니다.\n",
        "    기업들은 개인화된 추천 시스템과 빠른 배송 서비스를 통해 경쟁력을 높이고 있습니다.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    환경 보호는 현재 가장 중요한 글로벌 이슈 중 하나입니다.\n",
        "    플라스틱 사용 줄이기, 재활용, 에너지 절약 등 개인 차원의 노력이 필요합니다.\n",
        "    정부와 기업들도 친환경 정책과 기술 개발에 투자하고 있습니다.\n",
        "    지속가능한 발전을 위해서는 모든 사람의 참여가 중요합니다.\n",
        "    미래 세대를 위해 지금부터 행동해야 합니다.\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "summaries = [\n",
        "    \"AI는 우리 생활 곳곳에 활용되고 있으며 딥러닝 발전으로 다양한 분야에서 혁신을 이루고 있다\",\n",
        "    \"기후 변화는 이산화탄소 증가로 인한 지구 온난화 현상으로 재생에너지 확대가 필요하다\",\n",
        "    \"코로나19로 인해 재택근무 온라인 수업 등 디지털 기술 기반의 언택트 문화가 확산되었다\",\n",
        "    \"전자상거래는 코로나19 이후 급성장하며 모바일 쇼핑과 새로운 판매 방식이 등장하고 있다\",\n",
        "    \"환경 보호를 위해 개인과 정부 기업의 노력이 필요하며 지속가능한 발전을 위한 참여가 중요하다\"\n",
        "]\n",
        "\n",
        "# 특수 토큰 정의\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "\n",
        "# 언어 클래스 (번역 예제와 동일)\n",
        "class Language:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n",
        "        self.n_words = 3\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# 텍스트 전처리\n",
        "def preprocess_text(text):\n",
        "    # 줄바꿈 제거 및 공백 정리\n",
        "    text = re.sub(r'\\s+', ' ', text.strip())\n",
        "    # 구두점 제거\n",
        "    text = re.sub(r'[.!?,:;()]', '', text)\n",
        "    return text.lower()\n",
        "\n",
        "# 언어 모델 구축\n",
        "doc_lang = Language('document')\n",
        "summary_lang = Language('summary')\n",
        "\n",
        "# 전처리된 문서-요약 쌍\n",
        "pairs = []\n",
        "for doc, summ in zip(documents, summaries):\n",
        "    doc_processed = preprocess_text(doc)\n",
        "    summ_processed = preprocess_text(summ)\n",
        "    pairs.append([doc_processed, summ_processed])\n",
        "    doc_lang.addSentence(doc_processed)\n",
        "    summary_lang.addSentence(summ_processed)\n",
        "\n",
        "print(f\"문서 어휘 크기: {doc_lang.n_words}\")\n",
        "print(f\"요약 어휘 크기: {summary_lang.n_words}\")\n",
        "\n",
        "# 인코더 (문서 인코더) - 차원 통일\n",
        "class DocumentEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
        "        super(DocumentEncoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers,\n",
        "                           batch_first=True, bidirectional=True)\n",
        "\n",
        "        # bidirectional LSTM 출력을 hidden_size로 맞춤\n",
        "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.fc_output = nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # 양방향 LSTM 출력을 hidden_size로 변환\n",
        "        outputs = self.fc_output(outputs)  # [batch, seq_len, hidden_size]\n",
        "\n",
        "        # 양방향 LSTM의 마지막 hidden state 결합\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        hidden = self.fc_hidden(hidden).unsqueeze(0)  # [1, batch, hidden_size]\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "# 어텐션 디코더 (요약 디코더) - 간단한 어텐션\n",
        "class SummaryDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=1, dropout_p=0.1):\n",
        "        super(SummaryDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.lstm = nn.LSTM(hidden_size * 2, hidden_size, num_layers, batch_first=True)  # 임베딩 + 컨텍스트\n",
        "\n",
        "        # 어텐션 메커니즘\n",
        "        self.attention = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.attn_v = nn.Linear(hidden_size, 1)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
        "        # 입력 토큰 차원 조정\n",
        "        if input_token.dim() == 1:\n",
        "            input_token = input_token.unsqueeze(1)\n",
        "        elif input_token.dim() == 3:\n",
        "            input_token = input_token.squeeze(1)\n",
        "\n",
        "        embedded = self.embedding(input_token)  # [batch, 1, hidden_size]\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        # hidden state 차원 조정\n",
        "        if hidden.dim() == 3:\n",
        "            hidden_for_attn = hidden.squeeze(0)  # [batch, hidden_size]\n",
        "        else:\n",
        "            hidden_for_attn = hidden\n",
        "\n",
        "        # 어텐션 계산\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "        hidden_repeated = hidden_for_attn.unsqueeze(1).repeat(1, seq_len, 1)  # [batch, seq_len, hidden_size]\n",
        "\n",
        "        # 어텐션 에너지 계산 (단순화)\n",
        "        energy = self.attention(torch.cat((hidden_repeated, encoder_outputs), dim=2))  # [batch, seq_len, hidden_size]\n",
        "        attention_weights = F.softmax(self.attn_v(energy).squeeze(2), dim=1)  # [batch, seq_len]\n",
        "\n",
        "        # 컨텍스트 벡터 계산\n",
        "        context = torch.sum(encoder_outputs * attention_weights.unsqueeze(2), dim=1)  # [batch, hidden_size]\n",
        "        context = context.unsqueeze(1)  # [batch, 1, hidden_size]\n",
        "\n",
        "        # 임베딩과 컨텍스트 결합\n",
        "        lstm_input = torch.cat([embedded, context], dim=2)  # [batch, 1, hidden_size * 2]\n",
        "\n",
        "        # LSTM forward\n",
        "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
        "\n",
        "        # 최종 출력\n",
        "        output = F.log_softmax(self.out(output.squeeze(1)), dim=1)\n",
        "        return output, hidden, cell, attention_weights\n",
        "\n",
        "# 텐서 변환 함수\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index.get(word, PAD_token) for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long)\n",
        "\n",
        "# 데이터셋 클래스\n",
        "class SummarizationDataset(Dataset):\n",
        "    def __init__(self, pairs, doc_lang, summary_lang):\n",
        "        self.pairs = pairs\n",
        "        self.doc_lang = doc_lang\n",
        "        self.summary_lang = summary_lang\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.pairs[idx]\n",
        "        doc_tensor = tensorFromSentence(self.doc_lang, pair[0])\n",
        "        summary_tensor = tensorFromSentence(self.summary_lang, pair[1])\n",
        "        return doc_tensor, summary_tensor\n",
        "\n",
        "# 패딩 함수\n",
        "def collate_fn_summary(batch):\n",
        "    doc_batch, summary_batch = zip(*batch)\n",
        "\n",
        "    # 최대 길이 계산\n",
        "    max_doc_len = max([len(seq) for seq in doc_batch])\n",
        "    max_summary_len = max([len(seq) for seq in summary_batch])\n",
        "\n",
        "    # 패딩 적용\n",
        "    padded_docs = []\n",
        "    padded_summaries = []\n",
        "\n",
        "    for doc, summary in zip(doc_batch, summary_batch):\n",
        "        # 문서 패딩\n",
        "        if len(doc) < max_doc_len:\n",
        "            padded_doc = torch.cat([doc, torch.full((max_doc_len - len(doc),), PAD_token)])\n",
        "        else:\n",
        "            padded_doc = doc\n",
        "        padded_docs.append(padded_doc)\n",
        "\n",
        "        # 요약 패딩\n",
        "        if len(summary) < max_summary_len:\n",
        "            padded_summary = torch.cat([summary, torch.full((max_summary_len - len(summary),), PAD_token)])\n",
        "        else:\n",
        "            padded_summary = summary\n",
        "        padded_summaries.append(padded_summary)\n",
        "\n",
        "    return torch.stack(padded_docs), torch.stack(padded_summaries)\n",
        "\n",
        "# 모델 초기화\n",
        "hidden_size = 256\n",
        "encoder = DocumentEncoder(doc_lang.n_words, hidden_size)\n",
        "decoder = SummaryDecoder(hidden_size, summary_lang.n_words)\n",
        "\n",
        "# 데이터 로더\n",
        "dataset = SummarizationDataset(pairs, doc_lang, summary_lang)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn_summary)\n",
        "\n",
        "# 훈련 함수\n",
        "def train_summarization(doc_tensor, summary_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    doc_length = doc_tensor.size(1)\n",
        "    summary_length = summary_tensor.size(1)\n",
        "\n",
        "    # 인코더 forward\n",
        "    encoder_outputs, encoder_hidden = encoder(doc_tensor)\n",
        "\n",
        "    # 디코더 초기화\n",
        "    decoder_input = torch.tensor([[SOS_token]], dtype=torch.long)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = torch.zeros_like(decoder_hidden)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # Teacher forcing 사용\n",
        "    for di in range(summary_length - 1):\n",
        "        decoder_output, decoder_hidden, decoder_cell, attention_weights = decoder(\n",
        "            decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "\n",
        "        loss += criterion(decoder_output, summary_tensor[:, di])\n",
        "        decoder_input = summary_tensor[:, di].unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / (summary_length - 1)\n",
        "\n",
        "# 훈련 설정\n",
        "learning_rate = 0.001\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# 훈련 실행\n",
        "print(\"요약 모델 훈련 시작...\")\n",
        "for epoch in range(200):\n",
        "    total_loss = 0\n",
        "    for doc_tensor, summary_tensor in dataloader:\n",
        "        loss = train_summarization(doc_tensor, summary_tensor, encoder, decoder,\n",
        "                                 encoder_optimizer, decoder_optimizer, criterion)\n",
        "        total_loss += loss\n",
        "\n",
        "    if epoch % 40 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}')\n",
        "\n",
        "# 요약 함수\n",
        "def summarize(document, max_length=25):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        doc_processed = preprocess_text(document)\n",
        "        doc_tensor = tensorFromSentence(doc_lang, doc_processed).unsqueeze(0)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(doc_tensor)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], dtype=torch.long)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = torch.zeros_like(decoder_hidden)\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, attention_weights = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(summary_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.detach().unsqueeze(0)\n",
        "\n",
        "        return ' '.join(decoded_words)\n",
        "\n",
        "# ROUGE 점수 계산 (간단 버전)\n",
        "def simple_rouge_1(reference, hypothesis):\n",
        "    ref_words = set(reference.split())\n",
        "    hyp_words = set(hypothesis.split())\n",
        "\n",
        "    if len(ref_words) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    overlap = len(ref_words.intersection(hyp_words))\n",
        "    precision = overlap / len(hyp_words) if len(hyp_words) > 0 else 0\n",
        "    recall = overlap / len(ref_words)\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return f1\n",
        "\n",
        "# 테스트\n",
        "print(\"\\n=== 텍스트 요약 결과 ===\")\n",
        "test_documents = [\n",
        "    \"\"\"\n",
        "    스마트폰은 현대인의 필수품이 되었습니다.\n",
        "    통화, 메시지 전송뿐만 아니라 인터넷 검색, 사진 촬영,\n",
        "    게임, 음악 감상 등 다양한 기능을 제공합니다.\n",
        "    특히 모바일 앱의 발달로 은행 업무, 쇼핑,\n",
        "    교육 등의 활동도 스마트폰으로 가능해졌습니다.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    건강한 식습관은 우리 몸에 매우 중요합니다.\n",
        "    균형 잡힌 영양소 섭취와 규칙적인 식사가 필요합니다.\n",
        "    과도한 당분과 지방 섭취는 피하고 신선한 채소와\n",
        "    과일을 많이 먹어야 합니다. 충분한 수분 섭취도 잊지 말아야 합니다.\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "for i, doc in enumerate(test_documents):\n",
        "    summary = summarize(doc)\n",
        "    print(f\"문서 {i+1}:\")\n",
        "    print(f\"원문: {doc.strip()}\")\n",
        "    print(f\"요약: {summary}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# 훈련 데이터에 대한 성능 확인\n",
        "print(\"\\n=== 훈련 데이터 요약 성능 ===\")\n",
        "total_rouge = 0\n",
        "for i, (doc, ref_summary) in enumerate(zip(documents, summaries)):\n",
        "    generated_summary = summarize(doc)\n",
        "    rouge_score = simple_rouge_1(preprocess_text(ref_summary), generated_summary)\n",
        "    total_rouge += rouge_score\n",
        "\n",
        "    print(f\"문서 {i+1} ROUGE-1 F1: {rouge_score:.3f}\")\n",
        "    print(f\"참조: {ref_summary}\")\n",
        "    print(f\"생성: {generated_summary}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(f\"평균 ROUGE-1 F1: {total_rouge/len(documents):.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
