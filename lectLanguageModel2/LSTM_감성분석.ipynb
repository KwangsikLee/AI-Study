{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM 모델을 이용한 텍스트 감성분석\n",
        "\n",
        "### tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zCTmBo4pY_xL",
        "outputId": "9b792a58-a788-4b15-c5bc-6f70d1206198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 예제 2: LSTM으로 한글 감정 분석 ===\n",
            "\n",
            "총 어휘 수: 157\n",
            "빈도 상위 10개 단어:\n",
            "  너무: 5\n",
            "  영화: 3\n",
            "  정말: 3\n",
            "  연기가: 3\n",
            "  훌륭한: 3\n",
            "  있는: 3\n",
            "  배우들: 2\n",
            "  스토리도: 2\n",
            "  완전: 2\n",
            "  영화네요: 2\n",
            "\n",
            "총 리뷰 수: 34\n",
            "긍정 리뷰: 17개\n",
            "부정 리뷰: 17개\n",
            "최대 시퀀스 길이: 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "모델 훈련 중...\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5123 - loss: 0.6928 - val_accuracy: 0.4286 - val_loss: 0.6955\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.4630 - loss: 0.6968 - val_accuracy: 0.4286 - val_loss: 0.6968\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.4668 - loss: 0.6936 - val_accuracy: 0.4286 - val_loss: 0.6967\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.5826 - loss: 0.6927 - val_accuracy: 0.4286 - val_loss: 0.6973\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.5826 - loss: 0.6897 - val_accuracy: 0.4286 - val_loss: 0.6981\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - accuracy: 0.5332 - loss: 0.6865 - val_accuracy: 0.4286 - val_loss: 0.6994\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5864 - loss: 0.6912 - val_accuracy: 0.4286 - val_loss: 0.6995\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.4174 - loss: 0.6875 - val_accuracy: 0.4286 - val_loss: 0.7009\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - accuracy: 0.3966 - loss: 0.6984 - val_accuracy: 0.4286 - val_loss: 0.7024\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - accuracy: 0.5617 - loss: 0.6894 - val_accuracy: 0.4286 - val_loss: 0.7045\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - accuracy: 0.5123 - loss: 0.6928 - val_accuracy: 0.4286 - val_loss: 0.7071\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.4877 - loss: 0.6897 - val_accuracy: 0.4286 - val_loss: 0.7079\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.5046 - loss: 0.7128 - val_accuracy: 0.4286 - val_loss: 0.7073\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.4668 - loss: 0.7124 - val_accuracy: 0.4286 - val_loss: 0.7040\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.5085 - loss: 0.6946 - val_accuracy: 0.4286 - val_loss: 0.7010\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.5995 - loss: 0.6835 - val_accuracy: 0.4286 - val_loss: 0.6986\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5255 - loss: 0.6947 - val_accuracy: 0.4286 - val_loss: 0.6955\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.4630 - loss: 0.6973 - val_accuracy: 0.4286 - val_loss: 0.6945\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.4421 - loss: 0.6959 - val_accuracy: 0.4286 - val_loss: 0.6938\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.6242 - loss: 0.6867 - val_accuracy: 0.4286 - val_loss: 0.6938\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.4630 - loss: 0.6938 - val_accuracy: 0.4286 - val_loss: 0.6938\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.3719 - loss: 0.7013 - val_accuracy: 0.4286 - val_loss: 0.6940\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3966 - loss: 0.6956 - val_accuracy: 0.4286 - val_loss: 0.6943\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.4877 - loss: 0.6947 - val_accuracy: 0.4286 - val_loss: 0.6947\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.5502 - loss: 0.6876 - val_accuracy: 0.4286 - val_loss: 0.6954\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.5332 - loss: 0.6961 - val_accuracy: 0.4286 - val_loss: 0.6960\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.3302 - loss: 0.6980 - val_accuracy: 0.4286 - val_loss: 0.6968\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.4954 - loss: 0.6990 - val_accuracy: 0.4286 - val_loss: 0.6975\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6034 - loss: 0.6942 - val_accuracy: 0.4286 - val_loss: 0.6985\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.4630 - loss: 0.7016 - val_accuracy: 0.4286 - val_loss: 0.6994\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.4421 - loss: 0.7041 - val_accuracy: 0.4286 - val_loss: 0.6992\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.4630 - loss: 0.7064 - val_accuracy: 0.4286 - val_loss: 0.6985\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.3966 - loss: 0.7027 - val_accuracy: 0.4286 - val_loss: 0.6973\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 0.6281 - loss: 0.6842 - val_accuracy: 0.4286 - val_loss: 0.6970\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 0.5995 - loss: 0.6848 - val_accuracy: 0.4286 - val_loss: 0.6970\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.5748 - loss: 0.6867 - val_accuracy: 0.4286 - val_loss: 0.6970\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - accuracy: 0.5162 - loss: 0.6968 - val_accuracy: 0.4286 - val_loss: 0.6969\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - accuracy: 0.4213 - loss: 0.6947 - val_accuracy: 0.4286 - val_loss: 0.6969\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - accuracy: 0.5123 - loss: 0.6936 - val_accuracy: 0.4286 - val_loss: 0.6968\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.4174 - loss: 0.6977 - val_accuracy: 0.4286 - val_loss: 0.6967\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.5748 - loss: 0.6886 - val_accuracy: 0.4286 - val_loss: 0.6966\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.5502 - loss: 0.6904 - val_accuracy: 0.4286 - val_loss: 0.6963\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.4174 - loss: 0.6905 - val_accuracy: 0.4286 - val_loss: 0.6959\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.5579 - loss: 0.6806 - val_accuracy: 0.4286 - val_loss: 0.6959\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6736 - loss: 0.6888 - val_accuracy: 0.4286 - val_loss: 0.6959\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.4877 - loss: 0.6880 - val_accuracy: 0.4286 - val_loss: 0.6961\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.5787 - loss: 0.6936 - val_accuracy: 0.4286 - val_loss: 0.6960\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.5085 - loss: 0.6958 - val_accuracy: 0.4286 - val_loss: 0.6957\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.5540 - loss: 0.6902 - val_accuracy: 0.4286 - val_loss: 0.6957\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.3056 - loss: 0.7057 - val_accuracy: 0.4286 - val_loss: 0.6954\n",
            "\n",
            "테스트 정확도: 0.4286\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793ms/step\n",
            "\n",
            "분류 성능 리포트:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          부정       0.00      0.00      0.00         4\n",
            "          긍정       0.43      1.00      0.60         3\n",
            "\n",
            "    accuracy                           0.43         7\n",
            "   macro avg       0.21      0.50      0.30         7\n",
            "weighted avg       0.18      0.43      0.26         7\n",
            "\n",
            "\n",
            "=== 새로운 리뷰 감정 분석 결과 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. 리뷰: '이 영화 진짜 최고예요! 너무 재미있어서 시간 가는 줄 몰랐어요.'\n",
            "   감정: 긍정 (신뢰도: 0.508, 원점수: 0.508)\n",
            "\n",
            "2. 리뷰: '정말 지루하고 재미없는 영화였습니다. 돈이 아까워요.'\n",
            "   감정: 긍정 (신뢰도: 0.508, 원점수: 0.508)\n",
            "\n",
            "3. 리뷰: '그럭저럭 볼 만한 영화였어요. 나쁘지 않네요.'\n",
            "   감정: 긍정 (신뢰도: 0.508, 원점수: 0.508)\n",
            "\n",
            "4. 리뷰: '스토리가 감동적이고 배우들 연기도 훌륭했습니다.'\n",
            "   감정: 긍정 (신뢰도: 0.508, 원점수: 0.508)\n",
            "\n",
            "5. 리뷰: '예상보다 별로였어요. 다른 영화를 볼 걸 그랬네요.'\n",
            "   감정: 긍정 (신뢰도: 0.508, 원점수: 0.508)\n",
            "\n",
            "6. 리뷰: '가족과 함께 보기 좋은 따뜻한 영화였습니다.'\n",
            "   감정: 긍정 (신뢰도: 0.508, 원점수: 0.508)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 예제 2: LSTM으로 한글 감정 분석 (리뷰 데이터)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# 한글 리뷰 샘플 데이터 (긍정: 1, 부정: 0)\n",
        "korean_reviews = [\n",
        "    # 긍정 리뷰\n",
        "    (\"이 영화 정말 재미있어요! 강력 추천합니다.\", 1),\n",
        "    (\"배우들 연기가 너무 좋고 스토리도 흥미진진해요.\", 1),\n",
        "    (\"완전 대박이에요. 다시 보고 싶은 영화네요.\", 1),\n",
        "    (\"감동적인 스토리와 훌륭한 연출이 인상적이었습니다.\", 1),\n",
        "    (\"최고의 영화 중 하나입니다. 꼭 보세요!\", 1),\n",
        "    (\"웃음도 감동도 모두 주는 완벽한 작품이에요.\", 1),\n",
        "    (\"놀라운 영상미와 깊이 있는 내용에 감탄했어요.\", 1),\n",
        "    (\"시간 가는 줄 모르고 봤습니다. 정말 좋아요.\", 1),\n",
        "    (\"예상보다 훨씬 재미있고 의미 있는 영화였어요.\", 1),\n",
        "    (\"모든 장면이 인상 깊고 기억에 남을 것 같아요.\", 1),\n",
        "    (\"훌륭한 음악과 함께 완벽한 하모니를 이루는 작품이에요.\", 1),\n",
        "    (\"배우들의 열연과 감독의 연출력이 돋보이는 영화입니다.\", 1),\n",
        "\n",
        "    # 부정 리뷰\n",
        "    (\"정말 지루하고 재미없어요. 시간 낭비였습니다.\", 0),\n",
        "    (\"스토리가 뻔하고 예측 가능해서 실망했어요.\", 0),\n",
        "    (\"연기가 어색하고 대사도 어색해서 몰입이 안돼요.\", 0),\n",
        "    (\"너무 길고 지루해서 중간에 나오고 싶었어요.\", 0),\n",
        "    (\"기대했는데 완전 실망이에요. 별로예요.\", 0),\n",
        "    (\"스토리 전개가 느리고 재미없어서 졸았어요.\", 0),\n",
        "    (\"예고편이 더 재미있었어요. 본편은 실망.\", 0),\n",
        "    (\"돈 아까워요. 다른 영화 볼 걸 그랬어요.\", 0),\n",
        "    (\"억지스러운 감동과 뻔한 결말이 아쉬워요.\", 0),\n",
        "    (\"배우들 연기가 어색하고 스토리도 이상해요.\", 0),\n",
        "    (\"기대와 달리 너무 유치하고 재미없었어요.\", 0),\n",
        "    (\"시간이 아까운 영화였습니다. 추천하지 않아요.\", 0),\n",
        "\n",
        "    # 추가 긍정 리뷰\n",
        "    (\"마음이 따뜻해지는 좋은 영화였어요.\", 1),\n",
        "    (\"가족과 함께 보기 좋은 훌륭한 작품입니다.\", 1),\n",
        "    (\"깊은 여운이 남는 의미 있는 영화네요.\", 1),\n",
        "    (\"볼 때마다 새로운 감동을 주는 명작이에요.\", 1),\n",
        "    (\"연출과 연기 모든 면에서 완벽했습니다.\", 1),\n",
        "\n",
        "    # 추가 부정 리뷰\n",
        "    (\"내용이 너무 무겁고 우울해서 힘들었어요.\", 0),\n",
        "    (\"억지로 만든 것 같은 느낌이 강해요.\", 0),\n",
        "    (\"캐릭터들이 매력적이지 않고 공감하기 어려워요.\", 0),\n",
        "    (\"결말이 너무 허무하고 아쉬웠습니다.\", 0),\n",
        "    (\"과장된 연출이 부자연스러워서 실망했어요.\", 0)\n",
        "]\n",
        "\n",
        "class KoreanSentimentAnalyzer:\n",
        "    def __init__(self, max_words=10000, max_length=50):\n",
        "        self.max_words = max_words\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = Tokenizer(\n",
        "            num_words=max_words,\n",
        "            oov_token=\"<OOV>\",\n",
        "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'  # 한글 처리를 위해 필터 조정\n",
        "        )\n",
        "\n",
        "    def preprocess_korean_text(self, text):\n",
        "        # 한글 텍스트 전처리\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)  # 특수문자 제거\n",
        "        text = re.sub(r'\\s+', ' ', text)     # 여러 공백을 하나로\n",
        "        text = text.strip()\n",
        "        return text\n",
        "\n",
        "    def prepare_data(self, reviews_data):\n",
        "        # 텍스트와 라벨 분리 및 전처리\n",
        "        texts = [self.preprocess_korean_text(review[0]) for review in reviews_data]\n",
        "        labels = [review[1] for review in reviews_data]\n",
        "\n",
        "        # 토크나이저 훈련\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "\n",
        "        # 어휘 정보 출력\n",
        "        print(f\"총 어휘 수: {len(self.tokenizer.word_index)}\")\n",
        "        print(\"빈도 상위 10개 단어:\")\n",
        "        word_freq = sorted(self.tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        for word, freq in word_freq[:10]:\n",
        "            print(f\"  {word}: {freq}\")\n",
        "\n",
        "        # 텍스트를 시퀀스로 변환\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "        # 패딩 적용\n",
        "        X = pad_sequences(sequences, maxlen=self.max_length, padding='post', truncating='post')\n",
        "        y = np.array(labels)\n",
        "\n",
        "        return X, y, texts\n",
        "\n",
        "    def build_model(self, embedding_dim=100, lstm_units=64):\n",
        "        model = Sequential([\n",
        "            Embedding(self.max_words, embedding_dim, input_length=self.max_length),\n",
        "            LSTM(lstm_units, dropout=0.3, recurrent_dropout=0.3, return_sequences=True),\n",
        "            LSTM(lstm_units//2, dropout=0.3, recurrent_dropout=0.3),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def predict_sentiment(self, model, text):\n",
        "        # 텍스트 전처리\n",
        "        processed_text = self.preprocess_korean_text(text)\n",
        "        sequence = self.tokenizer.texts_to_sequences([processed_text])\n",
        "        padded = pad_sequences(sequence, maxlen=self.max_length, padding='post', truncating='post')\n",
        "\n",
        "        # 예측\n",
        "        prediction = model.predict(padded, verbose=0)[0][0]\n",
        "\n",
        "        if prediction > 0.5:\n",
        "            sentiment = \"긍정\"\n",
        "            confidence = prediction\n",
        "        else:\n",
        "            sentiment = \"부정\"\n",
        "            confidence = 1 - prediction\n",
        "\n",
        "        return sentiment, confidence, prediction\n",
        "\n",
        "def run_korean_sentiment_example():\n",
        "    print(\"=== 예제 2: LSTM으로 한글 감정 분석 ===\\n\")\n",
        "\n",
        "    # 1. 데이터 준비\n",
        "    analyzer = KoreanSentimentAnalyzer(max_words=5000, max_length=50)\n",
        "    X, y, texts = analyzer.prepare_data(korean_reviews)\n",
        "\n",
        "    print(f\"\\n총 리뷰 수: {len(X)}\")\n",
        "    print(f\"긍정 리뷰: {sum(y)}개\")\n",
        "    print(f\"부정 리뷰: {len(y) - sum(y)}개\")\n",
        "    print(f\"최대 시퀀스 길이: {analyzer.max_length}\")\n",
        "\n",
        "    # 2. 훈련/테스트 데이터 분할\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # 3. 모델 구축\n",
        "    model = analyzer.build_model()\n",
        "    model.summary()\n",
        "\n",
        "    # 4. 모델 훈련\n",
        "    print(\"\\n모델 훈련 중...\")\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=50,\n",
        "        batch_size=16,\n",
        "        validation_data=(X_test, y_test),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 5. 모델 평가\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\n테스트 정확도: {test_accuracy:.4f}\")\n",
        "\n",
        "    # 상세 분류 리포트\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "    print(\"\\n분류 성능 리포트:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['부정', '긍정']))\n",
        "\n",
        "    # 6. 새로운 리뷰 감정 분석\n",
        "    test_reviews = [\n",
        "        \"이 영화 진짜 최고예요! 너무 재미있어서 시간 가는 줄 몰랐어요.\",\n",
        "        \"정말 지루하고 재미없는 영화였습니다. 돈이 아까워요.\",\n",
        "        \"그럭저럭 볼 만한 영화였어요. 나쁘지 않네요.\",\n",
        "        \"스토리가 감동적이고 배우들 연기도 훌륭했습니다.\",\n",
        "        \"예상보다 별로였어요. 다른 영화를 볼 걸 그랬네요.\",\n",
        "        \"가족과 함께 보기 좋은 따뜻한 영화였습니다.\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n=== 새로운 리뷰 감정 분석 결과 ===\")\n",
        "    for i, review in enumerate(test_reviews, 1):\n",
        "        sentiment, confidence, raw_score = analyzer.predict_sentiment(model, review)\n",
        "        print(f\"{i}. 리뷰: '{review}'\")\n",
        "        print(f\"   감정: {sentiment} (신뢰도: {confidence:.3f}, 원점수: {raw_score:.3f})\\n\")\n",
        "\n",
        "    return model, analyzer, history\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    model, analyzer, history = run_korean_sentiment_example()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llmenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
