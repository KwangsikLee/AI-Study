{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 감성분석 \n",
        "\n",
        "\n",
        "## Graph Attention Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 코드 요약\n",
        "\n",
        "GraphEmotionNetwork 클래스는 BERT와 그래프 신경망(GNN)을 결합해 감정 분석을 수행하는 모델입니다.\n",
        "\n",
        "구성 및 동작:\n",
        "\n",
        "BERT 인코더로 입력 문장을 임베딩(벡터화)합니다.  \n",
        "각 토큰별 감정 점수(6개 감정)를 추가해 특징을 만듭니다.  \n",
        "특징을 변환한 뒤, 3개의 Graph Attention Layer(GAT)를 거쳐 토큰 간 관계와 감정 전파를 학습합니다.  \n",
        "각 감정별로 추가적인 특징 추출 레이어(emotion_propagation)를 적용합니다.  \n",
        "모든 특징을 합쳐 최종 분류기(classifier)에서 감정(7종: 기쁨, 슬픔, 분노, 공포, 놀람, 혐오, 중립)별 확률을 예측합니다.  \n",
        "즉, 문장 내 토큰 간의 감정적 연결과 BERT의 언어적 특징을 동시에 활용해, 더 정교한 감정 분석을 목표로 하는 모델입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tls-gyeNK9w",
        "outputId": "c5b152e3-06e3-490c-b4c4-81e8ccb771cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌐 Graph Neural Network 기반 감정 전파 모델\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델 훈련 중...\n",
            "Epoch 5/10, Loss: 1.3338\n",
            "Epoch 10/10, Loss: 0.8100\n",
            "\n",
            "============================================================\n",
            "그래프 기반 감정 분석 결과\n",
            "============================================================\n",
            "\n",
            "📝 분석 텍스트: 기쁜 소식을 듣고 행복해서 눈물이 났어요\n",
            "\n",
            "🔗 그래프 기반 감정 분석:\n",
            "  기쁜           → 😊 기쁨   (신뢰도: 25.84%, 그래프 영향: 없음)\n",
            "  소식           → 😊 기쁨   (신뢰도: 23.48%, 그래프 영향: 없음)\n",
            "  ##을          → 😊 기쁨   (신뢰도: 21.56%, 그래프 영향: 없음)\n",
            "  듣            → 😊 기쁨   (신뢰도: 21.11%, 그래프 영향: 없음)\n",
            "  ##고          → 😊 기쁨   (신뢰도: 22.31%, 그래프 영향: 기쁨)\n",
            "  행복           → 😊 기쁨   (신뢰도: 22.63%, 그래프 영향: 없음)\n",
            "  ##해서         → 😠 분노   (신뢰도: 22.66%, 그래프 영향: 슬픔)\n",
            "  눈물           → 😠 분노   (신뢰도: 23.60%, 그래프 영향: 없음)\n",
            "  ##이          → 😠 분노   (신뢰도: 24.13%, 그래프 영향: 없음)\n",
            "  났            → 😠 분노   (신뢰도: 24.41%, 그래프 영향: 없음)\n",
            "  ##어요         → 😊 기쁨   (신뢰도: 27.92%, 그래프 영향: 없음)\n",
            "\n",
            "🌐 감정 네트워크 특성:\n",
            "  - 기쁨: 7개 노드가 연결됨\n",
            "  - 분노: 4개 노드가 연결됨\n",
            "  → 그래프 엣지 수: 20개\n",
            "------------------------------------------------------------\n",
            "\n",
            "📝 분석 텍스트: 무서운 이야기를 듣고 너무 놀라고 두려웠어요\n",
            "\n",
            "🔗 그래프 기반 감정 분석:\n",
            "  무서운          → 😨 공포   (신뢰도: 30.19%, 그래프 영향: 없음)\n",
            "  이야기          → 😨 공포   (신뢰도: 28.93%, 그래프 영향: 없음)\n",
            "  ##를          → 😨 공포   (신뢰도: 26.51%, 그래프 영향: 없음)\n",
            "  듣            → 😨 공포   (신뢰도: 24.38%, 그래프 영향: 없음)\n",
            "  ##고          → 😨 공포   (신뢰도: 22.99%, 그래프 영향: 기쁨)\n",
            "  너무           → 😨 공포   (신뢰도: 22.19%, 그래프 영향: 놀람)\n",
            "  놀라           → 😠 분노   (신뢰도: 22.29%, 그래프 영향: 없음)\n",
            "  ##고          → 😠 분노   (신뢰도: 23.99%, 그래프 영향: 없음)\n",
            "  두려웠          → 😠 분노   (신뢰도: 24.77%, 그래프 영향: 없음)\n",
            "  ##어요         → 😨 공포   (신뢰도: 24.04%, 그래프 영향: 없음)\n",
            "\n",
            "🌐 감정 네트워크 특성:\n",
            "  - 공포: 7개 노드가 연결됨\n",
            "  - 분노: 3개 노드가 연결됨\n",
            "  → 그래프 엣지 수: 20개\n",
            "------------------------------------------------------------\n",
            "\n",
            "📝 분석 텍스트: 화가 나서 짜증이 나지만 참고 있어요\n",
            "\n",
            "🔗 그래프 기반 감정 분석:\n",
            "  화가           → 😠 분노   (신뢰도: 53.52%, 그래프 영향: 없음)\n",
            "  나서           → 😠 분노   (신뢰도: 51.64%, 그래프 영향: 분노)\n",
            "  짜증           → 😠 분노   (신뢰도: 49.14%, 그래프 영향: 없음)\n",
            "  ##이          → 😠 분노   (신뢰도: 47.86%, 그래프 영향: 없음)\n",
            "  나지           → 😠 분노   (신뢰도: 47.83%, 그래프 영향: 없음)\n",
            "  ##만          → 😠 분노   (신뢰도: 47.84%, 그래프 영향: 없음)\n",
            "  참고           → 😠 분노   (신뢰도: 47.80%, 그래프 영향: 없음)\n",
            "  있            → 😠 분노   (신뢰도: 47.61%, 그래프 영향: 없음)\n",
            "  ##어요         → 😠 분노   (신뢰도: 51.97%, 그래프 영향: 없음)\n",
            "\n",
            "🌐 감정 네트워크 특성:\n",
            "  - 분노: 9개 노드가 연결됨\n",
            "  → 그래프 엣지 수: 16개\n",
            "------------------------------------------------------------\n",
            "\n",
            "📝 분석 텍스트: 놀라운 결과에 기쁘면서도 믿기지 않아요\n",
            "\n",
            "🔗 그래프 기반 감정 분석:\n",
            "  놀라운          → 😊 기쁨   (신뢰도: 25.77%, 그래프 영향: 없음)\n",
            "  결과           → 😊 기쁨   (신뢰도: 25.25%, 그래프 영향: 없음)\n",
            "  ##에          → 😊 기쁨   (신뢰도: 23.00%, 그래프 영향: 기쁨)\n",
            "  기쁘           → 😠 분노   (신뢰도: 21.67%, 그래프 영향: 없음)\n",
            "  ##면서         → 😠 분노   (신뢰도: 23.36%, 그래프 영향: 없음)\n",
            "  ##도          → 😠 분노   (신뢰도: 24.58%, 그래프 영향: 없음)\n",
            "  믿기           → 😠 분노   (신뢰도: 25.28%, 그래프 영향: 없음)\n",
            "  ##지          → 😠 분노   (신뢰도: 25.40%, 그래프 영향: 없음)\n",
            "  않            → 😠 분노   (신뢰도: 24.99%, 그래프 영향: 없음)\n",
            "  ##아          → 😠 분노   (신뢰도: 24.79%, 그래프 영향: 없음)\n",
            "  ##요          → 😊 기쁨   (신뢰도: 29.71%, 그래프 영향: 없음)\n",
            "\n",
            "🌐 감정 네트워크 특성:\n",
            "  - 분노: 7개 노드가 연결됨\n",
            "  - 기쁨: 4개 노드가 연결됨\n",
            "  → 그래프 엣지 수: 20개\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Dict, Tuple\n",
        "# Graph Neural Network 구현 (torch_geometric 없이)\n",
        "\n",
        "# 한국어 감정 어휘 그래프\n",
        "EMOTION_GRAPH = {\n",
        "    'joy': {\n",
        "        'core': ['기쁘', '행복', '즐겁', '좋'],\n",
        "        'related': ['웃', '신나', '감동', '사랑', '희망', '만족'],\n",
        "        'intensifiers': ['매우', '정말', '너무', '아주', '진짜']\n",
        "    },\n",
        "    'sadness': {\n",
        "        'core': ['슬프', '우울', '눈물', '아프'],\n",
        "        'related': ['외롭', '그립', '후회', '실망', '절망', '비참'],\n",
        "        'intensifiers': ['너무', '정말', '매우', '몹시']\n",
        "    },\n",
        "    'anger': {\n",
        "        'core': ['화', '분노', '짜증', '싫'],\n",
        "        'related': ['미워', '열받', '답답', '억울', '불쾌'],\n",
        "        'intensifiers': ['정말', '너무', '진짜', '완전']\n",
        "    },\n",
        "    'fear': {\n",
        "        'core': ['무서', '두렵', '겁', '공포'],\n",
        "        'related': ['불안', '걱정', '떨', '긴장', '위험'],\n",
        "        'intensifiers': ['너무', '정말', '매우']\n",
        "    },\n",
        "    'surprise': {\n",
        "        'core': ['놀라', '깜짝', '충격', '갑작'],\n",
        "        'related': ['믿기지', '의외', '뜻밖', '예상외'],\n",
        "        'intensifiers': ['정말', '너무', '완전']\n",
        "    },\n",
        "    'disgust': {\n",
        "        'core': ['역겹', '더럽', '혐오', '구역질'],\n",
        "        'related': ['불쾌', '끔찍', '징그럽', '메스껍'],\n",
        "        'intensifiers': ['너무', '정말', '진짜']\n",
        "    }\n",
        "}\n",
        "\n",
        "class EmotionGraphBuilder:\n",
        "    \"\"\"텍스트를 감정 그래프로 변환\"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.emotion_vocab = self._build_emotion_vocab()\n",
        "\n",
        "    def _build_emotion_vocab(self):\n",
        "        \"\"\"감정 어휘 사전 구축\"\"\"\n",
        "        vocab = {}\n",
        "        for emotion, words_dict in EMOTION_GRAPH.items():\n",
        "            for word_list in words_dict.values():\n",
        "                for word in word_list:\n",
        "                    if word not in vocab:\n",
        "                        vocab[word] = []\n",
        "                    vocab[word].append(emotion)\n",
        "        return vocab\n",
        "\n",
        "    def build_graph(self, text):\n",
        "        \"\"\"텍스트를 그래프로 변환\"\"\"\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "\n",
        "        # 노드 특징 (감정 초기값)\n",
        "        node_features = []\n",
        "        emotion_scores = []\n",
        "\n",
        "        for token in tokens:\n",
        "            token_clean = token.replace('##', '')\n",
        "\n",
        "            # 감정 점수 계산\n",
        "            scores = np.zeros(6)  # 6개 감정\n",
        "            for emotion_idx, emotion in enumerate(['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust']):\n",
        "                for category, words in EMOTION_GRAPH[emotion].items():\n",
        "                    for word in words:\n",
        "                        if word in token_clean:\n",
        "                            if category == 'core':\n",
        "                                scores[emotion_idx] += 2.0\n",
        "                            elif category == 'related':\n",
        "                                scores[emotion_idx] += 1.0\n",
        "                            elif category == 'intensifiers':\n",
        "                                scores[emotion_idx] += 0.5\n",
        "\n",
        "            emotion_scores.append(scores)\n",
        "\n",
        "        # 엣지 구성 (인접 토큰 + 의미적 연결)\n",
        "        edges = []\n",
        "        edge_weights = []\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            # 인접 토큰 연결\n",
        "            if i > 0:\n",
        "                edges.append([i-1, i])\n",
        "                edge_weights.append(1.0)\n",
        "            if i < len(tokens) - 1:\n",
        "                edges.append([i, i+1])\n",
        "                edge_weights.append(1.0)\n",
        "\n",
        "            # 같은 감정 키워드끼리 연결\n",
        "            for j in range(i+1, min(i+5, len(tokens))):  # 5토큰 이내\n",
        "                if self._are_emotionally_related(tokens[i], tokens[j]):\n",
        "                    edges.append([i, j])\n",
        "                    edges.append([j, i])\n",
        "                    edge_weights.extend([0.5, 0.5])\n",
        "\n",
        "        return tokens, np.array(emotion_scores), edges, edge_weights\n",
        "\n",
        "    def _are_emotionally_related(self, token1, token2):\n",
        "        \"\"\"두 토큰이 감정적으로 연관되어 있는지 확인\"\"\"\n",
        "        t1_clean = token1.replace('##', '')\n",
        "        t2_clean = token2.replace('##', '')\n",
        "\n",
        "        emotions1 = self.emotion_vocab.get(t1_clean, [])\n",
        "        emotions2 = self.emotion_vocab.get(t2_clean, [])\n",
        "\n",
        "        return len(set(emotions1) & set(emotions2)) > 0\n",
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    \"\"\"Graph Attention Layer 직접 구현\"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, dropout=0.1, alpha=0.2):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
        "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
        "\n",
        "        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        \"\"\"\n",
        "        x: [num_nodes, in_features]\n",
        "        adj: [num_nodes, num_nodes] adjacency matrix\n",
        "        \"\"\"\n",
        "        h = torch.mm(x, self.W)  # [num_nodes, out_features]\n",
        "        num_nodes = h.size(0)\n",
        "\n",
        "        # Attention mechanism\n",
        "        h_repeat = h.repeat(num_nodes, 1)  # [num_nodes*num_nodes, out_features]\n",
        "        h_repeat_interleave = h.repeat_interleave(num_nodes, dim=0)\n",
        "        h_concat = torch.cat([h_repeat_interleave, h_repeat], dim=1)  # [num_nodes*num_nodes, 2*out_features]\n",
        "\n",
        "        e = self.leakyrelu(torch.matmul(h_concat, self.a).squeeze(1))\n",
        "        e = e.view(num_nodes, num_nodes)\n",
        "\n",
        "        # Mask attention scores\n",
        "        zero_vec = -9e15 * torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "        attention = F.softmax(attention, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "\n",
        "        h_prime = torch.matmul(attention, h)\n",
        "\n",
        "        return F.elu(h_prime)\n",
        "\n",
        "class GraphEmotionNetwork(nn.Module):\n",
        "    \"\"\"Graph Neural Network 기반 감정 분석 모델\"\"\"\n",
        "\n",
        "    def __init__(self, model_name='klue/bert-base', hidden_dim=256, num_emotions=7):\n",
        "        super().__init__()\n",
        "\n",
        "        # BERT 인코더\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        bert_dim = self.bert.config.hidden_size\n",
        "\n",
        "        # 초기 특징 변환\n",
        "        self.input_transform = nn.Linear(bert_dim + 6, hidden_dim)  # BERT + 감정 점수\n",
        "\n",
        "        # Graph Attention Layers\n",
        "        self.gat1 = GraphAttentionLayer(hidden_dim, hidden_dim, dropout=0.1)\n",
        "        self.gat2 = GraphAttentionLayer(hidden_dim, hidden_dim, dropout=0.1)\n",
        "        self.gat3 = GraphAttentionLayer(hidden_dim, hidden_dim, dropout=0.1)\n",
        "\n",
        "        # 감정 전파 레이어\n",
        "        self.emotion_propagation = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, 64) for _ in range(num_emotions)\n",
        "        ])\n",
        "\n",
        "        # 최종 분류기\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + 64 * num_emotions, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim, num_emotions)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, emotion_scores, edge_index, edge_weight=None):\n",
        "        # BERT 인코딩\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        bert_features = outputs.last_hidden_state  # [batch, seq_len, bert_dim]\n",
        "\n",
        "        # 그래프 데이터 준비\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        node_features = []\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            # BERT 특징과 감정 점수 결합\n",
        "            bert_feat = bert_features[b]  # [seq_len, bert_dim]\n",
        "            emotion_feat = emotion_scores[b] if b < len(emotion_scores) else torch.zeros(seq_len, 6)\n",
        "\n",
        "            if isinstance(emotion_feat, np.ndarray):\n",
        "                emotion_feat = torch.tensor(emotion_feat, dtype=torch.float32)\n",
        "\n",
        "            # 크기 맞추기\n",
        "            if emotion_feat.shape[0] < seq_len:\n",
        "                padding = torch.zeros(seq_len - emotion_feat.shape[0], 6)\n",
        "                emotion_feat = torch.cat([emotion_feat, padding], dim=0)\n",
        "            elif emotion_feat.shape[0] > seq_len:\n",
        "                emotion_feat = emotion_feat[:seq_len]\n",
        "\n",
        "            combined = torch.cat([bert_feat, emotion_feat], dim=-1)\n",
        "            node_features.append(combined)\n",
        "\n",
        "        # 노드 특징 변환\n",
        "        x = torch.stack(node_features).view(-1, bert_features.shape[-1] + 6)\n",
        "        x = self.input_transform(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Adjacency matrix 생성\n",
        "        num_nodes = x.shape[0]\n",
        "        adj = torch.zeros(num_nodes, num_nodes)\n",
        "\n",
        "        if edge_index is not None and len(edge_index) > 0:\n",
        "            for edge in edge_index:\n",
        "                if edge[0] < num_nodes and edge[1] < num_nodes:\n",
        "                    adj[edge[0], edge[1]] = 1.0\n",
        "                    adj[edge[1], edge[0]] = 1.0  # 무방향 그래프\n",
        "\n",
        "        # 자기 연결 추가\n",
        "        adj = adj + torch.eye(num_nodes)\n",
        "\n",
        "        # GAT 레이어 통과\n",
        "        x = self.gat1(x, adj)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.gat2(x, adj)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.gat3(x, adj)\n",
        "\n",
        "        # 감정별 특징 추출\n",
        "        emotion_features = []\n",
        "        for emotion_layer in self.emotion_propagation:\n",
        "            emotion_feat = emotion_layer(x)\n",
        "            emotion_features.append(emotion_feat)\n",
        "\n",
        "        # 특징 결합\n",
        "        combined_features = torch.cat([x] + emotion_features, dim=-1)\n",
        "\n",
        "        # 최종 분류\n",
        "        logits = self.classifier(combined_features)\n",
        "\n",
        "        # Reshape back to [batch, seq_len, num_emotions]\n",
        "        logits = logits.view(batch_size, seq_len, -1)\n",
        "\n",
        "        return logits\n",
        "\n",
        "class GNNEmotionAnalyzer:\n",
        "    \"\"\"GNN 기반 감정 분석기\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, graph_builder):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.graph_builder = graph_builder\n",
        "        self.emotion_names = ['기쁨', '슬픔', '분노', '공포', '놀람', '혐오', '중립']\n",
        "\n",
        "    def analyze(self, text):\n",
        "        \"\"\"텍스트 감정 분석\"\"\"\n",
        "        # 그래프 구성\n",
        "        tokens, emotion_scores, edges, edge_weights = self.graph_builder.build_graph(text)\n",
        "\n",
        "        # 토크나이징\n",
        "        encoded = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "        # 엣지 텐서 변환\n",
        "        if edges:\n",
        "            edge_index = torch.tensor(edges, dtype=torch.long)\n",
        "            edge_weight = torch.tensor(edge_weights, dtype=torch.float)\n",
        "        else:\n",
        "            edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
        "            edge_weight = torch.tensor([1.0], dtype=torch.float)\n",
        "\n",
        "        # 예측\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(\n",
        "                encoded['input_ids'],\n",
        "                encoded['attention_mask'],\n",
        "                [emotion_scores],\n",
        "                edge_index,\n",
        "                edge_weight\n",
        "            )\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # 결과 정리\n",
        "        results = []\n",
        "        valid_tokens = self.tokenizer.convert_ids_to_tokens(encoded['input_ids'][0])\n",
        "\n",
        "        for i, token in enumerate(valid_tokens):\n",
        "            if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
        "                token_probs = probs[0, i]\n",
        "                max_prob, max_idx = torch.max(token_probs, dim=0)\n",
        "\n",
        "                results.append({\n",
        "                    'token': token,\n",
        "                    'emotion': self.emotion_names[max_idx.item()],\n",
        "                    'confidence': max_prob.item(),\n",
        "                    'all_probs': token_probs.numpy(),\n",
        "                    'graph_influence': emotion_scores[min(i, len(emotion_scores)-1)] if i < len(emotion_scores) else np.zeros(6)\n",
        "                })\n",
        "\n",
        "        return results, edges\n",
        "\n",
        "    def visualize_emotion_graph(self, text, results, edges):\n",
        "        \"\"\"감정 그래프 시각화\"\"\"\n",
        "        G = nx.Graph()\n",
        "\n",
        "        # 노드 추가\n",
        "        for i, r in enumerate(results):\n",
        "            G.add_node(i,\n",
        "                      label=r['token'],\n",
        "                      emotion=r['emotion'],\n",
        "                      confidence=r['confidence'])\n",
        "\n",
        "        # 엣지 추가\n",
        "        for edge in edges:\n",
        "            if edge[0] < len(results) and edge[1] < len(results):\n",
        "                G.add_edge(edge[0], edge[1])\n",
        "\n",
        "        # 시각화\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        pos = nx.spring_layout(G, k=2, iterations=50)\n",
        "\n",
        "        # 노드 색상 (감정별)\n",
        "        emotion_colors = {\n",
        "            '기쁨': '#FFD700', '슬픔': '#4169E1', '분노': '#DC143C',\n",
        "            '공포': '#8B008B', '놀람': '#FF69B4', '혐오': '#228B22', '중립': '#C0C0C0'\n",
        "        }\n",
        "\n",
        "        node_colors = [emotion_colors[r['emotion']] for r in results]\n",
        "        node_sizes = [r['confidence'] * 3000 for r in results]\n",
        "\n",
        "        # 그래프 그리기\n",
        "        nx.draw_networkx_nodes(G, pos, node_color=node_colors,\n",
        "                              node_size=node_sizes, alpha=0.7)\n",
        "        nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
        "\n",
        "        # 라벨\n",
        "        labels = {i: r['token'] + '\\n' + r['emotion'][:2]\n",
        "                 for i, r in enumerate(results)}\n",
        "        nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
        "\n",
        "        plt.title(f'감정 그래프: \"{text}\"')\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def train_gnn_model(model, tokenizer, graph_builder, epochs=20):\n",
        "    \"\"\"GNN 모델 간단 훈련\"\"\"\n",
        "    # 훈련 데이터\n",
        "    train_data = [\n",
        "        (\"정말 기쁜 소식이에요 너무 행복해요\", \"joy\"),\n",
        "        (\"슬픈 이별의 순간이 왔어요\", \"sadness\"),\n",
        "        (\"화가 나서 참을 수가 없어요\", \"anger\"),\n",
        "        (\"무서운 일이 생길까봐 걱정돼요\", \"fear\"),\n",
        "        (\"깜짝 놀랄만한 일이 일어났어요\", \"surprise\"),\n",
        "        (\"역겨운 냄새가 나서 힘들어요\", \"disgust\")\n",
        "    ]\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    emotion_to_idx = {'joy': 0, 'sadness': 1, 'anger': 2,\n",
        "                     'fear': 3, 'surprise': 4, 'disgust': 5}\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for text, emotion in train_data:\n",
        "            # 그래프 구성\n",
        "            tokens, emotion_scores, edges, edge_weights = graph_builder.build_graph(text)\n",
        "\n",
        "            # 토크나이징\n",
        "            encoded = tokenizer(text, return_tensors='pt', truncation=True,\n",
        "                              padding='max_length', max_length=128)\n",
        "\n",
        "            # 레이블 생성\n",
        "            emotion_idx = emotion_to_idx[emotion]\n",
        "            labels = torch.full((1, 128), emotion_idx, dtype=torch.long)\n",
        "\n",
        "            # 엣지 처리\n",
        "            if edges:\n",
        "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
        "            else:\n",
        "                edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
        "\n",
        "            # 순전파\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(\n",
        "                encoded['input_ids'],\n",
        "                encoded['attention_mask'],\n",
        "                [emotion_scores],\n",
        "                edge_index\n",
        "            )\n",
        "\n",
        "            # Loss 계산\n",
        "            loss = criterion(logits.view(-1, 7), labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_data):.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "def display_gnn_results(text, results):\n",
        "    \"\"\"GNN 결과 출력\"\"\"\n",
        "    print(f\"\\n📝 분석 텍스트: {text}\")\n",
        "    print(\"\\n🔗 그래프 기반 감정 분석:\")\n",
        "\n",
        "    emotion_emoji = {\n",
        "        '기쁨': '😊', '슬픔': '😢', '분노': '😠',\n",
        "        '공포': '😨', '놀람': '😲', '혐오': '🤢', '중립': '😐'\n",
        "    }\n",
        "\n",
        "    for r in results:\n",
        "        emoji = emotion_emoji.get(r['emotion'], '')\n",
        "        graph_influence = r['graph_influence']\n",
        "        max_influence_idx = np.argmax(graph_influence)\n",
        "        influence_emotions = ['기쁨', '슬픔', '분노', '공포', '놀람', '혐오']\n",
        "\n",
        "        if r['emotion'] != '중립':\n",
        "            print(f\"  {r['token']:12s} → {emoji} {r['emotion']:4s} \"\n",
        "                  f\"(신뢰도: {r['confidence']:.2%}, \"\n",
        "                  f\"그래프 영향: {influence_emotions[max_influence_idx] if graph_influence[max_influence_idx] > 0 else '없음'})\")\n",
        "        else:\n",
        "            print(f\"  {r['token']:12s} → {emoji} {r['emotion']:4s} ({r['confidence']:.2%})\")\n",
        "\n",
        "    # 감정 네트워크 요약\n",
        "    print(\"\\n🌐 감정 네트워크 특성:\")\n",
        "    emotion_counts = {}\n",
        "    for r in results:\n",
        "        if r['emotion'] != '중립':\n",
        "            emotion_counts[r['emotion']] = emotion_counts.get(r['emotion'], 0) + 1\n",
        "\n",
        "    if emotion_counts:\n",
        "        for emotion, count in sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"  - {emotion}: {count}개 노드가 연결됨\")\n",
        "\n",
        "# 메인 실행\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🌐 Graph Neural Network 기반 감정 전파 모델\\n\")\n",
        "\n",
        "    # 초기화\n",
        "    tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
        "    graph_builder = EmotionGraphBuilder(tokenizer)\n",
        "    model = GraphEmotionNetwork('klue/bert-base')\n",
        "    analyzer = GNNEmotionAnalyzer(model, tokenizer, graph_builder)\n",
        "\n",
        "    # 간단 훈련\n",
        "    print(\"모델 훈련 중...\")\n",
        "    model = train_gnn_model(model, tokenizer, graph_builder, epochs=10)\n",
        "\n",
        "    # 테스트\n",
        "    test_texts = [\n",
        "        \"기쁜 소식을 듣고 행복해서 눈물이 났어요\",\n",
        "        \"무서운 이야기를 듣고 너무 놀라고 두려웠어요\",\n",
        "        \"화가 나서 짜증이 나지만 참고 있어요\",\n",
        "        \"놀라운 결과에 기쁘면서도 믿기지 않아요\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"그래프 기반 감정 분석 결과\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for text in test_texts:\n",
        "        results, edges = analyzer.analyze(text)\n",
        "        display_gnn_results(text, results)\n",
        "        print(f\"  → 그래프 엣지 수: {len(edges)}개\")\n",
        "        print(\"-\"*60)\n",
        "\n",
        "        # 그래프 시각화 (선택적)\n",
        "        # analyzer.visualize_emotion_graph(text, results, edges)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
