{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3mtar7frMyD",
        "outputId": "39b70162-0ae3-4c5b-ab88-f13fadf0139e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m835.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# 0) ì„¤ì¹˜ (Colab ìµœì´ˆ ì‹¤í–‰ ì‹œ)\n",
        "# =========================================\n",
        "!pip -q install -U langchain langchain-openai langchain-community langsmith faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAcrz5DxrQoJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1) (ì„ íƒ) OpenAI ì‚¬ìš© ì‹œ\n",
        "import os, uuid\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
        "OPENAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LangSmith_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "# 2) LangSmith ì—°ë™ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"      # íŠ¸ë ˆì´ì‹± í™œì„±í™”\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"]   = \"https://api.smith.langchain.com\"  # ê¸°ë³¸ê°’\n",
        "os.environ[\"LANGSMITH_PROJECT\"]    = \"llm_colab_ex_2\"                 # ìˆ˜ì—…ìš© í”„ë¡œì íŠ¸ëª…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOg2x2sorKmy",
        "outputId": "4341e4be-1382-4882-bc2a-954082e39895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì²­í‚¹ëœ ë¬¸ì„œ ê°œìˆ˜: 4\n",
            "Chunk 0: LangSmithëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê´€ì°°, í‰ê°€, ë””ë²„ê¹…í•  ìˆ˜ ìˆëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.\n",
            "Chunk 1: LangChainì€ LLMì„ ì²´ì¸ìœ¼ë¡œ êµ¬ì„±í•´ ì‰½ê²Œ ê°œë°œ/ìš´ì˜í•˜ë„ë¡ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
            "Chunk 2: RAG(Retrieval-Augmented Generation)ëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•´ ë‹µë³€ì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
            "Chunk 3: ì„ë² ë”©(embedding)ì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”í•˜ê³ , ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
            "LangSmithëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê´€ì°°, í‰ê°€, ë””ë²„ê¹…í•  ìˆ˜ ìˆëŠ” í”Œë«í¼ì´ë©°, RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•´ ë‹µë³€ì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ë‘ ê°œë…ì€ LLMì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ í•¨ê»˜ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# =========================================\n",
        "# 2) ë¬¸ì„œ ì˜ˆì œ ì¤€ë¹„\n",
        "# =========================================\n",
        "docs_text = \"\"\"\n",
        "LangSmithëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê´€ì°°, í‰ê°€, ë””ë²„ê¹…í•  ìˆ˜ ìˆëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.\n",
        "LangChainì€ LLMì„ ì²´ì¸ìœ¼ë¡œ êµ¬ì„±í•´ ì‰½ê²Œ ê°œë°œ/ìš´ì˜í•˜ë„ë¡ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
        "RAG(Retrieval-Augmented Generation)ëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•´ ë‹µë³€ì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
        "ì„ë² ë”©(embedding)ì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”í•˜ê³ , ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
        "\"\"\"\n",
        "\n",
        "# =========================================\n",
        "# 3) ì²­í‚¹ (ë¬¸ì„œ ë¶„í• )\n",
        "# =========================================\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=80, chunk_overlap=20)\n",
        "docs = splitter.create_documents([docs_text])\n",
        "\n",
        "print(\"âœ… ì²­í‚¹ëœ ë¬¸ì„œ ê°œìˆ˜:\", len(docs))\n",
        "for i, d in enumerate(docs):\n",
        "    print(f\"Chunk {i}:\", d.page_content)\n",
        "\n",
        "# =========================================\n",
        "# 4) ì„ë² ë”© & ë²¡í„°ìŠ¤í† ì–´ (FAISS)\n",
        "# =========================================\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "# =========================================\n",
        "# 5) Retriever + LLM + Prompt â†’ ì²´ì¸\n",
        "# =========================================\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"ì§ˆë¬¸: {question}\\n\"\n",
        "    \"ê²€ìƒ‰ëœ ë¬¸ì„œ:\\n{context}\\n\"\n",
        "    \"ğŸ‘‰ ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°íˆ ë‹µí•´ì¤˜.\"\n",
        ")\n",
        "\n",
        "# ì²´ì¸ ì •ì˜ (Runnable ì¡°í•©)\n",
        "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# =========================================\n",
        "# 6) LangSmith íŠ¸ë˜í‚¹ ì‹¤í–‰\n",
        "# =========================================\n",
        "config = {\n",
        "    \"tags\": [\"demo\", \"rag\", \"chunking\", \"embedding\"],\n",
        "    \"metadata\": {\"lesson\":\"ls-tracing-03\"},\n",
        "    \"run_name\": \"rag_with_chunking_embedding\"\n",
        "}\n",
        "\n",
        "print(rag_chain.invoke(\"LangSmithì™€ RAGëŠ” ì–´ë–¤ ê´€ê³„ê°€ ìˆë‚˜ìš”?\", config=config))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
