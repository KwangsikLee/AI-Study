{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangSmith & simple evaluation\n",
        "\n",
        "# simple evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "asTgozvhYF7o"
      },
      "outputs": [],
      "source": [
        "# ========== 1. 패키지 설치 ==========\n",
        "!pip install langsmith langchain langchain-openai langchain-community chromadb tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UTutrzhXeaf9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ========== 2. 환경 설정 ==========\n",
        "import os\n",
        "import getpass\n",
        "import json\n",
        "import pandas as pd\n",
        "from typing import List, Dict\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpvyoDYhedVx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# OpenAI API 키 설정 (사용자가 입력해야 함)\n",
        "# from google.colab import userdata\n",
        "# api_key=userdata.get('api_key')\n",
        "# os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API 클라이언트 생성\n",
        "OPENAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LangSmith_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "\n",
        "# 2) LangSmith 연동 필수 환경변수\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"      # 트레이싱 활성화\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"]   = \"https://api.smith.langchain.com\"  # 기본값\n",
        "os.environ[\"LANGSMITH_PROJECT\"]    = \"RAG_EV_ex1\"                 # 수업용 프로젝트명"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFvhLydRfDxu",
        "outputId": "057c9581-2002-4c8a-f577-43cb9293bdfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "생성된 청크 수: 3\n",
            "\n",
            "===== 합성 테스트 데이터 생성 시작 =====\n",
            "✅ Simple 질문 6개 생성 완료\n",
            "✅ Reasoning 질문 3개 생성 완료\n",
            "✅ Multi-context 질문 2개 생성 완료\n",
            "\n",
            "총 11개의 테스트 케이스 생성 완료!\n",
            "\n",
            "===== 생성된 테스트 데이터셋 미리보기 =====\n",
            "\n",
            "[테스트 케이스 1]\n",
            "질문: 인공지능(AI)은 무엇을 구현한 컴퓨터 시스템인가요?\n",
            "정답: 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현한 컴퓨터 시스템입니다.\n",
            "유형: simple\n",
            "컨텍스트 수: 1\n",
            "--------------------------------------------------\n",
            "\n",
            "[테스트 케이스 2]\n",
            "질문: 머신러닝은 AI의 어떤 분야인가요?\n",
            "정답: AI의 한 분야로, 데이터를 통해 컴퓨터가 스스로 학습하도록 하는 기술입니다.\n",
            "유형: simple\n",
            "컨텍스트 수: 1\n",
            "--------------------------------------------------\n",
            "\n",
            "[테스트 케이스 3]\n",
            "질문: 딥러닝은 무엇을 통해 복잡한 패턴을 학습하나요?\n",
            "정답: 인공신경망을 여러 층으로 쌓아 복잡한 패턴을 학습합니다.\n",
            "유형: simple\n",
            "컨텍스트 수: 1\n",
            "--------------------------------------------------\n",
            "\n",
            "✅ 데이터셋이 LangSmith에 업로드되었습니다!\n",
            "데이터셋 이름: synthetic_qa_dataset_v3\n",
            "테스트 케이스 수: 11\n",
            "\n",
            "===== 데이터셋 통계 =====\n",
            "evolution_type\n",
            "simple           6\n",
            "reasoning        3\n",
            "multi_context    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "질문 길이:\n",
            "  평균: 28.8 글자\n",
            "  최소: 18 글자\n",
            "  최대: 37 글자\n",
            "\n",
            "답변 길이:\n",
            "  평균: 121.7 글자\n",
            "  최소: 16 글자\n",
            "  최대: 329 글자\n",
            "\n",
            "✅ 데이터셋이 'synthetic_qa_dataset.csv'로 저장되었습니다.\n",
            "\n",
            "===== 데이터 품질 검증 =====\n",
            "✅ 중복 질문 없음\n",
            "✅ 모든 질문과 답변이 정상적으로 생성됨\n",
            "\n",
            "===== 샘플 품질 평가 (처음 3개) =====\n",
            "\n",
            "케이스 1:\n",
            "  컨텍스트 겹침: 100.00%\n",
            "  완성도: ✅\n",
            "\n",
            "케이스 2:\n",
            "  컨텍스트 겹침: 100.00%\n",
            "  완성도: ✅\n",
            "\n",
            "케이스 3:\n",
            "  컨텍스트 겹침: 100.00%\n",
            "  완성도: ✅\n",
            "\n",
            "🎉 합성 테스트 데이터셋 생성 완료!\n",
            "총 11개의 고품질 QA 쌍이 생성되었습니다.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ========== 3. 샘플 문서 준비 ==========\n",
        "sample_documents = [\n",
        "    \"\"\"\n",
        "    인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현한 컴퓨터 시스템입니다.\n",
        "    머신러닝은 AI의 한 분야로, 데이터를 통해 컴퓨터가 스스로 학습하도록 하는 기술입니다.\n",
        "    딥러닝은 머신러닝의 한 방법으로, 인공신경망을 여러 층으로 쌓아 복잡한 패턴을 학습합니다.\n",
        "    최근에는 GPT, BERT 같은 대규모 언어모델이 AI 발전을 주도하고 있습니다.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    자연어처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 처리하는 기술입니다.\n",
        "    최근 트랜스포머 모델의 등장으로 NLP 분야는 큰 발전을 이루었습니다.\n",
        "    BERT는 양방향 인코더 표현을 사용하여 문맥을 이해하는 모델입니다.\n",
        "    GPT는 자기회귀 방식으로 텍스트를 생성하는 언어모델입니다.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    RAG(Retrieval-Augmented Generation)는 검색과 생성을 결합한 AI 기술입니다.\n",
        "    외부 지식베이스에서 관련 정보를 검색한 후, 이를 바탕으로 답변을 생성합니다.\n",
        "    이를 통해 LLM의 환각(hallucination) 문제를 완화하고 최신 정보를 반영할 수 있습니다.\n",
        "    벡터 데이터베이스를 활용하여 효율적인 유사도 검색을 수행합니다.\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "# Document 객체로 변환\n",
        "documents = [Document(page_content=doc, metadata={\"source\": f\"doc_{i}\"})\n",
        "             for i, doc in enumerate(sample_documents)]\n",
        "\n",
        "# ========== 4. 텍스트 분할 ==========\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"생성된 청크 수: {len(chunks)}\")\n",
        "\n",
        "# ========== 5. LLM 기반 QA 생성 클래스 ==========\n",
        "class SyntheticQAGenerator:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def generate_simple_questions(self, text: str, num_questions: int = 3) -> List[Dict]:\n",
        "        \"\"\"단순 사실 확인 질문 생성\"\"\"\n",
        "        prompt = PromptTemplate(\n",
        "            input_variables=[\"text\", \"num_questions\"],\n",
        "            template=\"\"\"다음 텍스트를 읽고 직접적인 사실 확인 질문과 답변을 생성하세요.\n",
        "\n",
        "텍스트:\n",
        "{text}\n",
        "\n",
        "요구사항:\n",
        "- {num_questions}개의 질문-답변 쌍을 생성하세요\n",
        "- 질문은 텍스트에서 직접 찾을 수 있는 내용이어야 합니다\n",
        "- 답변은 간결하고 정확해야 합니다\n",
        "\n",
        "다음 JSON 형식으로 출력하세요:\n",
        "[\n",
        "    {{\n",
        "        \"question\": \"질문 내용\",\n",
        "        \"answer\": \"답변 내용\"\n",
        "    }},\n",
        "    ...\n",
        "]\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "        response = self.llm.invoke(prompt.format(text=text, num_questions=num_questions))\n",
        "\n",
        "        try:\n",
        "            # JSON 파싱\n",
        "            qa_pairs = json.loads(response.content)\n",
        "            return [\n",
        "                {\n",
        "                    \"question\": qa[\"question\"],\n",
        "                    \"ground_truth\": qa[\"answer\"],\n",
        "                    \"contexts\": [text],\n",
        "                    \"evolution_type\": \"simple\"\n",
        "                }\n",
        "                for qa in qa_pairs\n",
        "            ]\n",
        "        except:\n",
        "            # JSON 파싱 실패 시 대체 방법\n",
        "            return self._parse_fallback(response.content, text, \"simple\")\n",
        "\n",
        "    def generate_reasoning_questions(self, texts: List[str], num_questions: int = 2) -> List[Dict]:\n",
        "        \"\"\"추론이 필요한 질문 생성\"\"\"\n",
        "        combined_text = \"\\n\\n\".join(texts)\n",
        "        prompt = PromptTemplate(\n",
        "            input_variables=[\"text\", \"num_questions\"],\n",
        "            template=\"\"\"다음 텍스트들을 읽고 추론이 필요한 질문과 답변을 생성하세요.\n",
        "\n",
        "텍스트:\n",
        "{text}\n",
        "\n",
        "요구사항:\n",
        "- {num_questions}개의 질문-답변 쌍을 생성하세요\n",
        "- 질문은 여러 정보를 종합하거나 추론이 필요한 내용이어야 합니다\n",
        "- 답변은 논리적이고 근거가 명확해야 합니다\n",
        "\n",
        "다음 JSON 형식으로 출력하세요:\n",
        "[\n",
        "    {{\n",
        "        \"question\": \"추론이 필요한 질문\",\n",
        "        \"answer\": \"논리적인 답변\"\n",
        "    }},\n",
        "    ...\n",
        "]\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "        response = self.llm.invoke(prompt.format(text=combined_text, num_questions=num_questions))\n",
        "\n",
        "        try:\n",
        "            qa_pairs = json.loads(response.content)\n",
        "            return [\n",
        "                {\n",
        "                    \"question\": qa[\"question\"],\n",
        "                    \"ground_truth\": qa[\"answer\"],\n",
        "                    \"contexts\": texts,\n",
        "                    \"evolution_type\": \"reasoning\"\n",
        "                }\n",
        "                for qa in qa_pairs\n",
        "            ]\n",
        "        except:\n",
        "            return self._parse_fallback(response.content, texts, \"reasoning\")\n",
        "\n",
        "    def generate_multi_context_questions(self, texts: List[str], num_questions: int = 2) -> List[Dict]:\n",
        "        \"\"\"여러 문서를 참조해야 하는 질문 생성\"\"\"\n",
        "        combined_text = \"\\n\\n\".join(texts)\n",
        "        prompt = PromptTemplate(\n",
        "            input_variables=[\"text\", \"num_questions\"],\n",
        "            template=\"\"\"다음 여러 텍스트를 종합하여 답해야 하는 질문과 답변을 생성하세요.\n",
        "\n",
        "텍스트:\n",
        "{text}\n",
        "\n",
        "요구사항:\n",
        "- {num_questions}개의 질문-답변 쌍을 생성하세요\n",
        "- 질문은 여러 문서의 정보를 종합해야 답할 수 있어야 합니다\n",
        "- 답변은 포괄적이고 상세해야 합니다\n",
        "\n",
        "다음 JSON 형식으로 출력하세요:\n",
        "[\n",
        "    {{\n",
        "        \"question\": \"종합적인 질문\",\n",
        "        \"answer\": \"포괄적인 답변\"\n",
        "    }},\n",
        "    ...\n",
        "]\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "        response = self.llm.invoke(prompt.format(text=combined_text, num_questions=num_questions))\n",
        "\n",
        "        try:\n",
        "            qa_pairs = json.loads(response.content)\n",
        "            return [\n",
        "                {\n",
        "                    \"question\": qa[\"question\"],\n",
        "                    \"ground_truth\": qa[\"answer\"],\n",
        "                    \"contexts\": texts,\n",
        "                    \"evolution_type\": \"multi_context\"\n",
        "                }\n",
        "                for qa in qa_pairs\n",
        "            ]\n",
        "        except:\n",
        "            return self._parse_fallback(response.content, texts, \"multi_context\")\n",
        "\n",
        "    def _parse_fallback(self, content: str, contexts, evolution_type: str) -> List[Dict]:\n",
        "        \"\"\"JSON 파싱 실패 시 대체 파싱\"\"\"\n",
        "        qa_pairs = []\n",
        "        lines = content.strip().split('\\n')\n",
        "\n",
        "        current_q = None\n",
        "        for line in lines:\n",
        "            if '\"question\"' in line.lower() or 'q:' in line.lower():\n",
        "                # 질문 추출\n",
        "                if ':' in line:\n",
        "                    current_q = line.split(':', 1)[1].strip().strip('\"').strip(',')\n",
        "            elif '\"answer\"' in line.lower() or 'a:' in line.lower():\n",
        "                # 답변 추출\n",
        "                if current_q and ':' in line:\n",
        "                    answer = line.split(':', 1)[1].strip().strip('\"').strip(',').strip('}')\n",
        "                    qa_pairs.append({\n",
        "                        \"question\": current_q,\n",
        "                        \"ground_truth\": answer,\n",
        "                        \"contexts\": contexts if isinstance(contexts, list) else [contexts],\n",
        "                        \"evolution_type\": evolution_type\n",
        "                    })\n",
        "                    current_q = None\n",
        "\n",
        "        return qa_pairs\n",
        "\n",
        "# ========== 6. 테스트 데이터셋 생성 ==========\n",
        "# LLM 초기화\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
        "\n",
        "# QA 생성기 초기화\n",
        "qa_generator = SyntheticQAGenerator(llm)\n",
        "\n",
        "print(\"\\n===== 합성 테스트 데이터 생성 시작 =====\")\n",
        "\n",
        "# 1. Simple 질문 생성\n",
        "simple_qa = []\n",
        "for chunk in chunks[:2]:\n",
        "    qa_pairs = qa_generator.generate_simple_questions(chunk.page_content, num_questions=3)\n",
        "    simple_qa.extend(qa_pairs)\n",
        "\n",
        "print(f\"✅ Simple 질문 {len(simple_qa)}개 생성 완료\")\n",
        "\n",
        "# 2. Reasoning 질문 생성\n",
        "reasoning_qa = qa_generator.generate_reasoning_questions(\n",
        "    [chunk.page_content for chunk in chunks[:3]],\n",
        "    num_questions=3\n",
        ")\n",
        "print(f\"✅ Reasoning 질문 {len(reasoning_qa)}개 생성 완료\")\n",
        "\n",
        "# 3. Multi-context 질문 생성\n",
        "multi_context_qa = qa_generator.generate_multi_context_questions(\n",
        "    [chunk.page_content for chunk in chunks],\n",
        "    num_questions=2\n",
        ")\n",
        "print(f\"✅ Multi-context 질문 {len(multi_context_qa)}개 생성 완료\")\n",
        "\n",
        "# 모든 QA 결합\n",
        "all_qa = simple_qa + reasoning_qa + multi_context_qa\n",
        "test_df = pd.DataFrame(all_qa)\n",
        "\n",
        "print(f\"\\n총 {len(test_df)}개의 테스트 케이스 생성 완료!\")\n",
        "\n",
        "# ========== 7. 결과 확인 ==========\n",
        "print(\"\\n===== 생성된 테스트 데이터셋 미리보기 =====\")\n",
        "for idx, row in test_df.head(3).iterrows():\n",
        "    print(f\"\\n[테스트 케이스 {idx + 1}]\")\n",
        "    print(f\"질문: {row['question']}\")\n",
        "    print(f\"정답: {row['ground_truth']}\")\n",
        "    print(f\"유형: {row['evolution_type']}\")\n",
        "    print(f\"컨텍스트 수: {len(row['contexts'])}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# ========== 8. LangSmith에 데이터셋 업로드 ==========\n",
        "from langsmith import Client\n",
        "\n",
        "try:\n",
        "    client = Client()\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    dataset_name = \"synthetic_qa_dataset_v3\"\n",
        "    dataset = client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=\"LLM으로 생성한 합성 Q&A 테스트 데이터셋\"\n",
        "    )\n",
        "\n",
        "    # 각 테스트 케이스를 LangSmith에 추가\n",
        "    for idx, row in test_df.iterrows():\n",
        "        client.create_example(\n",
        "            dataset_id=dataset.id,\n",
        "            inputs={\n",
        "                \"question\": row['question'],\n",
        "                \"contexts\": row['contexts']\n",
        "            },\n",
        "            outputs={\n",
        "                \"answer\": row['ground_truth']\n",
        "            },\n",
        "            metadata={\n",
        "                \"evolution_type\": row['evolution_type']\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(f\"\\n✅ 데이터셋이 LangSmith에 업로드되었습니다!\")\n",
        "    print(f\"데이터셋 이름: {dataset_name}\")\n",
        "    print(f\"테스트 케이스 수: {len(test_df)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️ LangSmith 업로드 실패: {e}\")\n",
        "    print(\"로컬에만 저장합니다.\")\n",
        "\n",
        "# ========== 9. 데이터셋 통계 및 분석 ==========\n",
        "print(\"\\n===== 데이터셋 통계 =====\")\n",
        "print(test_df['evolution_type'].value_counts())\n",
        "\n",
        "# 질문/답변 길이 분석\n",
        "test_df['question_length'] = test_df['question'].str.len()\n",
        "test_df['answer_length'] = test_df['ground_truth'].str.len()\n",
        "\n",
        "print(f\"\\n질문 길이:\")\n",
        "print(f\"  평균: {test_df['question_length'].mean():.1f} 글자\")\n",
        "print(f\"  최소: {test_df['question_length'].min()} 글자\")\n",
        "print(f\"  최대: {test_df['question_length'].max()} 글자\")\n",
        "\n",
        "print(f\"\\n답변 길이:\")\n",
        "print(f\"  평균: {test_df['answer_length'].mean():.1f} 글자\")\n",
        "print(f\"  최소: {test_df['answer_length'].min()} 글자\")\n",
        "print(f\"  최대: {test_df['answer_length'].max()} 글자\")\n",
        "\n",
        "# ========== 10. CSV로 저장 ==========\n",
        "test_df.to_csv('synthetic_qa_dataset.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"\\n✅ 데이터셋이 'synthetic_qa_dataset.csv'로 저장되었습니다.\")\n",
        "\n",
        "# ========== 11. 품질 검증 ==========\n",
        "print(\"\\n===== 데이터 품질 검증 =====\")\n",
        "\n",
        "# 중복 질문 체크\n",
        "duplicate_questions = test_df[test_df.duplicated(['question'], keep=False)]\n",
        "if len(duplicate_questions) > 0:\n",
        "    print(f\"⚠️ 중복 질문 발견: {len(duplicate_questions)}개\")\n",
        "else:\n",
        "    print(\"✅ 중복 질문 없음\")\n",
        "\n",
        "# 빈 값 체크\n",
        "empty_questions = test_df[test_df['question'].str.strip() == '']\n",
        "empty_answers = test_df[test_df['ground_truth'].str.strip() == '']\n",
        "\n",
        "if len(empty_questions) > 0 or len(empty_answers) > 0:\n",
        "    print(f\"⚠️ 빈 값 발견 - 질문: {len(empty_questions)}개, 답변: {len(empty_answers)}개\")\n",
        "else:\n",
        "    print(\"✅ 모든 질문과 답변이 정상적으로 생성됨\")\n",
        "\n",
        "# ========== 12. 샘플 평가용 함수 (선택사항) ==========\n",
        "def evaluate_qa_quality(question: str, answer: str, context: str) -> Dict:\n",
        "    \"\"\"간단한 QA 품질 평가\"\"\"\n",
        "    # 답변이 컨텍스트에 기반하는지 체크\n",
        "    context_words = set(context.lower().split())\n",
        "    answer_words = set(answer.lower().split())\n",
        "\n",
        "    # 답변과 컨텍스트의 단어 겹침 비율\n",
        "    overlap_ratio = len(answer_words & context_words) / len(answer_words) if answer_words else 0\n",
        "\n",
        "    return {\n",
        "        \"question_length\": len(question),\n",
        "        \"answer_length\": len(answer),\n",
        "        \"context_overlap\": overlap_ratio,\n",
        "        \"is_complete\": '?' in question and len(answer) > 10\n",
        "    }\n",
        "\n",
        "# 샘플 평가\n",
        "print(\"\\n===== 샘플 품질 평가 (처음 3개) =====\")\n",
        "for idx, row in test_df.head(3).iterrows():\n",
        "    quality = evaluate_qa_quality(\n",
        "        row['question'],\n",
        "        row['ground_truth'],\n",
        "        row['contexts'][0] if row['contexts'] else \"\"\n",
        "    )\n",
        "    print(f\"\\n케이스 {idx+1}:\")\n",
        "    print(f\"  컨텍스트 겹침: {quality['context_overlap']:.2%}\")\n",
        "    print(f\"  완성도: {'✅' if quality['is_complete'] else '⚠️'}\")\n",
        "\n",
        "print(\"\\n🎉 합성 테스트 데이터셋 생성 완료!\")\n",
        "print(f\"총 {len(test_df)}개의 고품질 QA 쌍이 생성되었습니다.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
