{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOCrGa7II790",
        "outputId": "b74788f5-d6d4-4ce9-ebb2-3a068958ad0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/377.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ── 설치(최초 1회) ─────────────────────────────────────────────\n",
        "!pip -q install -U langchain langchain-openai langsmith\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvKYO0vMIvRB"
      },
      "outputs": [],
      "source": [
        "# 1) (선택) OpenAI 사용 시\n",
        "import os, uuid\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API 클라이언트 생성\n",
        "OPENAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LangSmith_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "# 2) LangSmith 연동 필수 환경변수\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"      # 트레이싱 활성화\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"]   = \"https://api.smith.langchain.com\"  # 기본값\n",
        "os.environ[\"LANGSMITH_PROJECT\"]    = \"llm_colab_ex_3\"                 # 수업용 프로젝트명\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "171ELdtcIteL",
        "outputId": "89d86e47-61da-4b10-c0c3-e4b0263aefc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단건:\n",
            "계산 결과: 166.0\n",
            "\n",
            "배치:\n",
            "- LangSmith는 자연어 처리(NLP) 모델을 개발하고 관리하는 데 도움을 주는 플랫폼으로, 모델의 성능을 향상시키고, 데이터 세트를 효율적으로 관리하며, 실험을 쉽게 수행할 수 있도록 지원합니다. 이를 통해 개발자와 연구자들이 더 나은 AI 솔루션을 구축할 수 있습니다.\n",
            "- 계산 결과: 500\n",
            "- RAG(Recall-Augmented Generation)는 정보 검색과 생성 모델을 결합한 방법입니다. 이 방식은 먼저 관련 정보를 검색한 후, 그 정보를 바탕으로 자연어를 생성하여 더 정확하고 풍부한 답변을 제공합니다. 주로 질문 응답 시스템이나 대화형 AI에서 사용됩니다.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ── 임포트 ───────────────────────────────────────────────────\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnableBranch, RunnablePassthrough\n",
        "\n",
        "# ── LLM & 공통 파서 ──────────────────────────────────────────\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# ── 안전 계산기(+, -, *, /, 괄호만 허용) ─────────────────────\n",
        "import re\n",
        "def safe_eval(expr: str) -> float:\n",
        "    expr = expr.replace(\" \", \"\")\n",
        "    if not re.fullmatch(r\"[0-9+\\-*/().]+\", expr):\n",
        "        raise ValueError(\"허용되지 않는 문자가 포함되어 있습니다.\")\n",
        "    return eval(expr, {\"__builtins__\": {}}, {})\n",
        "\n",
        "calc_chain = (\n",
        "    {\"expr\": RunnableLambda(lambda x: str(x[\"input\"]).split(\"calc:\",1)[1].strip())}\n",
        "    | RunnableLambda(lambda d: {\"result\": safe_eval(d[\"expr\"])})\n",
        "    | RunnableLambda(lambda d: f\"계산 결과: {d['result']}\")\n",
        ")\n",
        "\n",
        "# ── 일반 챗 체인 ──────────────────────────────────────────────\n",
        "prompt_chat = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 인공지능 비서이다. 답변은 간결하게.\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "chat_chain = prompt_chat | llm | parser\n",
        "\n",
        "# ── 라우터: 'calc:'로 시작하면 계산기로, 아니면 챗으로 ───────\n",
        "router = RunnableBranch(\n",
        "    (lambda x: str(x.get(\"input\",\"\")).lower().startswith(\"calc:\"), calc_chain),\n",
        "    chat_chain  # else\n",
        ")\n",
        "\n",
        "# ── 실행 (단건 + 배치) ───────────────────────────────────────\n",
        "cfg = {\"tags\":[\"demo\",\"routing\",\"branch\"], \"run_name\":\"intent_router_demo\"}\n",
        "\n",
        "print(\"단건:\")\n",
        "print(router.invoke({\"input\":\"calc: (23*7) + 10 / 2\"}, config=cfg))\n",
        "\n",
        "print(\"\\n배치:\")\n",
        "outs = router.batch(\n",
        "    [\n",
        "        {\"input\":\"오늘 LangSmith를 왜 쓰는지 간략하게 설명해줘\"},\n",
        "        {\"input\":\"calc: 100*(2+3)\"},\n",
        "        {\"input\":\"한국어로 RAG를 간단히 설명해줘\"}\n",
        "    ],\n",
        "    config=cfg\n",
        ")\n",
        "for o in outs:\n",
        "    print(\"-\", o)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
