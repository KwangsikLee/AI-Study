{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CfxZ-RowFgXD"
      },
      "outputs": [],
      "source": [
        "# ── 설치 (최초 1회만)\n",
        "!pip -q install -U langchain langchain-openai langsmith\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IGt6PYlFhHE"
      },
      "outputs": [],
      "source": [
        "# 1) (선택) OpenAI 사용 시\n",
        "import os, uuid\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API 클라이언트 생성\n",
        "OPENAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LangSmith_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "# 2) LangSmith 연동 필수 환경변수\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"      # 트레이싱 활성화\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"]   = \"https://api.smith.langchain.com\"  # 기본값\n",
        "os.environ[\"LANGSMITH_PROJECT\"]    = \"llm_colab_ex_RunnablePassthrough\"                 # 수업용 프로젝트명\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNauo2w4FdX4",
        "outputId": "f0a9799d-80d7-4e1d-f6ab-498f74cead2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith는 LLM 앱을 관찰, 평가, 디버깅할 수 있는 플랫폼입니다.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ── 임포트\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
        "\n",
        "# ── LLM 준비\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# ── 프롬프트: 질문(question)과 컨텍스트(context)를 받아 답변\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"질문: {question}\\n\"\n",
        "    \"컨텍스트: {context}\\n\"\n",
        "    \"👉 위 내용을 바탕으로 간단히 답해줘.\"\n",
        ")\n",
        "\n",
        "# ── RunnablePassthrough를 사용한 체인\n",
        "# question은 그대로 통과, context는 전처리 함수 적용\n",
        "chain = (\n",
        "    {\n",
        "        \"question\": RunnablePassthrough(),  # 입력의 question을 그대로 전달\n",
        "        \"context\": RunnableLambda(lambda x: f\"[Extra Context Attached] {x['context']}\")\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | parser\n",
        ")\n",
        "\n",
        "# ── 실행 (LangSmith 트래킹 태그/이름 추가)\n",
        "config = {\"tags\":[\"demo\",\"passthrough\"], \"run_name\":\"passthrough_demo\"}\n",
        "\n",
        "inputs = {\"question\": \"LangSmith는 무엇인가요?\", \"context\": \"LangSmith는 LLM 앱을 관찰/평가/디버깅할 수 있는 플랫폼이다.\"}\n",
        "\n",
        "print(chain.invoke(inputs, config=config))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
