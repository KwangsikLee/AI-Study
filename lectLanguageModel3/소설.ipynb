{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 소설 작성 \n",
        "\n",
        "## skt/kogpt2-base-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rjYsSqh8_P-Q",
        "outputId": "2b09cd7e-ee79-42c8-cd43-0b8854ade93c"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install numpy==1.26.4\n",
        "!pip install torch==2.2.2 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install transformers==4.41.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfMGsmAM-NuP",
        "outputId": "8bf4002f-da24-43a6-d39f-5f17972b5684"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =========================================\n",
        "# 1) 로딩\n",
        "# =========================================\n",
        "import re, random, textwrap\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MODEL_NAME = \"skt/kogpt2-base-v2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model     = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# GPT-2 계열은 pad 토큰이 없으므로 eos를 pad로 사용\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_Q39IEPn-PrA"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# 2) 유틸: 문장 경계/키워드 체크/연결어 등\n",
        "# =========================================\n",
        "CONNECTIVES = [\"그러나\", \"한편\", \"그때\", \"곧\", \"결국\", \"마침내\", \"한동안\", \"이윽고\", \"그럼에도\", \"하지만\"]\n",
        "\n",
        "def split_sentences_kr(text: str) -> List[str]:\n",
        "    sents = re.split(r'(?<=[\\.!?])\\s+', text.strip())\n",
        "    sents = [s.strip() for s in sents if s.strip()]\n",
        "    return sents\n",
        "\n",
        "def join_to_range(sents: List[str], min_n=5, max_n=7) -> str:\n",
        "    if len(sents) < min_n:\n",
        "        # 짧으면 마지막 문장을 약간 늘리는 방식으로 보정(그냥 이어 붙이기)\n",
        "        return \" \".join(sents)\n",
        "    return \" \".join(sents[:min(len(sents), max_n)])\n",
        "\n",
        "def ensure_connectives(sents: List[str]) -> List[str]:\n",
        "    # 2~4번째 문장에 연결어가 없으면 부드럽게 하나 추가\n",
        "    for idx in range(1, min(len(sents), 5)):\n",
        "        if not any(sents[idx].startswith(c) for c in CONNECTIVES):\n",
        "            sents[idx] = f\"{random.choice(CONNECTIVES)} \" + sents[idx]\n",
        "    return sents\n",
        "\n",
        "def contains_all_keywords(text: str, keywords: List[str]) -> bool:\n",
        "    low = text.lower()\n",
        "    return all(kw.lower() in low for kw in keywords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e_MSNHv1-RB4"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# 3) 프롬프트 설계 (계획 → 집필)\n",
        "# =========================================\n",
        "def build_outline_prompt(keywords: List[str]) -> str:\n",
        "    kw = \", \".join(keywords)\n",
        "    return (\n",
        "        \"아래 키워드들을 모두 중심 motief로 삼아 짧은 소설의 개요를 4줄로 작성하세요.\\n\"\n",
        "        \"각 줄은 항목명: 간결한 구절 형태로 쓰고 군더더기를 피하세요.\\n\"\n",
        "        \"항목: 배경, 인물, 갈등, 해결\\n\"\n",
        "        f\"키워드: {kw}\\n\"\n",
        "        \"개요:\\n\"\n",
        "        \"- 배경:\\n- 인물:\\n- 갈등:\\n- 해결:\"\n",
        "    )\n",
        "\n",
        "def build_story_prompt(keywords: List[str], outline: str, tone: str = \"담백하고 서정적인 3인칭 시점\"):\n",
        "    kw = \", \".join(keywords)\n",
        "    return (\n",
        "        \"다음 개요를 바탕으로 한국어 짧은 소설을 5~7문장으로 작성하세요.\\n\"\n",
        "        \"문장은 자연스럽고 연결이 매끄럽게 이어지며, 과도한 반복을 피합니다.\\n\"\n",
        "        f\"문체는 {tone}으로 유지하고, 모든 키워드를 반드시 포함합니다.\\n\"\n",
        "        \"문장마다 마침표로 끝맺고, 이야기의 호흡이 부드럽게 흐르도록 하세요.\\n\\n\"\n",
        "        f\"[키워드] {kw}\\n\"\n",
        "        f\"[개요]\\n{outline}\\n\"\n",
        "        \"[소설]\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MG9c_ben-Snm"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# 4) 생성기 (대조 탐색 우선, 폴백: 빔)\n",
        "# =========================================\n",
        "@torch.inference_mode()\n",
        "def generate_text(prompt: str,\n",
        "                  strategy: str = \"contrastive\",\n",
        "                  max_new_tokens: int = 220,\n",
        "                  temperature: float = 0.9,\n",
        "                  top_p: float = 0.92,\n",
        "                  num_beams: int = 5,\n",
        "                  penalty_alpha: float = 0.6,  # contrastive\n",
        "                  top_k: int = 4,             # contrastive\n",
        "                  repetition_penalty: float = 1.12,\n",
        "                  no_repeat_ngram_size: int = 3) -> str:\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
        "\n",
        "    gen_kwargs = dict(\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    if strategy == \"contrastive\":\n",
        "        # Contrastive Search: 더 일관적인 문장 경향\n",
        "        try:\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                do_sample=False,\n",
        "                penalty_alpha=penalty_alpha,\n",
        "                top_k=top_k,\n",
        "                **gen_kwargs\n",
        "            )\n",
        "        except Exception:\n",
        "            # 일부 환경/버전에서 contrastive 미지원 → 빔서치로 대체\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                do_sample=False,\n",
        "                num_beams=num_beams,\n",
        "                length_penalty=1.05,\n",
        "                early_stopping=True,\n",
        "                **gen_kwargs\n",
        "            )\n",
        "    elif strategy == \"beam\":\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            do_sample=False,\n",
        "            num_beams=num_beams,\n",
        "            length_penalty=1.05,\n",
        "            early_stopping=True,\n",
        "            **gen_kwargs\n",
        "        )\n",
        "    else:  # sampling\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            **gen_kwargs\n",
        "        )\n",
        "\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # 프롬프트 이후만 추출\n",
        "    return text[len(prompt):].strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2lYiHVhK-UH9"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# 5) 엔드투엔드: 키워드 → 개요 → 소설 → 후편집(+재시도)\n",
        "# =========================================\n",
        "def generate_outline(keywords: List[str],\n",
        "                     strategy=\"beam\",\n",
        "                     max_new_tokens=120) -> str:\n",
        "    prompt = build_outline_prompt(keywords)\n",
        "    raw = generate_text(prompt, strategy=strategy, max_new_tokens=max_new_tokens)\n",
        "    # 간단 정리: 불릿 없으면 줄 단위로 보정\n",
        "    lines = [ln.strip(\" -\") for ln in raw.splitlines() if ln.strip()]\n",
        "    # 첫 4줄만 사용\n",
        "    cleaned = []\n",
        "    for ln in lines:\n",
        "        if any(h in ln for h in [\"배경\", \"인물\", \"갈등\", \"해결\"]):\n",
        "            cleaned.append(ln)\n",
        "        elif len(cleaned) < 4:\n",
        "            cleaned.append(ln)\n",
        "        if len(cleaned) == 4:\n",
        "            break\n",
        "    # 포맷이 흐트러져도 그대로 사용\n",
        "    return \"\\n\".join(f\"- {ln}\" for ln in cleaned[:4])\n",
        "\n",
        "def post_edit_story(text: str, min_s=5, max_s=7) -> str:\n",
        "    sents = split_sentences_kr(text)\n",
        "    sents = [re.sub(r\"\\s+\", \" \", s).strip() for s in sents if s.strip()]\n",
        "    sents = ensure_connectives(sents)\n",
        "    story = join_to_range(sents, min_n=min_s, max_n=max_s)\n",
        "    return story\n",
        "\n",
        "def generate_short_story_smooth(\n",
        "    keywords: List[str],\n",
        "    tone: str = \"담백하고 서정적인 3인칭 시점\",\n",
        "    strategy: str = \"contrastive\",          # \"contrastive\" | \"beam\" | \"sample\"\n",
        "    max_new_tokens_outline: int = 120,\n",
        "    max_new_tokens_story: int = 220,\n",
        "    max_retries: int = 3,\n",
        "    seed: int = 42\n",
        ") -> Tuple[str, dict]:\n",
        "\n",
        "    assert len(keywords) > 0, \"키워드를 한 개 이상 입력하세요.\"\n",
        "    random.seed(seed); torch.manual_seed(seed)\n",
        "\n",
        "    # 1) 개요 생성\n",
        "    outline = generate_outline(keywords, strategy=\"beam\", max_new_tokens=max_new_tokens_outline)\n",
        "\n",
        "    # 2) 소설 생성 (+재시도: 키워드 누락 시 톤/전략 고정, 페널티만 조금씩 조정)\n",
        "    rep = 1.10\n",
        "    for attempt in range(1, max_retries+1):\n",
        "        prompt_story = build_story_prompt(keywords, outline, tone=tone)\n",
        "        raw = generate_text(\n",
        "            prompt_story,\n",
        "            strategy=strategy,\n",
        "            max_new_tokens=max_new_tokens_story,\n",
        "            repetition_penalty=rep,\n",
        "            no_repeat_ngram_size=3\n",
        "        )\n",
        "        story = post_edit_story(raw, min_s=5, max_s=7)\n",
        "\n",
        "        if contains_all_keywords(story, keywords):\n",
        "            return story, {\"attempt\": attempt, \"strategy\": strategy, \"repetition_penalty\": rep, \"tone\": tone}\n",
        "\n",
        "        # 키워드 빠졌으면 재시도(반복 페널티↑)\n",
        "        rep = min(1.25, rep + 0.05)\n",
        "\n",
        "    # 3) 마지막 시도 결과라도 반환\n",
        "    return story, {\"attempt\": attempt, \"strategy\": strategy, \"repetition_penalty\": rep, \"tone\": tone}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li2ugE7Q-Wer",
        "outputId": "ecf04db6-b2c5-44c0-e1a5-875e9fc76351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 키워드: ['비', '소녀', '들판', '우산'] ===\n",
            "비, 소녀,들판, 우산 이 게임의 주인공. 한편 성우는 카와스미 아야코/정규 1기 오프닝에서 나왔던 오리지널 캐릭터. 그러나 원작과 같은 인물로, 마법소녀 리리컬\n",
            "나노하 일레븐에 등장하는 괴인 중 한 명이다. 결국 본래 이름은 코바야시 히토미의 친누나이자 사쿠라이 유우키가 맡았다. 곧 고스트 버스터즈의 히로인으로 등장할\n",
            "예정이었으나 갑작스럽게 불발된 바 있다. 그런데 이 캐릭터의 외모를 보고 팬들이 놀라는 일이 벌어지기도 했다. (...\n",
            "메타: {'attempt': 1, 'strategy': 'contrastive', 'repetition_penalty': 1.1, 'tone': '담백하고 서정적인 3인칭 시점'}\n",
            "\n",
            "=== 키워드: ['바다', '라디오', '여름밤'] ===\n",
            "해리포터 시리즈와 마블 코믹스의 캐릭터를 원작으로 한 영화. 한편 이 게임은 전작과 같은 난이도를 자랑한다. 하지만 다행히 스토리가 길기 때문에 플레이어들의\n",
            "평타에 맞출 수 있는 스킬들이 꽤 많이 나오며, 그 중 가장 높은 점수를 받을 수 있다는 점이 매력 포인트. 한동안 또한 스테이지 클리어 보상으로 아이템 획득량이\n",
            "증가하기 때문에, 초반에는 어렵지 않게 클리어가 가능하다. 그러나 고레벨 유저들을 위한 패치도 진행중이다. 전작의 보스 몬스터인 카미카제 일행을 처치하면 레벨\n",
            "5가 되는 것을 볼 수 있다. 보스몬스터로 등장했을 때 얻을 수 있었던 카드들은 다음과 같다.\n",
            "메타: {'attempt': 3, 'strategy': 'contrastive', 'repetition_penalty': 1.25, 'tone': '담백하고 서정적인 3인칭 시점'}\n",
            "\n",
            "=== 키워드: ['연구실', '노트', '낡은 시계', '비밀'] ===\n",
            "완성도 높은 시나리오가 나올 수 있도록 도와줍니다. 한편 (단순 암기하는 방식 ) ※ 이 글을 읽다 보면 다음과 같은 내용이 떠오릅니다. 하지만 2016년 1월,\n",
            "한화생명은 서울 여의도 63빌딩에서 ‘생명보험사회공헌위원회’를 발족했다. 한동안 그동안 사회 공헌 활동을 해온 임직원들을 중심으로 구성됐으며, 올해 창립\n",
            "20주년을 맞는다. 그러나 한화생명 관계자는 “지난 20년간 지속가능경영에 대한 의지를 다지기 위해 노력해왔다”며 “이번 위원회 출범으로 더 많은 분들이 참여할\n",
            "것으로 기대한다”고 말했다. 한국관광공사(사장 오지철)는 국내 여행업계 최초로 외국인 전용 카지노인 파라다이스를 개장한다고 밝혔다. 외국인전용카지노는 내국인이\n",
            "출입할 수 있는 시설 중 가장 규모가 큰 관광숙박시설이다.\n",
            "메타: {'attempt': 3, 'strategy': 'contrastive', 'repetition_penalty': 1.25, 'tone': '담백하고 서정적인 3인칭 시점'}\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# 6) 테스트\n",
        "# =========================================\n",
        "cases = [\n",
        "    [\"비\", \"소녀\", \"들판\", \"우산\"],\n",
        "    [\"바다\", \"라디오\", \"여름밤\"],\n",
        "    [\"연구실\", \"노트\", \"낡은 시계\", \"비밀\"]\n",
        "]\n",
        "\n",
        "for kws in cases:\n",
        "    story, meta = generate_short_story_smooth(\n",
        "        kws,\n",
        "        tone=\"담백하고 서정적인 3인칭 시점\",   # 다른 톤 예: \"차분한 1인칭 회고체\", \"미묘하게 긴장감 있는 묘사체\"\n",
        "        strategy=\"contrastive\",              # contrastive ↔ beam ↔ sample\n",
        "        max_new_tokens_outline=120,\n",
        "        max_new_tokens_story=220,\n",
        "        max_retries=3,\n",
        "        seed=42\n",
        "    )\n",
        "    print(f\"\\n=== 키워드: {kws} ===\")\n",
        "    print(textwrap.fill(story, width=90))\n",
        "    print(\"메타:\", meta)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
