{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suVbLJAikN3w",
        "outputId": "2c2a273a-5035-46b7-91e7-fc661ee2dedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/310.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/310.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install transformers accelerate sentencepiece pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, math, textwrap, torch\n",
        "from typing import List, Dict, Tuple\n",
        "from dataclasses import dataclass\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForQuestionAnswering, pipeline,\n",
        "    AutoModelForSeq2SeqLM\n",
        ")\n",
        "from pypdf import PdfReader\n",
        "\n",
        "DEVICE = 0 if torch.cuda.is_available() else -1\n",
        "print(\"Device:\", \"GPU\" if DEVICE==0 else \"CPU\")\n",
        "\n",
        "# --- (A) 한국어 추출형 QA 파이프라인: KoELECTRA (KorQuAD 파인튜닝) ---\n",
        "qa_tok = AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v3-discriminator\")\n",
        "qa_model = AutoModelForQuestionAnswering.from_pretrained(\n",
        "    \"monologg/koelectra-small-v3-finetuned-korquad\"\n",
        ")\n",
        "qa = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tok, device=DEVICE)\n",
        "\n",
        "# --- (B) 한국어 요약 파이프라인: KoBART 요약 ---\n",
        "# KoBART는 fast 토크나이저 이슈가 있을 수 있어 use_fast=False로 로드\n",
        "sum_name = \"gogamza/kobart-summarization\"\n",
        "# Changed use_fast=False to use_fast=True\n",
        "sum_tok = AutoTokenizer.from_pretrained(sum_name, use_fast=True)\n",
        "sum_model = AutoModelForSeq2SeqLM.from_pretrained(sum_name)\n",
        "summarizer = pipeline(\"summarization\", model=sum_model, tokenizer=sum_tok, device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyH3tOFCks0v",
        "outputId": "9f437556-2185-447a-b629-0dfb1b402b6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
            "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
            "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰 단위 슬라이딩 윈도"
      ],
      "metadata": {
        "id": "9lkf0doBkvL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Chunk:\n",
        "    idx: int\n",
        "    text: str\n",
        "    start_char: int\n",
        "    end_char: int\n",
        "    token_len: int\n",
        "\n",
        "def chunk_by_tokens(\n",
        "    text: str,\n",
        "    tokenizer,\n",
        "    max_tokens: int = 384,     # 청크 크기(토큰)\n",
        "    stride_tokens: int = 64     # 겹침(오버랩) 크기(토큰)\n",
        ") -> List[Chunk]:\n",
        "    \"\"\"\n",
        "    문서를 토큰 단위로 슬라이딩 윈도 청킹합니다.\n",
        "    - max_tokens : 한 청크의 최대 토큰 수\n",
        "    - stride_tokens : 다음 청크로 이동할 때 겹치는 토큰 수(문맥 보존)\n",
        "    반환: 청크 리스트(텍스트와 원문 내 문자 위치 포함)\n",
        "    \"\"\"\n",
        "    assert stride_tokens < max_tokens, \"stride_tokens < max_tokens 여야 합니다.\"\n",
        "\n",
        "    # 토큰화(오프셋 매핑으로 원문 문자 위치 역추적)\n",
        "    enc = tokenizer(\n",
        "        text, return_offsets_mapping=True, add_special_tokens=False\n",
        "    )\n",
        "    input_ids = enc[\"input_ids\"]\n",
        "    offsets = enc[\"offset_mapping\"]\n",
        "\n",
        "    chunks: List[Chunk] = []\n",
        "    start_tok = 0\n",
        "    idx = 0\n",
        "    while start_tok < len(input_ids):\n",
        "        end_tok = min(start_tok + max_tokens, len(input_ids))\n",
        "        # 토큰 → 문자 위치\n",
        "        start_char = offsets[start_tok][0] if start_tok < len(offsets) else 0\n",
        "        end_char = offsets[end_tok-1][1] if end_tok-1 < len(offsets) else len(text)\n",
        "        chunk_text = text[start_char:end_char]\n",
        "\n",
        "        chunks.append(\n",
        "            Chunk(\n",
        "                idx=idx,\n",
        "                text=chunk_text,\n",
        "                start_char=start_char,\n",
        "                end_char=end_char,\n",
        "                token_len=(end_tok - start_tok),\n",
        "            )\n",
        "        )\n",
        "        idx += 1\n",
        "        if end_tok == len(input_ids):\n",
        "            break\n",
        "        # 슬라이딩: (현재 시작 + max_tokens - stride) 지점으로 이동\n",
        "        start_tok = end_tok - stride_tokens\n",
        "\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "sKMTIRC8kvm1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF 텍스트 추출 함수"
      ],
      "metadata": {
        "id": "dyBikpREk0nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pdf_text(pdf_path: str, max_pages: int = None) -> str:\n",
        "    reader = PdfReader(pdf_path)\n",
        "    pages = reader.pages[:max_pages] if max_pages else reader.pages\n",
        "    texts = []\n",
        "    for p in pages:\n",
        "        t = p.extract_text() or \"\"\n",
        "        texts.append(t)\n",
        "    return \"\\n\".join(texts)\n"
      ],
      "metadata": {
        "id": "Hscqnez7k1tv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ① 직접 텍스트를 넣어 데모\n",
        "demo_text = \"\"\"\n",
        "소나기는 1959년에 발표된 황순원의 단편소설이다. 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려진다.\n",
        "작품은 강렬한 자연의 이미지와 사소한 사건들을 통해 성장의 순간을 섬세하게 포착한다.\n",
        "특히 갑작스런 소나기와 그 후의 정적은 인물들의 감정을 비유적으로 드러내는 장치로 기능한다.\n",
        "이 작품은 한국 단편소설의 고전으로 평가받는다.\n",
        "\"\"\" * 20  # 길이를 늘리기 위해 반복\n",
        "\n",
        "# ② PDF로 실습하려면 아래 주석 해제 후 파일 경로 지정\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # PDF 업로드\n",
        "# pdf_path = list(uploaded.keys())[0]\n",
        "# demo_text = read_pdf_text(pdf_path, max_pages=10)\n"
      ],
      "metadata": {
        "id": "ggutyWzJk3ql"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "청킹 시각화"
      ],
      "metadata": {
        "id": "eG5V_ZOwk6Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰 기준 청킹\n",
        "chunks = chunk_by_tokens(\n",
        "    demo_text,\n",
        "    tokenizer=qa_tok,         # QA 토크나이저 기준으로 청킹하면 좋음\n",
        "    max_tokens=384,\n",
        "    stride_tokens=64\n",
        ")\n",
        "\n",
        "print(f\"총 청크 수: {len(chunks)}  |  첫 3개 미리보기\")\n",
        "for c in chunks[:3]:\n",
        "    preview = textwrap.shorten(c.text.replace(\"\\n\", \" \"), width=120)\n",
        "    print(f\"[{c.idx:02d}] tokens={c.token_len:3d}  chars=({c.start_char}-{c.end_char})  {preview}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFtuFadek6ju",
        "outputId": "43059c2a-f51d-470e-ee84-d727d2f47d87"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1980 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 청크 수: 6  |  첫 3개 미리보기\n",
            "[00] tokens=384  chars=(1-782)  소나기는 1959년에 발표된 황순원의 단편소설이다. 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려진다. 작품은 강렬한 자연의 이미지와 사소한 사건들을 통해 성장의 순간을 섬세하게 [...]\n",
            "[01] tokens=384  chars=(645-1428)  한 감정이 여름 들판과 소나기라는 배경 속에서 그려진다. 작품은 강렬한 자연의 이미지와 사소한 사건들을 통해 성장의 순간을 섬세하게 포착한다. 특히 갑작스런 소나기와 그 후의 정적은 인물들의 감정을 [...]\n",
            "[02] tokens=384  chars=(1297-2076)  사소한 사건들을 통해 성장의 순간을 섬세하게 포착한다. 특히 갑작스런 소나기와 그 후의 정적은 인물들의 감정을 비유적으로 드러내는 장치로 기능한다. 이 작품은 한국 단편소설의 고전으로 평가받는다. 소나기는 [...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "청킹 기반 한국어 QA"
      ],
      "metadata": {
        "id": "obg8_rujk84S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def qa_over_chunks(question: str, chunks: List[Chunk], top_k: int = 3):\n",
        "    scored = []\n",
        "    for c in chunks:\n",
        "        try:\n",
        "            out = qa({\"question\": question, \"context\": c.text})\n",
        "            scored.append((out[\"score\"], out[\"answer\"], c))\n",
        "        except Exception as e:\n",
        "            # 청크가 너무 짧거나 토큰 이슈가 있을 수 있음 → 스킵\n",
        "            continue\n",
        "    # score 내림차순\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    return scored[:top_k]\n",
        "\n",
        "question = \"이 작품의 작가는 누구인가?\"\n",
        "top_answers = qa_over_chunks(question, chunks, top_k=3)\n",
        "\n",
        "print(f\"[질문] {question}\\n\")\n",
        "for rank, (score, ans, c) in enumerate(top_answers, 1):\n",
        "    prev = textwrap.shorten(c.text.replace(\"\\n\", \" \"), width=80)\n",
        "    print(f\"#{rank}  score={score:.4f}  answer=「{ans}」  (chunk={c.idx}, tokens={c.token_len})\")\n",
        "    print(f\"    └ context: {prev}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BooEx8osk9KJ",
        "outputId": "1c3f628e-5926-4ccb-e4d3-b80feb588c28"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[질문] 이 작품의 작가는 누구인가?\n",
            "\n",
            "#1  score=1.2905  answer=「황순원의」  (chunk=5, tokens=380)\n",
            "    └ context: 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려진다. 작품은 강렬한 자연의 이미지와 사소한 사건들을 통해 [...]\n",
            "#2  score=1.1119  answer=「황순원의」  (chunk=4, tokens=384)\n",
            "    └ context: 고전으로 평가받는다. 소나기는 1959년에 발표된 황순원의 단편소설이다. 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 [...]\n",
            "#3  score=1.0679  answer=「황순원의」  (chunk=0, tokens=384)\n",
            "    └ context: 소나기는 1959년에 발표된 황순원의 단편소설이다. 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려진다. [...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "청킹 기반 요약 (Map-Reduce)"
      ],
      "metadata": {
        "id": "0eRmwS8Gk_mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_long_text(\n",
        "    text: str,\n",
        "    tokenizer,\n",
        "    chunk_tokens: int = 600,   # KoBART 입력 길이 감안(여유 잡기)\n",
        "    stride_tokens: int = 100,\n",
        "    map_max_new_tokens: int = 120,\n",
        "    reduce_max_new_tokens: int = 150,\n",
        ") -> Dict[str, str]:\n",
        "    # 1) 청킹 (요약 기준으로 토크나이저 바꿔도 OK)\n",
        "    sum_chunks = chunk_by_tokens(text, summarizer.tokenizer, chunk_tokens, stride_tokens)\n",
        "\n",
        "    # 2) Map 단계: 청크별 요약\n",
        "    partials = []\n",
        "    for c in sum_chunks:\n",
        "        # 너무 짧은 청크는 스킵\n",
        "        if c.token_len < 50:\n",
        "            continue\n",
        "        try:\n",
        "            s = summarizer(\n",
        "                c.text,\n",
        "                max_length=map_max_new_tokens,\n",
        "                min_length=min(50, map_max_new_tokens-10),\n",
        "                do_sample=False\n",
        "            )[0][\"summary_text\"].strip()\n",
        "            partials.append(s)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # 3) Reduce 단계: 부분 요약들을 하나로 합쳐 다시 요약\n",
        "    reduce_input = \"\\n\".join(partials)\n",
        "    final = summarizer(\n",
        "        reduce_input,\n",
        "        max_length=reduce_max_new_tokens,\n",
        "        min_length=min(70, reduce_max_new_tokens-20),\n",
        "        do_sample=False\n",
        "    )[0][\"summary_text\"].strip()\n",
        "\n",
        "    return {\"map_summaries\": partials, \"final_summary\": final}\n",
        "\n",
        "sum_out = summarize_long_text(demo_text, sum_tok)\n",
        "print(\"▶ 청크 요약 개수:\", len(sum_out[\"map_summaries\"]))\n",
        "print(\"\\n[최종 요약]\\n\", textwrap.fill(sum_out[\"final_summary\"], width=90))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQiH7_GKk_-n",
        "outputId": "9f64026f-0eff-4252-e169-b8684b3c6f40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ 청크 요약 개수: 4\n",
            "\n",
            "[최종 요약]\n",
            " 1959년에 발표된 황순원의 단편소설인 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려져 있고, 한 소년과 소녀의 풋풋한 감정이 여름\n",
            "들판과 소나기라는 배경 속에서 그려져 있다. 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려져 있다. 한 소년과 소녀의 풋풋한 감정이\n",
            "여름 들판과 소나기라는 배경 속에서 그려져 있다. 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려져 있다. 한 소년과 소녀의 풋풋한\n",
            "감정이 여름 들판과 소나기라는 배경 속에서 그려졌을작품은 강렬한 자연의 이미지와 사소한 사건들을 통해 성장의 순간을 섬세하게 포착하고, 성장의 순간을 섬세하게\n",
            "포착하고, 성장의 순간을 섬세하게 정적은 인물들의 감정을 비유적으로 드러내는 장치로 기능하였다.이 작품은 한국 단편소설의 고전으로 평가되고, 황금 황금소나기는\n",
            "1959년에 발표된 황순원의 단편소설인 한 소년과 소녀의 풋풋한 감정이 여름 들판과 소나기라는 배경 속에서 그려져 있다. 한 소년과 소녀의 풋풋한 감정이 여름\n",
            "들판과 소나기라는 배경 속에서 그려져 있다. 한 소년과 소녀\n"
          ]
        }
      ]
    }
  ]
}