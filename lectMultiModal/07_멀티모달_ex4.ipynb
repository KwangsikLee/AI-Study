{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ba117289213145658465990e9a21a79f",
            "952b5d34082e4313a42fe7429e3b1a1e",
            "3776246062fd4788b26ed14b9055d5a6",
            "effb384b71f14bedb86516157fa6f801",
            "6df62d02490c42dcbe3c4533eb50e08a",
            "2f6b6ef128874d7b85a26b62fffb6008",
            "f91508bf5a654dadb9d45e86d2ae746a",
            "db0eb96250ce44609b06a9d95d1f7255",
            "b811a4325b584db8bd0cd2171e7c06d6",
            "2d91d9acc6764c0b8c08282b409db3b3",
            "dbbcde36c6cf4d5eb178a06b8bc92353"
          ]
        },
        "id": "T44j3Nt6WY5v",
        "outputId": "be6960f6-147e-461d-8537-027bc384d000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Tavily Search (langchain-teddynote) ë¡œë“œ ì™„ë£Œ\n",
            "âœ… CLIP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ GPT & LangChain & Tavily ì—°ë™ ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œ\n",
            "======================================================================\n",
            "\n",
            "âœ… API í‚¤ ì„¤ì • ì™„ë£Œ:\n",
            "   â€¢ OpenAI API: sk-proj-ZFU7TcfmbMzg...\n",
            "   â€¢ LangSmith í”„ë¡œì íŠ¸: langgraph_5\n",
            "   â€¢ Tavily API: tvly-dev-r3bStTqv6qi...\n",
            "ğŸš€ GPT API ì—°ë™ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\n",
            "ğŸ”‘ API ì„œë¹„ìŠ¤ ì„¤ì • ì¤‘...\n",
            "âœ… OpenAI API: ì„¤ì •ë¨\n",
            "âœ… LangSmith: ì„¤ì •ë¨ (í”„ë¡œì íŠ¸: langgraph_6)\n",
            "âœ… Tavily API: ì„¤ì •ë¨\n",
            "ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: cpu\n",
            "ğŸ“¦ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë”©...\n",
            "âœ… ResNet ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
            "ğŸ” ë¹„ì „-ì–¸ì–´ ëª¨ë¸ ë¡œë”©...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba117289213145658465990e9a21a79f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… BLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
            "ğŸ§  GPT ë° LangChain ì´ˆê¸°í™”...\n",
            "âœ… LangSmith íŠ¸ë ˆì´ì‹± í™œì„±í™” (í”„ë¡œì íŠ¸: langgraph_6)\n",
            "âœ… GPT ë° LangChain ì´ˆê¸°í™” ì™„ë£Œ\n",
            "ğŸ” ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”...\n",
            "âœ… Tavily Search ë„êµ¬ ë¡œë“œ ì™„ë£Œ\n",
            "âœ… AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
            "\n",
            "ğŸŒ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
            "ğŸ’¡ ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤!\n",
            "ğŸ”— ìˆ˜ë™ ì ‘ì†: http://localhost:17861\n",
            "\n",
            "======================================================================\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://46eb9af34a9987d580.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://46eb9af34a9987d580.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# GPT API & LangChain ì—°ë™ ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œ (API í‚¤ ì§ì ‘ ì„¤ì •)\n",
        "# ì´ë¯¸ì§€ ì—…ë¡œë“œ, ë¶„ì„, ì§ˆë¬¸ë‹µë³€ì„ ëª¨ë‘ ì›¹ì—ì„œ í•  ìˆ˜ ìˆëŠ” í†µí•© ì‹œìŠ¤í…œ\n",
        "\n",
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜\"\"\"\n",
        "    packages = [\n",
        "        \"gradio\",\n",
        "        \"torch\",\n",
        "        \"torchvision\",\n",
        "        \"transformers\",\n",
        "        \"pillow\",\n",
        "        \"requests\",\n",
        "        \"matplotlib\",\n",
        "        \"openai\",\n",
        "        \"langchain\",\n",
        "        \"langchain-openai\",\n",
        "        \"langsmith\",\n",
        "        \"langchain-community\",\n",
        "        \"tavily-python\"\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"Warning: Failed to install {package}\")\n",
        "\n",
        "# langchain-teddynote ì„¤ì¹˜ (TavilySearchìš©)\n",
        "def install_teddynote():\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langchain-teddynote\"])\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"Warning: Failed to install langchain-teddynote\")\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤í–‰\n",
        "install_packages()\n",
        "install_teddynote()\n",
        "\n",
        "# CLIP ì„¤ì¹˜ (ë³„ë„ë¡œ)\n",
        "try:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"git+https://github.com/openai/CLIP.git\"])\n",
        "except:\n",
        "    print(\"Warning: CLIP installation failed, some features may be limited\")\n",
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# =============================================================================\n",
        "# API í‚¤ ì„¤ì • (ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥)\n",
        "# =============================================================================\n",
        "\n",
        "# OpenAI API í‚¤ ì„¤ì • (ì‚¬ìš©ìê°€ ì…ë ¥í•´ì•¼ í•¨)\n",
        "# from google.colab import userdata\n",
        "\n",
        "# api_key=userdata.get('api_key')\n",
        "# api_key2=userdata.get('api_key2')\n",
        "# api_key3=userdata.get('api_key3')\n",
        "# os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = api_key2\n",
        "# os.environ[\"TAVILY_API_KEY\"] = api_key3\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
        "OPENAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LangSmith_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
        "\n",
        "# 2) LangSmith ì—°ë™ ì„¤ì •\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langgraph_6\"\n",
        "\n",
        "# =============================================================================\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ë° ëª¨ë¸ ê°€ìš©ì„± í™•ì¸\n",
        "# =============================================================================\n",
        "\n",
        "# OpenAI & LangChain imports\n",
        "from openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.callbacks import LangChainTracer\n",
        "from langsmith import Client\n",
        "\n",
        "# Tavily Search import\n",
        "try:\n",
        "    from langchain_teddynote.tools.tavily import TavilySearch\n",
        "    TAVILY_AVAILABLE = True\n",
        "    print(\"âœ… Tavily Search (langchain-teddynote) ë¡œë“œ ì™„ë£Œ\")\n",
        "except ImportError:\n",
        "    try:\n",
        "        from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "        TAVILY_AVAILABLE = True\n",
        "        print(\"âœ… Tavily Search (community) ë¡œë“œ ì™„ë£Œ\")\n",
        "    except ImportError:\n",
        "        TAVILY_AVAILABLE = False\n",
        "        print(\"âŒ Tavily Search not available\")\n",
        "\n",
        "# CLIP import\n",
        "try:\n",
        "    import clip\n",
        "    CLIP_AVAILABLE = True\n",
        "    print(\"âœ… CLIP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
        "except ImportError:\n",
        "    CLIP_AVAILABLE = False\n",
        "    print(\"âŒ CLIP not available, using alternative methods\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class GPTMultimodalAI:\n",
        "    \"\"\"GPT API ì—°ë™ ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œ (API í‚¤ ì§ì ‘ ì„¤ì •)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"ğŸš€ GPT API ì—°ë™ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
        "\n",
        "        # ëª¨ë¸ ê°€ìš©ì„± ìƒíƒœ ì´ˆê¸°í™”\n",
        "        self.clip_available = False\n",
        "        self.blip_available = False\n",
        "        self.search_available = False\n",
        "\n",
        "        # API í‚¤ í™•ì¸ ë° ì„¤ì •\n",
        "        self.setup_api_services()\n",
        "\n",
        "        # ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}\")\n",
        "\n",
        "        # ëª¨ë¸ë“¤ ì´ˆê¸°í™”\n",
        "        self.init_classification_model()\n",
        "        self.init_vision_language_models()\n",
        "        self.init_gpt_and_langchain()\n",
        "        self.init_search_tools()\n",
        "\n",
        "        self.current_image = None\n",
        "        self.analysis_cache = {}\n",
        "\n",
        "        print(\"âœ… AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "\n",
        "    def setup_api_services(self):\n",
        "        \"\"\"API ì„œë¹„ìŠ¤ ì„¤ì •\"\"\"\n",
        "        print(\"ğŸ”‘ API ì„œë¹„ìŠ¤ ì„¤ì • ì¤‘...\")\n",
        "\n",
        "        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "        self.openai_api_key = OPENAI_API_KEY\n",
        "        self.openai_client = OpenAI(api_key=self.openai_api_key)\n",
        "\n",
        "        # LangSmith ì„¤ì • í™•ì¸\n",
        "        self.langsmith_api_key = os.environ.get(\"LANGCHAIN_API_KEY\")\n",
        "        self.langsmith_project = os.environ.get(\"LANGSMITH_PROJECT\", \"langgraph_5\")\n",
        "\n",
        "        print(f\"âœ… OpenAI API: ì„¤ì •ë¨\")\n",
        "        print(f\"âœ… LangSmith: ì„¤ì •ë¨ (í”„ë¡œì íŠ¸: {self.langsmith_project})\")\n",
        "        print(f\"âœ… Tavily API: ì„¤ì •ë¨\")\n",
        "\n",
        "    def init_classification_model(self):\n",
        "        \"\"\"ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™”\"\"\"\n",
        "        print(\"ğŸ“¦ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë”©...\")\n",
        "        try:\n",
        "            self.classification_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "            self.classification_model.eval()\n",
        "\n",
        "            self.classification_transform = transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "            # ImageNet í´ë˜ìŠ¤ ë¡œë“œ\n",
        "            try:\n",
        "                url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "                response = requests.get(url, timeout=10)\n",
        "                self.imagenet_classes = response.text.strip().split('\\n')\n",
        "            except:\n",
        "                self.imagenet_classes = [f\"í´ë˜ìŠ¤_{i}\" for i in range(1000)]\n",
        "\n",
        "            print(\"âœ… ResNet ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "    def init_vision_language_models(self):\n",
        "        \"\"\"ë¹„ì „-ì–¸ì–´ ëª¨ë¸ ì´ˆê¸°í™”\"\"\"\n",
        "        print(\"ğŸ” ë¹„ì „-ì–¸ì–´ ëª¨ë¸ ë¡œë”©...\")\n",
        "\n",
        "        # CLIP ëª¨ë¸ ì´ˆê¸°í™”\n",
        "        if CLIP_AVAILABLE:\n",
        "            try:\n",
        "                self.clip_model, self.clip_preprocess = clip.load(\"ViT-B/32\", device=self.device)\n",
        "                self.clip_available = True\n",
        "                print(\"âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
        "            except Exception as e:\n",
        "                self.clip_available = False\n",
        "                print(f\"âŒ CLIP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "        else:\n",
        "            self.clip_available = False\n",
        "            print(\"â„¹ï¸ CLIP ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "\n",
        "        # BLIP ëª¨ë¸ ì´ˆê¸°í™”\n",
        "        try:\n",
        "            self.blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "            self.blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "            self.blip_available = True\n",
        "            print(\"âœ… BLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
        "        except Exception as e:\n",
        "            self.blip_available = False\n",
        "            print(f\"âŒ BLIP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "    def init_gpt_and_langchain(self):\n",
        "        \"\"\"GPT ë° LangChain ì´ˆê¸°í™”\"\"\"\n",
        "        print(\"ğŸ§  GPT ë° LangChain ì´ˆê¸°í™”...\")\n",
        "\n",
        "        try:\n",
        "            # LangChain ChatOpenAI ì„¤ì •\n",
        "            self.llm = ChatOpenAI(\n",
        "                openai_api_key=self.openai_api_key,\n",
        "                model_name=\"gpt-3.5-turbo\",\n",
        "                temperature=0.7,\n",
        "                max_tokens=1000\n",
        "            )\n",
        "\n",
        "            # ë©”ëª¨ë¦¬ ì„¤ì •\n",
        "            self.memory = ConversationBufferMemory(\n",
        "                return_messages=True,\n",
        "                memory_key=\"chat_history\"\n",
        "            )\n",
        "\n",
        "            # LangSmith íŠ¸ë ˆì´ì„œ ì„¤ì •\n",
        "            try:\n",
        "                self.tracer = LangChainTracer(\n",
        "                    project_name=self.langsmith_project\n",
        "                )\n",
        "                self.callbacks = [self.tracer]\n",
        "                print(f\"âœ… LangSmith íŠ¸ë ˆì´ì‹± í™œì„±í™” (í”„ë¡œì íŠ¸: {self.langsmith_project})\")\n",
        "            except:\n",
        "                self.callbacks = []\n",
        "                print(\"âš ï¸ LangSmith íŠ¸ë ˆì´ì‹± ì„¤ì • ì‹¤íŒ¨\")\n",
        "\n",
        "            print(\"âœ… GPT ë° LangChain ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ GPT/LangChain ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
        "            self.llm = None\n",
        "\n",
        "    def init_search_tools(self):\n",
        "        \"\"\"ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”\"\"\"\n",
        "        print(\"ğŸ” ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”...\")\n",
        "\n",
        "        if TAVILY_AVAILABLE:\n",
        "            try:\n",
        "                # TavilySearch ì´ˆê¸°í™” ì‹œë„\n",
        "                if 'TavilySearch' in globals():\n",
        "                    self.tavily_search = TavilySearch()\n",
        "                else:\n",
        "                    # ëŒ€ì•ˆìœ¼ë¡œ TavilySearchResults ì‚¬ìš©\n",
        "                    self.tavily_search = TavilySearchResults(max_results=3)\n",
        "                self.search_available = True\n",
        "                print(\"âœ… Tavily Search ë„êµ¬ ë¡œë“œ ì™„ë£Œ\")\n",
        "            except Exception as e:\n",
        "                self.search_available = False\n",
        "                print(f\"âš ï¸ Tavily Search ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
        "        else:\n",
        "            self.search_available = False\n",
        "            print(\"âŒ Tavily Search ì‚¬ìš© ë¶ˆê°€\")\n",
        "\n",
        "    def search_web(self, query):\n",
        "        \"\"\"ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\"\"\"\n",
        "        if not self.search_available:\n",
        "            return \"ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\"\n",
        "\n",
        "        try:\n",
        "            # TavilySearch ì‹¤í–‰\n",
        "            if hasattr(self, 'tavily_search'):\n",
        "                if hasattr(self.tavily_search, 'invoke'):\n",
        "                    results = self.tavily_search.invoke(query)\n",
        "                else:\n",
        "                    results = self.tavily_search.run(query)\n",
        "\n",
        "                # ê²°ê³¼ ì •ë¦¬\n",
        "                if isinstance(results, list):\n",
        "                    search_summary = \"\\n\".join([\n",
        "                        f\"â€¢ {result.get('title', 'No title')}: {result.get('content', result.get('snippet', 'No content'))[:200]}...\"\n",
        "                        for result in results[:3]\n",
        "                    ])\n",
        "                elif isinstance(results, str):\n",
        "                    search_summary = results[:500] + \"...\" if len(results) > 500 else results\n",
        "                else:\n",
        "                    search_summary = str(results)[:500]\n",
        "\n",
        "                return search_summary\n",
        "            else:\n",
        "                return \"ê²€ìƒ‰ ë„êµ¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "\n",
        "    def classify_image(self, image):\n",
        "        \"\"\"ì´ë¯¸ì§€ ë¶„ë¥˜ ìˆ˜í–‰\"\"\"\n",
        "        if image is None:\n",
        "            return \"ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "        try:\n",
        "            # PIL Imageë¡œ ë³€í™˜\n",
        "            if isinstance(image, str):\n",
        "                image = Image.open(image).convert('RGB')\n",
        "            elif not isinstance(image, Image.Image):\n",
        "                image = Image.fromarray(image).convert('RGB')\n",
        "\n",
        "            # ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡\n",
        "            input_tensor = self.classification_transform(image).unsqueeze(0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.classification_model(input_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "\n",
        "            # ìƒìœ„ 5ê°œ ê²°ê³¼\n",
        "            top_probs, top_indices = torch.topk(probabilities, 5)\n",
        "\n",
        "            results = \"ğŸ¯ **ì´ë¯¸ì§€ ë¶„ë¥˜ ê²°ê³¼**\\n\\n\"\n",
        "            for i in range(5):\n",
        "                class_idx = top_indices[i].item()\n",
        "                prob = top_probs[i].item()\n",
        "                class_name = self.imagenet_classes[class_idx]\n",
        "                results += f\"**{i+1}.** {class_name}\\n\"\n",
        "                results += f\"   ğŸ“Š ì‹ ë¢°ë„: {prob*100:.2f}%\\n\\n\"\n",
        "\n",
        "            self.current_image = image\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "\n",
        "    def generate_description_with_gpt(self, image):\n",
        "        \"\"\"GPT APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±\"\"\"\n",
        "        if image is None:\n",
        "            return \"ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "        try:\n",
        "            # PIL Imageë¡œ ë³€í™˜\n",
        "            if isinstance(image, str):\n",
        "                image = Image.open(image).convert('RGB')\n",
        "            elif not isinstance(image, Image.Image):\n",
        "                image = Image.fromarray(image).convert('RGB')\n",
        "\n",
        "            # BLIPìœ¼ë¡œ ê¸°ë³¸ ìº¡ì…˜ ìƒì„±\n",
        "            basic_caption = self.get_basic_caption(image)\n",
        "\n",
        "            # ì´ë¯¸ì§€ ë¶„ì„ ì •ë³´ ìˆ˜ì§‘\n",
        "            analysis_info = self.get_image_analysis(image)\n",
        "\n",
        "            # GPTë¡œ í–¥ìƒëœ ì„¤ëª… ìƒì„±\n",
        "            enhanced_description = self.enhance_description_with_gpt(basic_caption, analysis_info)\n",
        "\n",
        "            result = \"ğŸ“– **GPT í–¥ìƒ ì´ë¯¸ì§€ ì„¤ëª…**\\n\\n\"\n",
        "            result += f\"ğŸ” **ê¸°ë³¸ ë¶„ì„:** {basic_caption}\\n\\n\"\n",
        "            result += f\"ğŸ§  **GPT í–¥ìƒ ì„¤ëª…:**\\n{enhanced_description}\\n\\n\"\n",
        "            result += f\"ğŸ“Š **ë¶„ì„ ì •ë³´:** {analysis_info}\"\n",
        "\n",
        "            self.current_image = image\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "\n",
        "    def get_basic_caption(self, image):\n",
        "        \"\"\"BLIPì„ ì‚¬ìš©í•œ ê¸°ë³¸ ìº¡ì…˜ ìƒì„±\"\"\"\n",
        "        if not self.blip_available:\n",
        "            return \"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ (BLIP ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€)\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.blip_processor(image, return_tensors=\"pt\")\n",
        "            with torch.no_grad():\n",
        "                out = self.blip_model.generate(**inputs, max_length=50)\n",
        "            return self.blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "        except Exception as e:\n",
        "            return f\"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ (ì˜¤ë¥˜: {str(e)[:50]})\"\n",
        "\n",
        "    def get_image_analysis(self, image):\n",
        "        \"\"\"ì´ë¯¸ì§€ ì¶”ê°€ ë¶„ì„ ì •ë³´\"\"\"\n",
        "        analysis = []\n",
        "\n",
        "        # ì´ë¯¸ì§€ í¬ê¸°\n",
        "        width, height = image.size\n",
        "        analysis.append(f\"í¬ê¸°: {width}x{height}\")\n",
        "\n",
        "        # ìƒ‰ìƒ ë¶„ì„\n",
        "        try:\n",
        "            colors = image.getcolors(maxcolors=256*256*256)\n",
        "            if colors:\n",
        "                analysis.append(f\"ìƒ‰ìƒ ë¶„ì„ ì™„ë£Œ\")\n",
        "        except:\n",
        "            analysis.append(\"ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨\")\n",
        "\n",
        "        # CLIP ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
        "        if self.clip_available and hasattr(self, 'clip_model'):\n",
        "            try:\n",
        "                categories = [\"ì‚¬ëŒ\", \"ë™ë¬¼\", \"ìì—°\", \"ê±´ë¬¼\", \"ìŒì‹\", \"ì°¨ëŸ‰\", \"ìŠ¤í¬ì¸ \", \"ì˜ˆìˆ \"]\n",
        "                category = self.analyze_with_clip(image, categories)\n",
        "                analysis.append(f\"ì¹´í…Œê³ ë¦¬: {category}\")\n",
        "            except:\n",
        "                analysis.append(\"CLIP ë¶„ì„ ì‹¤íŒ¨\")\n",
        "\n",
        "        return \" | \".join(analysis)\n",
        "\n",
        "    def analyze_with_clip(self, image, categories):\n",
        "        \"\"\"CLIPì„ ì‚¬ìš©í•œ ì¹´í…Œê³ ë¦¬ ë¶„ì„\"\"\"\n",
        "        if not self.clip_available:\n",
        "            return \"CLIP ì‚¬ìš© ë¶ˆê°€\"\n",
        "\n",
        "        try:\n",
        "            text_queries = [f\"a photo of {cat}\" for cat in categories]\n",
        "            text_tokens = clip.tokenize(text_queries).to(self.device)\n",
        "            image_tensor = self.clip_preprocess(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                image_features = self.clip_model.encode_image(image_tensor)\n",
        "                text_features = self.clip_model.encode_text(text_tokens)\n",
        "                similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "\n",
        "            best_idx = similarity[0].argmax().item()\n",
        "            return categories[best_idx]\n",
        "        except Exception as e:\n",
        "            return f\"ë¶„ì„ ì˜¤ë¥˜: {str(e)[:20]}\"\n",
        "\n",
        "    def enhance_description_with_gpt(self, basic_caption, analysis_info):\n",
        "        \"\"\"GPTë¡œ ì„¤ëª… í–¥ìƒ\"\"\"\n",
        "        if not self.llm:\n",
        "            return \"GPT APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "            ì´ë¯¸ì§€ ê¸°ë³¸ ë¶„ì„: {basic_caption}\n",
        "            ì¶”ê°€ ì •ë³´: {analysis_info}\n",
        "\n",
        "            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸í•˜ê³  í¥ë¯¸ë¡œìš´ í•œêµ­ì–´ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "            ë‹¤ìŒ ìš”ì†Œë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”:\n",
        "            1. ì‹œê°ì  ìš”ì†Œë“¤ì˜ êµ¬ì²´ì  ì„¤ëª…\n",
        "            2. ë¶„ìœ„ê¸°ë‚˜ ëŠë‚Œ\n",
        "            3. ì£¼ëª©í• ë§Œí•œ íŠ¹ì§•ë“¤\n",
        "            4. ì¶”ì •ë˜ëŠ” ìƒí™©ì´ë‚˜ ë§¥ë½\n",
        "\n",
        "            ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ 2-3 ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "            \"\"\"\n",
        "\n",
        "            messages = [\n",
        "                SystemMessage(content=\"ë‹¹ì‹ ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì°½ì˜ì ì´ê³  ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
        "                HumanMessage(content=prompt)\n",
        "            ]\n",
        "\n",
        "            response = self.llm.invoke(messages, callbacks=self.callbacks)\n",
        "            return response.content\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"GPT ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
        "\n",
        "    def answer_question_with_gpt_and_search(self, image, question):\n",
        "        \"\"\"GPT APIì™€ ì›¹ ê²€ìƒ‰ì„ ê²°í•©í•œ ì´ë¯¸ì§€ ì§ˆë¬¸ë‹µë³€\"\"\"\n",
        "        if image is None:\n",
        "            return \"ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "        if not question or question.strip() == \"\":\n",
        "            return \"ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "        if not self.llm:\n",
        "            return \"GPT APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        try:\n",
        "            # PIL Imageë¡œ ë³€í™˜\n",
        "            if isinstance(image, str):\n",
        "                image = Image.open(image).convert('RGB')\n",
        "            elif not isinstance(image, Image.Image):\n",
        "                image = Image.fromarray(image).convert('RGB')\n",
        "\n",
        "            # ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
        "            context = self.create_image_context_for_gpt(image)\n",
        "\n",
        "            # í•„ìš”ì‹œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n",
        "            search_results = \"\"\n",
        "            if any(keyword in question.lower() for keyword in ['ìµœì‹ ', 'í˜„ì¬', 'ë‰´ìŠ¤', 'ì •ë³´', 'ì°¾ì•„', 'ê²€ìƒ‰']):\n",
        "                search_query = f\"{context['caption']} {question}\"\n",
        "                search_results = self.search_web(search_query)\n",
        "\n",
        "            # GPTë¡œ ì§ˆë¬¸ë‹µë³€\n",
        "            answer = self.generate_gpt_answer_with_search(context, question, search_results)\n",
        "\n",
        "            result = f\"â“ **ì§ˆë¬¸:** {question}\\n\\n\"\n",
        "            result += f\"ğŸ¤– **GPT ë‹µë³€:** {answer}\"\n",
        "\n",
        "            if search_results and search_results != \"ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\":\n",
        "                result += f\"\\n\\nğŸ” **ì°¸ê³  ê²€ìƒ‰ ê²°ê³¼:**\\n{search_results[:300]}...\"\n",
        "\n",
        "            self.current_image = image\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "\n",
        "    def create_image_context_for_gpt(self, image):\n",
        "        \"\"\"GPTìš© ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ìƒì„±\"\"\"\n",
        "        context = {}\n",
        "\n",
        "        # ê¸°ë³¸ ìº¡ì…˜\n",
        "        context['caption'] = self.get_basic_caption(image)\n",
        "\n",
        "        # ë¶„ë¥˜ ì •ë³´\n",
        "        try:\n",
        "            input_tensor = self.classification_transform(image).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.classification_model(input_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "            top_prob, top_idx = torch.topk(probabilities, 3)\n",
        "\n",
        "            top_classes = []\n",
        "            for i in range(3):\n",
        "                class_name = self.imagenet_classes[top_idx[i].item()]\n",
        "                prob = top_prob[i].item()\n",
        "                top_classes.append(f\"{class_name} ({prob*100:.1f}%)\")\n",
        "\n",
        "            context['classification'] = \", \".join(top_classes)\n",
        "        except:\n",
        "            context['classification'] = \"ë¶„ë¥˜ ì •ë³´ ì—†ìŒ\"\n",
        "\n",
        "        # ì¶”ê°€ ë¶„ì„\n",
        "        context['analysis'] = self.get_image_analysis(image)\n",
        "\n",
        "        return context\n",
        "\n",
        "    def generate_gpt_answer_with_search(self, context, question, search_results=\"\"):\n",
        "        \"\"\"GPTë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ ì§ˆë¬¸ ë‹µë³€ ìƒì„±\"\"\"\n",
        "        try:\n",
        "            search_context = f\"\\n\\nì›¹ ê²€ìƒ‰ ê²°ê³¼:\\n{search_results}\" if search_results else \"\"\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            ì´ë¯¸ì§€ ë¶„ì„ ì •ë³´:\n",
        "            - ê¸°ë³¸ ì„¤ëª…: {context['caption']}\n",
        "            - ë¶„ë¥˜ ê²°ê³¼: {context['classification']}\n",
        "            - ì¶”ê°€ ë¶„ì„: {context['analysis']}{search_context}\n",
        "\n",
        "            ì‚¬ìš©ì ì§ˆë¬¸: {question}\n",
        "\n",
        "            ìœ„ ì´ë¯¸ì§€ ë¶„ì„ ì •ë³´ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í•œêµ­ì–´ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
        "            ë§Œì•½ ì´ë¯¸ì§€ ì •ë³´ë§Œìœ¼ë¡œëŠ” í™•ì‹¤í•œ ë‹µë³€ì´ ì–´ë ¤ìš´ ê²½ìš°, ê·¸ë ‡ë‹¤ê³  ëª…ì‹œí•˜ê³  ê°€ëŠ¥í•œ ì¶”ì •ì´ë‚˜ ì¼ë°˜ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\n",
        "            ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì ì ˆíˆ í™œìš©í•´ì£¼ì„¸ìš”.\n",
        "            \"\"\"\n",
        "\n",
        "            # ë©”ëª¨ë¦¬ì—ì„œ ì´ì „ ëŒ€í™” ê°€ì ¸ì˜¤ê¸°\n",
        "            chat_history = self.memory.chat_memory.messages if self.memory.chat_memory.messages else []\n",
        "\n",
        "            messages = [\n",
        "                SystemMessage(content=\"ë‹¹ì‹ ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
        "                *chat_history[-6:],  # ìµœê·¼ 3ë²ˆì˜ ëŒ€í™”ë§Œ ìœ ì§€\n",
        "                HumanMessage(content=prompt)\n",
        "            ]\n",
        "\n",
        "            # callbacksëŠ” ì´ë¯¸ ì´ˆê¸°í™” ì‹œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì œê±°\n",
        "            response = self.llm.invoke(messages)\n",
        "            answer = response.content\n",
        "\n",
        "            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥\n",
        "            self.memory.chat_memory.add_user_message(question)\n",
        "            self.memory.chat_memory.add_ai_message(answer)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"GPT ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
        "\n",
        "    def get_api_status(self):\n",
        "        \"\"\"API ìƒíƒœ í™•ì¸\"\"\"\n",
        "        status = \"ğŸ”§ **API ìƒíƒœ**\\n\\n\"\n",
        "\n",
        "        # OpenAI API ìƒíƒœ\n",
        "        try:\n",
        "            test_response = self.openai_client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": \"test\"}],\n",
        "                max_tokens=5\n",
        "            )\n",
        "            status += \"âœ… OpenAI API: ì—°ê²°ë¨\\n\"\n",
        "        except:\n",
        "            status += \"âŒ OpenAI API: ì—°ê²° ì‹¤íŒ¨\\n\"\n",
        "\n",
        "        # LangSmith ìƒíƒœ\n",
        "        status += f\"âœ… LangSmith: í™œì„±í™”ë¨ (í”„ë¡œì íŠ¸: {self.langsmith_project})\\n\"\n",
        "\n",
        "        # Tavily Search ìƒíƒœ\n",
        "        status += f\"{'âœ…' if self.search_available else 'âŒ'} Tavily Search: {'í™œì„±í™”ë¨' if self.search_available else 'ë¹„í™œì„±í™”ë¨'}\\n\"\n",
        "\n",
        "        # ëª¨ë¸ ìƒíƒœ\n",
        "        status += f\"âœ… ì´ë¯¸ì§€ ë¶„ë¥˜: í™œì„±í™”ë¨\\n\"\n",
        "        status += f\"{'âœ…' if self.blip_available else 'âŒ'} BLIP ìº¡ì…˜: {'í™œì„±í™”ë¨' if self.blip_available else 'ë¹„í™œì„±í™”ë¨'}\\n\"\n",
        "        status += f\"{'âœ…' if self.clip_available else 'âŒ'} CLIP: {'í™œì„±í™”ë¨' if self.clip_available else 'ë¹„í™œì„±í™”ë¨'}\\n\"\n",
        "\n",
        "        return status\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"GPT ì—°ë™ Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\"\"\"\n",
        "\n",
        "    # AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
        "    ai_system = GPTMultimodalAI()\n",
        "\n",
        "    # CSS ìŠ¤íƒ€ì¼\n",
        "    css = \"\"\"\n",
        "    .gradio-container {\n",
        "        max-width: 1400px !important;\n",
        "    }\n",
        "    .image-container {\n",
        "        max-height: 400px;\n",
        "    }\n",
        "    .output-text {\n",
        "        font-family: 'Malgun Gothic', Arial, sans-serif;\n",
        "        line-height: 1.6;\n",
        "    }\n",
        "    .api-status {\n",
        "        background-color: #f0f0f0;\n",
        "        padding: 10px;\n",
        "        border-radius: 5px;\n",
        "        margin: 10px 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(css=css, title=\"ğŸ¤– GPT & LangChain & Tavily ì—°ë™ AI\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(f\"\"\"\n",
        "        # ğŸ¤– GPT & LangChain & Tavily ì—°ë™ ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œ\n",
        "        ### OpenAI GPT, LangChain, LangSmith, Tavily Searchê°€ ì—°ë™ëœ ìµœê³ ê¸‰ ì´ë¯¸ì§€ ë¶„ì„ ì‹œìŠ¤í…œ\n",
        "\n",
        "        ğŸš€ **ì£¼ìš” ê¸°ëŠ¥:**\n",
        "        - ğŸ“Š **ì´ë¯¸ì§€ ë¶„ë¥˜**: ResNet ê¸°ë°˜ ì •í™•í•œ ê°ì²´ ë¶„ë¥˜\n",
        "        - ğŸ§  **GPT í–¥ìƒ ì„¤ëª…**: BLIP + GPT APIë¡œ ìƒì„¸í•˜ê³  ì°½ì˜ì ì¸ ì„¤ëª… ìƒì„±\n",
        "        - ğŸ’¬ **ì§€ëŠ¥í˜• ì§ˆë¬¸ë‹µë³€**: ì´ë¯¸ì§€ + ì›¹ ê²€ìƒ‰ ê²°í•© AI ëŒ€í™”\n",
        "        - ğŸ” **Tavily ì›¹ ê²€ìƒ‰**: ì‹¤ì‹œê°„ ì •ë³´ ê²€ìƒ‰ ë° í†µí•©\n",
        "        - ğŸ“ˆ **LangSmith ì¶”ì **: ëŒ€í™” í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ (í”„ë¡œì íŠ¸: {ai_system.langsmith_project})\n",
        "\n",
        "        âš ï¸ **ë³´ì•ˆ ê³µì§€**: API í‚¤ê°€ ì½”ë“œì— ì§ì ‘ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìš´ì˜ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
        "        \"\"\")\n",
        "\n",
        "        # API ìƒíƒœ í‘œì‹œ\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                api_status = gr.Markdown(\n",
        "                    value=ai_system.get_api_status(),\n",
        "                    elem_classes=[\"api-status\"]\n",
        "                )\n",
        "                refresh_status_btn = gr.Button(\"ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨\", size=\"sm\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # ì´ë¯¸ì§€ ì—…ë¡œë“œ\n",
        "                image_input = gr.Image(\n",
        "                    label=\"ğŸ“· ì´ë¯¸ì§€ ì—…ë¡œë“œ\",\n",
        "                    type=\"pil\",\n",
        "                    height=400\n",
        "                )\n",
        "\n",
        "                # ì§ˆë¬¸ ì…ë ¥\n",
        "                question_input = gr.Textbox(\n",
        "                    label=\"â“ ì§ˆë¬¸ ì…ë ¥ (GPT + Tavily ê²€ìƒ‰ ê²°í•© ë‹µë³€)\",\n",
        "                    placeholder=\"ì˜ˆ: ì´ ì´ë¯¸ì§€ì˜ ìµœì‹  ì •ë³´ë¥¼ ì°¾ì•„ì„œ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "                    lines=3\n",
        "                )\n",
        "\n",
        "                # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "                with gr.Accordion(\"ğŸ” Tavily ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\", open=False):\n",
        "                    search_query_input = gr.Textbox(\n",
        "                        label=\"ê²€ìƒ‰ì–´ ì…ë ¥\",\n",
        "                        placeholder=\"ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”\"\n",
        "                    )\n",
        "                    search_btn = gr.Button(\"ğŸ” ì›¹ ê²€ìƒ‰ ì‹¤í–‰\")\n",
        "                    search_output = gr.Textbox(\n",
        "                        label=\"ê²€ìƒ‰ ê²°ê³¼\",\n",
        "                        lines=5\n",
        "                    )\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                # íƒ­ êµ¬ì„±\n",
        "                with gr.Tabs():\n",
        "                    with gr.Tab(\"ğŸ“Š ì´ë¯¸ì§€ ë¶„ë¥˜\"):\n",
        "                        classify_btn = gr.Button(\"ğŸ” ë¶„ë¥˜ ì‹œì‘\", variant=\"primary\", size=\"lg\")\n",
        "                        classification_output = gr.Markdown(\n",
        "                            label=\"ë¶„ë¥˜ ê²°ê³¼\",\n",
        "                            elem_classes=[\"output-text\"]\n",
        "                        )\n",
        "\n",
        "                    with gr.Tab(\"ğŸ§  GPT í–¥ìƒ ì„¤ëª…\"):\n",
        "                        describe_btn = gr.Button(\"âœ¨ GPT ì„¤ëª… ìƒì„±\", variant=\"primary\", size=\"lg\")\n",
        "                        description_output = gr.Markdown(\n",
        "                            label=\"GPT í–¥ìƒ ì„¤ëª…\",\n",
        "                            elem_classes=[\"output-text\"]\n",
        "                        )\n",
        "\n",
        "                    with gr.Tab(\"ğŸ’¬ GPT + Tavily ì§ˆë¬¸ë‹µë³€\"):\n",
        "                        answer_btn = gr.Button(\"ğŸ¤– GPT + ê²€ìƒ‰ ë‹µë³€\", variant=\"primary\", size=\"lg\")\n",
        "                        qa_output = gr.Markdown(\n",
        "                            label=\"GPT + Tavily ë‹µë³€\",\n",
        "                            elem_classes=[\"output-text\"]\n",
        "                        )\n",
        "\n",
        "                    with gr.Tab(\"ğŸ“ˆ ëŒ€í™” íˆìŠ¤í† ë¦¬\"):\n",
        "                        clear_memory_btn = gr.Button(\"ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\", variant=\"secondary\")\n",
        "                        memory_output = gr.Markdown(\n",
        "                            label=\"ëŒ€í™” ê¸°ë¡\",\n",
        "                            elem_classes=[\"output-text\"]\n",
        "                        )\n",
        "\n",
        "        # ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤\n",
        "        gr.Markdown(\"### ğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!\")\n",
        "\n",
        "        sample_images = [\n",
        "            \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/American_Eskimo_Dog.jpg/440px-American_Eskimo_Dog.jpg\",\n",
        "            \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Collage_of_Nine_Dogs.jpg/440px-Collage_of_Nine_Dogs.jpg\",\n",
        "            \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Orange_tabby_cat_sitting_on_fallen_leaves-Hisashi-01A.jpg/440px-Orange_tabby_cat_sitting_on_fallen_leaves-Hisashi-01A.jpg\"\n",
        "        ]\n",
        "\n",
        "        with gr.Row():\n",
        "            sample_btn1 = gr.Button(\"ğŸ• ê°•ì•„ì§€ ìƒ˜í”Œ\", size=\"sm\")\n",
        "            sample_btn2 = gr.Button(\"ğŸ•â€ğŸ¦º ì—¬ëŸ¬ ê°•ì•„ì§€\", size=\"sm\")\n",
        "            sample_btn3 = gr.Button(\"ğŸ± ê³ ì–‘ì´ ìƒ˜í”Œ\", size=\"sm\")\n",
        "\n",
        "        # í•¨ìˆ˜ë“¤ ì •ì˜\n",
        "        def show_memory():\n",
        "            if ai_system.memory.chat_memory.messages:\n",
        "                history = \"ğŸ“‹ **ìµœê·¼ ëŒ€í™” ê¸°ë¡:**\\n\\n\"\n",
        "                for i, msg in enumerate(ai_system.memory.chat_memory.messages[-10:]):  # ìµœê·¼ 10ê°œë§Œ\n",
        "                    if hasattr(msg, 'content'):\n",
        "                        role = \"ğŸ§‘ ì‚¬ìš©ì\" if \"Human\" in str(type(msg)) else \"ğŸ¤– AI\"\n",
        "                        history += f\"**{role}:** {msg.content[:200]}{'...' if len(msg.content) > 200 else ''}\\n\\n\"\n",
        "                return history\n",
        "            else:\n",
        "                return \"ì•„ì§ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        def clear_memory():\n",
        "            ai_system.memory.clear()\n",
        "            return \"ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        # ì´ë²¤íŠ¸ ë°”ì¸ë”©\n",
        "        classify_btn.click(\n",
        "            fn=ai_system.classify_image,\n",
        "            inputs=[image_input],\n",
        "            outputs=[classification_output]\n",
        "        )\n",
        "\n",
        "        describe_btn.click(\n",
        "            fn=ai_system.generate_description_with_gpt,\n",
        "            inputs=[image_input],\n",
        "            outputs=[description_output]\n",
        "        )\n",
        "\n",
        "        answer_btn.click(\n",
        "            fn=ai_system.answer_question_with_gpt_and_search,\n",
        "            inputs=[image_input, question_input],\n",
        "            outputs=[qa_output]\n",
        "        )\n",
        "\n",
        "        refresh_status_btn.click(\n",
        "            fn=ai_system.get_api_status,\n",
        "            inputs=[],\n",
        "            outputs=[api_status]\n",
        "        )\n",
        "\n",
        "        search_btn.click(\n",
        "            fn=ai_system.search_web,\n",
        "            inputs=[search_query_input],\n",
        "            outputs=[search_output]\n",
        "        )\n",
        "\n",
        "        clear_memory_btn.click(\n",
        "            fn=clear_memory,\n",
        "            inputs=[],\n",
        "            outputs=[memory_output]\n",
        "        )\n",
        "\n",
        "        # ëŒ€í™” ê¸°ë¡ í‘œì‹œ\n",
        "        answer_btn.click(\n",
        "            fn=show_memory,\n",
        "            inputs=[],\n",
        "            outputs=[memory_output]\n",
        "        )\n",
        "\n",
        "        # ìƒ˜í”Œ ì´ë¯¸ì§€ ë°”ì¸ë”©\n",
        "        sample_btn1.click(fn=lambda: sample_images[0], outputs=[image_input])\n",
        "        sample_btn2.click(fn=lambda: sample_images[1], outputs=[image_input])\n",
        "        sample_btn3.click(fn=lambda: sample_images[2], outputs=[image_input])\n",
        "\n",
        "        # ì‚¬ìš©ë²• ì•ˆë‚´\n",
        "        gr.Markdown(f\"\"\"\n",
        "        ---\n",
        "        ### ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´ ë° ì‚¬ìš©ë²•\n",
        "\n",
        "        #### ğŸ”§ **í˜„ì¬ ì„¤ì •**\n",
        "        - **OpenAI API**: ì§ì ‘ ì„¤ì •ë¨\n",
        "        - **LangSmith í”„ë¡œì íŠ¸**: {ai_system.langsmith_project}\n",
        "        - **Tavily Search**: {'í™œì„±í™”ë¨' if ai_system.search_available else 'ë¹„í™œì„±í™”ë¨'}\n",
        "        - **ì¶”ì  ëª¨ë“œ**: LangSmith íŠ¸ë ˆì´ì‹± í™œì„±í™”\n",
        "\n",
        "        #### ğŸ¯ **ê³ ê¸‰ ê¸°ëŠ¥**\n",
        "        1. **ì´ë¯¸ì§€ ë¶„ë¥˜**: ResNet ê¸°ë°˜ 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜\n",
        "        2. **GPT í–¥ìƒ ì„¤ëª…**: BLIP ê¸°ë³¸ ë¶„ì„ + GPTì˜ ì°½ì˜ì  í•´ì„\n",
        "        3. **GPT + Tavily ì§ˆë¬¸ë‹µë³€**: ì´ë¯¸ì§€ + ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ê²°í•©\n",
        "        4. **Tavily ê²€ìƒ‰**: ë…ë¦½ì ì¸ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥\n",
        "        5. **ëŒ€í™” íˆìŠ¤í† ë¦¬**: ì—°ì†ì  ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
        "\n",
        "        #### ğŸ’¡ **ê³ ê¸‰ ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "        - \"ì´ ë™ë¬¼ì˜ ìµœì‹  ì—°êµ¬ ê²°ê³¼ë¥¼ ì°¾ì•„ì„œ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
        "        - \"ì´ ì¥ì†Œì˜ í˜„ì¬ ê´€ê´‘ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”\"\n",
        "        - \"ì´ ì œí’ˆì˜ ìµœì‹  ë¦¬ë·°ë‚˜ ë‰´ìŠ¤ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”\"\n",
        "        - \"ì´ ê¸°ìˆ ì˜ ìµœê·¼ ë°œì „ ë™í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”\"\n",
        "\n",
        "        #### ğŸ” **LangSmith ëª¨ë‹ˆí„°ë§**\n",
        "        - í”„ë¡œì íŠ¸: {ai_system.langsmith_project}\n",
        "        - ëª¨ë“  ëŒ€í™”ì™€ ê²€ìƒ‰ì´ ì¶”ì ë©ë‹ˆë‹¤\n",
        "        - ì„±ëŠ¥, ë¹„ìš©, í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘\n",
        "\n",
        "        #### âš¡ **ì„±ëŠ¥ ìµœì í™”**\n",
        "        - ì´ë¯¸ì§€ëŠ” ìë™ìœ¼ë¡œ ìµœì  í¬ê¸°ë¡œ ì¡°ì •\n",
        "        - ëŒ€í™” ê¸°ë¡ì€ íš¨ìœ¨ì„±ì„ ìœ„í•´ ìµœê·¼ 6ê°œë§Œ ìœ ì§€\n",
        "        - ê²€ìƒ‰ ê²°ê³¼ëŠ” ê´€ë ¨ì„± ë†’ì€ ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©\n",
        "\n",
        "        âš ï¸ **ë³´ì•ˆ ì°¸ê³ **: í˜„ì¬ API í‚¤ê°€ ì½”ë“œì— í•˜ë“œì½”ë”©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "        ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë°˜ë“œì‹œ í™˜ê²½ë³€ìˆ˜ë‚˜ ë³´ì•ˆ í‚¤ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# ì‹¤í–‰ í•¨ìˆ˜\n",
        "def main():\n",
        "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ğŸš€ GPT & LangChain & Tavily ì—°ë™ ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(f\"\\nâœ… API í‚¤ ì„¤ì • ì™„ë£Œ:\")\n",
        "    print(f\"   â€¢ OpenAI API: {OPENAI_API_KEY[:20]}...\")\n",
        "    print(f\"   â€¢ LangSmith í”„ë¡œì íŠ¸: langgraph_5\")\n",
        "    print(f\"   â€¢ Tavily API: {TAVILY_API_KEY[:20]}...\")\n",
        "\n",
        "    # ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì‹¤í–‰\n",
        "    demo = create_gradio_interface()\n",
        "\n",
        "    print(\"\\nğŸŒ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    print(\"ğŸ’¡ ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤!\")\n",
        "    print(\"ğŸ”— ìˆ˜ë™ ì ‘ì†: http://localhost:17861\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "    # ê³µê°œ ë§í¬ë¡œ ì‹¤í–‰\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        inbrowser=True,\n",
        "        show_error=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=7860,\n",
        "        height=800,\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d91d9acc6764c0b8c08282b409db3b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6b6ef128874d7b85a26b62fffb6008": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3776246062fd4788b26ed14b9055d5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db0eb96250ce44609b06a9d95d1f7255",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b811a4325b584db8bd0cd2171e7c06d6",
            "value": 1
          }
        },
        "6df62d02490c42dcbe3c4533eb50e08a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952b5d34082e4313a42fe7429e3b1a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6b6ef128874d7b85a26b62fffb6008",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f91508bf5a654dadb9d45e86d2ae746a",
            "value": "Fetchingâ€‡1â€‡files:â€‡100%"
          }
        },
        "b811a4325b584db8bd0cd2171e7c06d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba117289213145658465990e9a21a79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_952b5d34082e4313a42fe7429e3b1a1e",
              "IPY_MODEL_3776246062fd4788b26ed14b9055d5a6",
              "IPY_MODEL_effb384b71f14bedb86516157fa6f801"
            ],
            "layout": "IPY_MODEL_6df62d02490c42dcbe3c4533eb50e08a"
          }
        },
        "db0eb96250ce44609b06a9d95d1f7255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbcde36c6cf4d5eb178a06b8bc92353": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "effb384b71f14bedb86516157fa6f801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d91d9acc6764c0b8c08282b409db3b3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dbbcde36c6cf4d5eb178a06b8bc92353",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡66.66it/s]"
          }
        },
        "f91508bf5a654dadb9d45e86d2ae746a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
