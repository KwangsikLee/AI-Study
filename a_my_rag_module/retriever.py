from typing import List, Dict, Any, Optional
from sentence_transformers import CrossEncoder
from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever




# =============================================================================
#  Reranker í´ë˜ìŠ¤ (ì¬ìˆœìœ„í™”)
# =============================================================================

class MyReranker:
    def __init__(self):
        # ì‚¬ìš© ê°€ëŠ¥í•œ reranker ëª¨ë¸ë“¤
        self.reranker_models = {
            "cross-encoder-ms-marco": {
                "name": "cross-encoder/ms-marco-MiniLM-L-6-v2",
                "description": "MS MARCO ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ê²½ëŸ‰ CrossEncoder",
                "language": "English (Multilingual capable)",
                "size": "~80MB"
            },
            "cross-encoder-multilingual": {
                "name": "cross-encoder/mmarco-mMiniLMv2-L12-H384-v1",
                "description": "ë‹¤êµ­ì–´ mMARCO CrossEncoder",
                "language": "Multilingual",
                "size": "~400MB"
            },
            "bge-reranker": {
                "name": "BAAI/bge-reranker-base",
                "description": "BGE Reranker (ì¤‘êµ­ì–´/ì˜ì–´ íŠ¹í™”)",
                "language": "Chinese/English",
                "size": "~400MB"
            }
        }

        self.loaded_rerankers = {}
        self.current_reranker = None
        self.current_model_key = None

    def load_reranker(self, model_key: str = "cross-encoder-ms-marco") -> CrossEncoder:
        """Reranker ëª¨ë¸ ë¡œë“œ"""
        if model_key in self.loaded_rerankers:
            self.current_reranker = self.loaded_rerankers[model_key]
            self.current_model_key = model_key
            return self.current_reranker

        if model_key not in self.reranker_models:
            model_key = "cross-encoder-ms-marco"  # fallback

        model_info = self.reranker_models[model_key]
        print(f"Loading reranker: {model_info['name']} ({model_info['size']})")

        try:
            reranker = CrossEncoder(model_info['name'])
            self.loaded_rerankers[model_key] = reranker
            self.current_reranker = reranker
            self.current_model_key = model_key
            return reranker
        except Exception as e:
            print(f"Failed to load reranker {model_key}: {e}")
            # fallback to None (no reranking)
            self.current_reranker = None
            return None

    def rerank_documents(self, query: str, documents: List[Document], top_k: int = 10) -> List[Document]:
        """ë¬¸ì„œ ì¬ìˆœìœ„í™”"""
        if not self.current_reranker or len(documents) <= 1:
            return documents[:top_k]

        try:
            # ì¿¼ë¦¬-ë¬¸ì„œ ìŒ ìƒì„±
            query_doc_pairs = [(query, doc.page_content[:512]) for doc in documents]

            # ì ìˆ˜ ê³„ì‚°
            scores = self.current_reranker.predict(query_doc_pairs)

            # ì ìˆ˜ì™€ ë¬¸ì„œë¥¼ ê²°í•©í•˜ì—¬ ì •ë ¬
            scored_docs = list(zip(scores, documents))
            scored_docs.sort(key=lambda x: x[0], reverse=True)

            # ìƒìœ„ top_k ê°œ ë¬¸ì„œ ë°˜í™˜
            reranked_docs = [doc for score, doc in scored_docs[:top_k]]

            print(f"Reranked {len(documents)} documents to top {len(reranked_docs)} with model: {self.current_model_key}")
            return reranked_docs

        except Exception as e:
            print(f"Reranking failed: {e}, returning original order")
            return documents[:top_k]

    def get_available_rerankers(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ reranker ëª¨ë¸ ëª©ë¡"""
        models = {key: f"{info['description']} ({info['language']}, {info['size']})"
                 for key, info in self.reranker_models.items()}
        models["none"] = "Reranking ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"
        return models

    def get_current_reranker_info(self) -> str:
        """í˜„ì¬ reranker ì •ë³´"""
        if self.current_reranker and self.current_model_key:
            info = self.reranker_models[self.current_model_key]
            return f"ğŸ”„ {info['description']} ({info['language']}, {info['size']})"
        return "ğŸ”„ Reranking ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"



# =============================================================================
# í–¥ìƒëœ ë³µí•© ê²€ìƒ‰ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ (Retrieval - ë³µìˆ˜ì˜ ëª¨ë¸ ì ìš© + Rerank)
# =============================================================================

class AdvancedHybridRetriever:
    def __init__(self, documents: List[Document], vector_store: FAISS,
                 reranker: MyReranker = None, reranker_model: str = "cross-encoder-ms-marco"):
        self.documents = documents
        self.vector_store = vector_store
        self.reranker = reranker or MyReranker()

        # Reranker ë¡œë“œ
        if reranker_model != "none":
            self.reranker.load_reranker(reranker_model)

        # BM25 ê²€ìƒ‰ê¸° ìƒì„±
        try:
            texts = [doc.page_content for doc in documents]
            self.bm25_retriever = BM25Retriever.from_texts(
                texts,
                metadatas=[doc.metadata for doc in documents]
            )
            self.bm25_retriever.k = 15  # rerankë¥¼ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
        except Exception as e:
            print(f"BM25 ê²€ìƒ‰ê¸° ìƒì„± ì˜¤ë¥˜: {e}")
            self.bm25_retriever = None

        # ë²¡í„° ê²€ìƒ‰ê¸°
        self.vector_retriever = vector_store.as_retriever(
            search_kwargs={"k": 15}  # rerankë¥¼ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
        )

        # ì•™ìƒë¸” ê²€ìƒ‰ê¸° (í•˜ì´ë¸Œë¦¬ë“œ)
        if self.bm25_retriever:
            self.ensemble_retriever = EnsembleRetriever(
                retrievers=[self.bm25_retriever, self.vector_retriever],
                weights=[0.4, 0.6]
            )
        else:
            self.ensemble_retriever = self.vector_retriever

    def search_by_similarity(self, query: str, k: int = 5, use_rerank: bool = True) -> List[Document]:
        """ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ + Rerank"""
        docs = self.vector_retriever.invoke(query)
        if use_rerank and self.reranker.current_reranker:
            docs = self.reranker.rerank_documents(query, docs, k)
        return docs[:k]

    def search_by_keyword(self, query: str, k: int = 5, use_rerank: bool = True) -> List[Document]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ + Rerank"""
        if self.bm25_retriever:
            docs = self.bm25_retriever.invoke(query)
        else:
            docs = self.vector_retriever.invoke(query)

        if use_rerank and self.reranker.current_reranker:
            docs = self.reranker.rerank_documents(query, docs, k)
        return docs[:k]

    def hybrid_search(self, query: str, k: int = 5, use_rerank: bool = True) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Rerank"""
        docs = self.ensemble_retriever.invoke(query)
        if use_rerank and self.reranker.current_reranker:
            docs = self.reranker.rerank_documents(query, docs, k)
        return docs[:k]

    def advanced_search(self, query: str, method: str = "hybrid", k: int = 5,
                       use_rerank: bool = True, rerank_top_k: int = 15) -> List[Document]:
        """ê³ ê¸‰ ê²€ìƒ‰ (ëª¨ë“  ë°©ë²• + Rerank)"""
        if method == "similarity":
            # ë²¡í„° ê²€ìƒ‰
            docs = self.vector_retriever.invoke(query)[:rerank_top_k]
        elif method == "keyword":
            # BM25 ê²€ìƒ‰
            if self.bm25_retriever:
                docs = self.bm25_retriever.invoke(query)[:rerank_top_k]
            else:
                docs = self.vector_retriever.invoke(query)[:rerank_top_k]
        elif method == "ensemble":
            # ì•™ìƒë¸” ê²€ìƒ‰ (BM25 + Vector)
            docs = self.ensemble_retriever.invoke(query)[:rerank_top_k]
        else:  # method == "hybrid"
            # ë‹¤ì¤‘ ë°©ë²• ìœµí•©
            vector_docs = self.vector_retriever.invoke(query)[:10]
            if self.bm25_retriever:
                keyword_docs = self.bm25_retriever.invoke(query)[:10]
                # ë¬¸ì„œ ìœµí•© (ì¤‘ë³µ ì œê±°)
                seen_docs = set()
                fused_docs = []
                for doc in vector_docs + keyword_docs:
                    doc_id = doc.page_content[:100]  # ê°„ë‹¨í•œ ì¤‘ë³µ ì²´í¬
                    if doc_id not in seen_docs:
                        seen_docs.add(doc_id)
                        fused_docs.append(doc)
                docs = fused_docs[:rerank_top_k]
            else:
                docs = vector_docs

        # Rerank ì ìš©
        if use_rerank and self.reranker.current_reranker:
            docs = self.reranker.rerank_documents(query, docs, k)

        return docs[:k]

    def search_by_date(self, date: str) -> List[Document]:
        """ë‚ ì§œ ê¸°ë°˜ ê²€ìƒ‰"""
        filtered_docs = [doc for doc in self.documents
                        if doc.metadata.get('date') == date]
        return filtered_docs

    def switch_reranker(self, reranker_model: str) -> str:
        """Reranker ëª¨ë¸ ë³€ê²½"""
        if reranker_model == "none":
            self.reranker.current_reranker = None
            return "ğŸ”„ Rerankingì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            self.reranker.load_reranker(reranker_model)
            return f"ğŸ”„ Reranker ë³€ê²½ ì™„ë£Œ: {self.reranker.get_current_reranker_info()}"
        

if __name__ == "__main__":
    import sys
    import os
    # í˜„ì¬ íŒŒì¼ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    sys.path.insert(0, parent_dir)
    
    from a_my_rag_module.embedding import VectorStoreManager

    # 1. Documents
    documents = [
        Document(
            page_content="""
            ë‹¹ë‡¨ë³‘ì€ ì¸ìŠë¦°ì˜ ë¶„ë¹„ëŸ‰ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ì •ìƒì ì¸ ê¸°ëŠ¥ì´ ì´ë£¨ì–´ì§€ì§€ ì•ŠëŠ” ëŒ€ì‚¬ì§ˆí™˜ì…ë‹ˆë‹¤.
            ì œ1í˜• ë‹¹ë‡¨ë³‘ì€ ì¸ìŠë¦°ì„ ìƒì‚°í•˜ì§€ ëª»í•´ ë°œìƒí•˜ë©°, ì£¼ë¡œ ì†Œì•„ì²­ì†Œë…„ê¸°ì— ë°œë³‘í•©ë‹ˆë‹¤.
            ì œ2í˜• ë‹¹ë‡¨ë³‘ì€ ì¸ìŠë¦° ì €í•­ì„±ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ë©°, ì„±ì¸ì—ê²Œì„œ ì£¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
            ë‹¹ë‡¨ë³‘ì˜ ì£¼ìš” ì¦ìƒìœ¼ë¡œëŠ” ë‹¤ë‡¨, ë‹¤ìŒ, ë‹¤ì‹, ì²´ì¤‘ê°ì†Œ ë“±ì´ ìˆìŠµë‹ˆë‹¤.
            í˜ˆë‹¹ ê´€ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” ê·œì¹™ì ì¸ ìš´ë™ê³¼ ì‹ì´ì¡°ì ˆì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.
            """,
            metadata={"category": "disease", "topic": "diabetes", "doc_id": "1"}
        ),
        Document(
            page_content="""
            ê³ í˜ˆì••ì€ ìˆ˜ì¶•ê¸° í˜ˆì••ì´ 140mmHg ì´ìƒì´ê±°ë‚˜ ì´ì™„ê¸° í˜ˆì••ì´ 90mmHg ì´ìƒì¸ ìƒíƒœë¥¼ ë§í•©ë‹ˆë‹¤.
            ê³ í˜ˆì••ì€ 'ì¹¨ë¬µì˜ ì‚´ì¸ì'ë¡œ ë¶ˆë¦¬ë©°, ì´ˆê¸°ì—ëŠ” íŠ¹ë³„í•œ ì¦ìƒì´ ì—†ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
            ì¥ê¸°ê°„ ê³ í˜ˆì••ì´ ì§€ì†ë˜ë©´ ì‹¬ì¥ì§ˆí™˜, ë‡Œì¡¸ì¤‘, ì‹ ì¥ì§ˆí™˜ì˜ ìœ„í—˜ì´ ì¦ê°€í•©ë‹ˆë‹¤.
            ìƒí™œìŠµê´€ ê°œì„ ê³¼ ì•½ë¬¼ì¹˜ë£Œë¥¼ í†µí•´ í˜ˆì••ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            ì •ê¸°ì ì¸ í˜ˆì•• ì¸¡ì •ê³¼ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
            """,
            metadata={"category": "disease", "topic": "hypertension", "doc_id": "2"}
        )
    ]

    # 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    print("3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    embedding_model_key: str = "ko-sroberta-multitask"
    vector_manager = VectorStoreManager()
    vector_store = vector_manager.create_vector_store(documents)

    # 5. ê³ ê¸‰ ê²€ìƒ‰ê¸° ìƒì„±
    print("5. ê³ ê¸‰ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì¤‘...")
    retriever = AdvancedHybridRetriever(documents, vector_store)
